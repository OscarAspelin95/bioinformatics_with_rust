<!DOCTYPE HTML>
<html lang="en" class="coal sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Bioinformatics with Rust</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        <meta property="og:title" content="Bioinformatics With Rust" />
        <meta property="og:description" content="An introduction to using Rust for bioinformatic applications." />
        <meta property="og:image" content="" />
        <meta property="og:url"
            content="https://github.com/OscarAspelin95/bioinformatics_with_rust/blob/5fd7158379edf483d5b975aa40b8460cd4bc85d2/src/assets/rust-bio-gray.png" />
        <meta property="og:type" content="website" />

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="src/assets/custom-aaa3e756.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Custom JS scripts for mdbook-pdf PDF generation -->
        <script type='text/javascript'>
            let markAllContentHasLoadedForPrinting = () =>
                window.setTimeout(
                    () => {
                        let p = document.createElement('div');
                        p.setAttribute('id', 'content-has-all-loaded-for-mdbook-pdf-generation');
                        document.body.appendChild(p);
                    }, 100
                );

            window.addEventListener('load', () => {
                // Expand all the <details> elements for printing.
                r = document.getElementsByTagName('details');
                for (let i of r)
                    i.open = true;

                try {
                    MathJax.Hub.Register.StartupHook('End', markAllContentHasLoadedForPrinting);
                } catch (e) {
                    markAllContentHasLoadedForPrinting();
                }
            });
        </script>
    <div style="display: none"><a href="#prefix-bioinformatics_with_rust">prefix-bioinformatics_with_rust</a><a href="#prefix-introduction">prefix-introduction</a><a href="#prefix-why_rust">prefix-why_rust</a><a href="#prefix-about_ai">prefix-about_ai</a><a href="#prefix-prerequisites">prefix-prerequisites</a><a href="#main-getting_started-getting_started">main-getting_started-getting_started</a><a href="#main-rust_basics-rust_basics">main-rust_basics-rust_basics</a><a href="#main-rust_basics-create_a_project">main-rust_basics-create_a_project</a><a href="#main-rust_basics-syntax">main-rust_basics-syntax</a><a href="#main-rust_basics-keywords">main-rust_basics-keywords</a><a href="#main-rust_basics-macros">main-rust_basics-macros</a><a href="#main-rust_basics-data_types">main-rust_basics-data_types</a><a href="#main-rust_basics-strings">main-rust_basics-strings</a><a href="#main-rust_basics-array">main-rust_basics-array</a><a href="#main-rust_basics-vec">main-rust_basics-vec</a><a href="#main-rust_basics-control_flow">main-rust_basics-control_flow</a><a href="#main-rust_basics-references">main-rust_basics-references</a><a href="#main-rust_basics-functions">main-rust_basics-functions</a><a href="#main-rust_basics-enums">main-rust_basics-enums</a><a href="#main-rust_basics-structs">main-rust_basics-structs</a><a href="#main-rust_basics-option_and_result">main-rust_basics-option_and_result</a><a href="#main-rust_basics-error_handling">main-rust_basics-error_handling</a><a href="#main-rust_basics-ownership_and_borrowing">main-rust_basics-ownership_and_borrowing</a><a href="#main-rust_basics-lifetimes">main-rust_basics-lifetimes</a><a href="#main-rust_basics-iterator_chaining">main-rust_basics-iterator_chaining</a><a href="#main-rust_basics-multi_threading">main-rust_basics-multi_threading</a><a href="#main-rust_basics-trait_bounds_and_generics">main-rust_basics-trait_bounds_and_generics</a><a href="#main-rust_basics-smart_pointers">main-rust_basics-smart_pointers</a><a href="#main-file_formats-introduction">main-file_formats-introduction</a><a href="#main-file_formats-fasta">main-file_formats-fasta</a><a href="#main-file_formats-fastq">main-file_formats-fastq</a><a href="#main-phred_score-introduction">main-phred_score-introduction</a><a href="#main-phred_score-calculating_mean">main-phred_score-calculating_mean</a><a href="#main-nucleotides-nucleotides">main-nucleotides-nucleotides</a><a href="#main-nucleotides-representations">main-nucleotides-representations</a><a href="#main-nucleotides-counting">main-nucleotides-counting</a><a href="#main-nucleotides-gc_content">main-nucleotides-gc_content</a><a href="#main-nucleotides-homopolymers">main-nucleotides-homopolymers</a><a href="#main-nucleotides-entropy">main-nucleotides-entropy</a><a href="#main-nucleotides-manipulating">main-nucleotides-manipulating</a><a href="#main-nucleotides-compression">main-nucleotides-compression</a><a href="#main-nucleotides-reverse_complement">main-nucleotides-reverse_complement</a><a href="#main-nucleotides-nucleotide_encoding">main-nucleotides-nucleotide_encoding</a><a href="#main-alignment-basics_of_alignment">main-alignment-basics_of_alignment</a><a href="#main-alignment-hamming_distance">main-alignment-hamming_distance</a><a href="#main-alignment-edit_distance">main-alignment-edit_distance</a><a href="#main-alignment-adding_traceback">main-alignment-adding_traceback</a><a href="#main-alignment-smith_waterman">main-alignment-smith_waterman</a><a href="#main-alignment-desktop_app">main-alignment-desktop_app</a><a href="#main-alignment-resources">main-alignment-resources</a><a href="#main-kmers-kmers">main-kmers-kmers</a><a href="#main-kmers-a_first_implementation">main-kmers-a_first_implementation</a><a href="#main-kmers-using_phred_scores">main-kmers-using_phred_scores</a><a href="#main-kmers-bit_shift_encoding">main-kmers-bit_shift_encoding</a><a href="#main-kmers-forward_strand">main-kmers-forward_strand</a><a href="#main-kmers-reverse_strand">main-kmers-reverse_strand</a><a href="#main-kmers-final_implementation">main-kmers-final_implementation</a><a href="#main-kmers-min_frac_hash">main-kmers-min_frac_hash</a><a href="#main-kmers-minimizers">main-kmers-minimizers</a><a href="#main-kmers-syncmers">main-kmers-syncmers</a><a href="#main-advanced_topics-kmers">main-advanced_topics-kmers</a><a href="#main-advanced_topics-simd_vectorization">main-advanced_topics-simd_vectorization</a><a href="#main-kmers-building_a_reverse_index">main-kmers-building_a_reverse_index</a><a href="#main-increasing_performance-introduction">main-increasing_performance-introduction</a><a href="#main-increasing_performance-using_appropriate_data_structures">main-increasing_performance-using_appropriate_data_structures</a><a href="#main-increasing_performance-favor_compile_time">main-increasing_performance-favor_compile_time</a><a href="#main-increasing_performance-multi_threading">main-increasing_performance-multi_threading</a><a href="#main-aminoacids-aminoacids">main-aminoacids-aminoacids</a><a href="#main-aminoacids-translation">main-aminoacids-translation</a><a href="#main-aminoacids-accounting_for_frames">main-aminoacids-accounting_for_frames</a><a href="#main-aminoacids-improving_translation_algorithm">main-aminoacids-improving_translation_algorithm</a><a href="#main-amplicon-introduction">main-amplicon-introduction</a><a href="#main-amplicon-in_silico_pcr">main-amplicon-in_silico_pcr</a><a href="#main-amplicon-clustering">main-amplicon-clustering</a><a href="#main-amplicon-classification">main-amplicon-classification</a><a href="#main-blueprints-introduction">main-blueprints-introduction</a><a href="#main-blueprints-argument_parsing">main-blueprints-argument_parsing</a><a href="#main-blueprints-commands">main-blueprints-commands</a><a href="#main-blueprints-dataframes">main-blueprints-dataframes</a><a href="#main-blueprints-needletail">main-blueprints-needletail</a><a href="#main-blueprints-bio">main-blueprints-bio</a><a href="#suffix-resources">suffix-resources</a><a href="#suffix-awesome_rust_crates">suffix-awesome_rust_crates</a><a href="#suffix-awesome_bioinformatic_tools">suffix-awesome_bioinformatic_tools</a><a href="#suffix-thank_you">suffix-thank_you</a></div>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "coal";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-815983b3.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-07a46225.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('coal')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Bioinformatics with Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/OscarAspelin95/bioinformatics_with_rust" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="bioinformatics-with-rust"><a class="header" href="#bioinformatics-with-rust">Bioinformatics With Rust</a></h1>
<p>Welcome to Bioinformatics with Rust! An unofficial book aimed at introducing the Rust programming language for bioinformatic applications.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<ul>
<li>
<p>This book is <strong>not</strong> in any way, shape or form, an official introduction to neither the Rust programming language, nor bioinformatics.</p>
<ul>
<li>For a comprehensive introduction to Rust, please visit <a href="#resources-1">resources</a>.</li>
<li>For learning bioinformatics, please visit your favorite university.</li>
</ul>
</li>
<li>
<p>The <strong>purpose</strong> of this book is trifold:</p>
<ul>
<li>Explain common bioinformatic concepts in a (hopefully) clear way.</li>
<li>Showcase some basic Rust implementations from scratch.</li>
<li>Provide examples of awesome open-source Rust crates for bioinformatics.</li>
</ul>
</li>
<li>
<p>Since <code>mdbook</code> is not easily integrated with external Rust crates, the code examples are minimally viable and built with native Rust. Throughout the book, however, examples of GitHub repositories and external Rust crates are provided as a way to showcase more real life applications.</p>
</li>
<li>
<p>We’ll mostly deal with DNA sequences and canonical nucleotides. However, feel free to request additional topics.</p>
</li>
<li>
<p>For any issues related to this book, please file a <a href="https://github.com/OscarAspelin95/bioinformatics_with_rust/issues">GitHub issue</a>.</p>
</li>
<li>
<p>Currently, I’m a single person working on this project. If this project grows, I most likely need help from other people. Contributions are welcome!</p>
</li>
</ul>
<img src="assets/rust-bio-gray.png" class="logo-gray" style="margin-top: 20px; border-radius: 5em;" />
<img src="assets/rust-bio-blue.png" class="logo-blue" style="margin-top: 20px; border-radius: 5em;" />
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="why-rust"><a class="header" href="#why-rust">Why Rust?</a></h1>
<h2 id="the-different-kinds-of-bioinformaticians"><a class="header" href="#the-different-kinds-of-bioinformaticians">The different kinds of bioinformaticians</a></h2>
<p>Bioinformatics encompasses lots of programming languages, from high level languages such as Python and R, to low level languages such as C and C++. The choice of language depends entirely on the target application. Below, I’ll list my interpretation of the different kinds of bioinformaticians I know of:</p>
<ul>
<li>
<p><strong>The tool developer</strong> - usually has a strong background in computer science and writes high-performance, open source tools for others to use. A name that comes to mind is <a href="https://github.com/lh3">Heng Li</a>.</p>
<ul>
<li>Language of choice is usually C or C++.</li>
</ul>
</li>
<li>
<p><strong>The pipeline developer</strong> - has a strong sense of what bioinformatic tools are suitable for which task. They are experts in chaining multiple tools together to create complete pipelines for a given application.</p>
<ul>
<li>Language of choice is usually Python, R and/or Bash, preferably in combination with ChatGPT.</li>
</ul>
</li>
<li>
<p><strong>The yak-shaver</strong> - is interested in the details of things. Does not hesitate to spend weeks or months building custom databases and reading through literature. Usually starts digging into things and has troubles stopping.</p>
<ul>
<li>Language of choice is usually Python and/or Bash.</li>
</ul>
</li>
<li>
<p><strong>The jack-of-all-trades</strong> - has no prominent strengths nor weaknesses. Good at multi-tasking and knows a bit about everything. Might not have the strongest background in bioinformatics or programming, but has very high versatility.</p>
<ul>
<li>Language of choice is whatever gets the job done.</li>
</ul>
</li>
</ul>
<h2 id="where-the-rust-programming-language-fits-in"><a class="header" href="#where-the-rust-programming-language-fits-in">Where the Rust programming language fits in</a></h2>
<p>In my own experience, programming is complex and difficult. In addition, there are almost countless programming languages to choose from, each with their own pros and cons.</p>
<p>Traditionally, C and C++ have been used to write high-performance code because they are low level languages. You have to manage a lot of things, such as memory, manually. However, this comes with the advantage of experienced developers being able to write blazingly fast programs.</p>
<p>There is a fundamental problem with manual memory management - it is easy to introduce bugs and security vulnerabilities that can be hard to debug. This can be detrimental for performance-critical applications. Check out this <a href="https://security.googleblog.com/2024/10/safer-with-google-advancing-memory.html">blogpost</a> as an example.</p>
<p>What is different about Rust? It prioritizes <a href="https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html">memory safety</a> in order to reduce the accidental introduction of bugs and security vulnerabilities, whilst maintaining high performance. In my opinion (coming from a Python background), this comes with a cost of added complexity. I would like to reference my favorite quote from some random person on the internet:</p>
<p><q><em>The Rust compiler is stricter than my high school chemistry teacher.</em></q></p>
<p>When I started learning Rust, I’d agree with this statement. However, today I’d say it is a blessing rather than a curse.</p>
<p>To conclude, use Rust for bioinformatics if:</p>
<ul>
<li>You are interested in learning a low level, high performance language for bioinformatic applications.</li>
<li>You want to create memory safe and performance critical bioinformatic pipelines.</li>
<li>You want to traverse a steep learning curve, especially if coming from the Python world.</li>
</ul>
<h2 id="why-not-python"><a class="header" href="#why-not-python">Why Not Python?</a></h2>
<p>Traditionally, Python has been used as a wrapper around bioinformatic software to generate capable pipelines with great success. If this is your only intent, it makes sense to stick to Python. It is easy to learn and has a straightforward syntax.</p>
<p>However, as soon as one diverges from this and aims for implementing any sort of high-performance library, Python is not your friend. It is usually too slow, even though libraries such as pandas (which is basically C in disguise) improve runtimes. Sure, one can use the C interoperability interface but this is a bit cumbersome and not inherently memory safe.</p>
<h2 id="bioinformatic-tools-written-in-rust"><a class="header" href="#bioinformatic-tools-written-in-rust">Bioinformatic tools written in Rust</a></h2>
<p>Finally, I just want to give a quick shoutout to some awesome bioinformatic tools written in Rust. There is actually quite a lot of bioinformatics-related crates available, but here are some of my favorites:</p>
<ul>
<li><a href="http://docs.rs/bio/latest/bio/">Bio</a> - General purpose bioinformatic tool for alignment, file processing and much more.</li>
<li><a href="https://github.com/bluenote-1577/sylph">Sylph</a> - Metagenomic classification tool.</li>
<li><a href="https://github.com/nextstrain/nextclade">NextClade</a> - Virus specific tool for alignment, SNP calling, clade assignment and more.</li>
</ul>
<p>For a more exhaustive list, see <a href="#awesome-bioinformatic-tools">resources</a>.</p>
<h2 id="alternatives-to-rust"><a class="header" href="#alternatives-to-rust">Alternatives To Rust</a></h2>
<p>We’ll finish this chapter off with listing some alternative programming languages, outside of Rust, that have been shown to work well within bioinformatics.</p>
<ul>
<li><code>C/C++</code> - Lots of bioinformatic software (dare I say the majority?) is written in C and C++. Some examples that come to mind are <a href="https://github.com/lh3/minimap2">Minimap2</a>, <a href="https://github.com/freebayes/freebayes">Freebayes</a> and <a href="https://github.com/mikolmogorov/Flye">Flye</a>.</li>
<li><code>Go</code> - Believe it or not, the fastx toolkit <a href="https://github.com/shenwei356/seqkit">Seqkit</a> is actually written in Go.</li>
<li><code>Python</code> - Despite its downsides, there are some high performance bioinformatic applications written in Python (with C interoperability) such as <a href="https://github.com/marcelm/cutadapt/">Cutadapt</a>. This also includes machine learning modules such as <a href="https://github.com/nanoporetech/medaka">Medaka</a>.</li>
<li><code>Perl</code> - Yes you read that right. Perl might have been voted one of the ugliest programming languages; regardless, there is at least one awesome tool <a href="https://github.com/tseemann/samclip">SAMclip</a> that makes the list.</li>
<li><code>Zig</code> - There might not be many existing bioinformatic tools written in Zig (yet), but due to its cross compilation functionality with C, I expect we’ll see much more of this language in the coming years.</li>
<li><code>Mojo</code> - If I were to bet my money on any programming language becoming the go-to for bioinformatics, Mojo would be it. Designed to be a superset of Python (similar to what TypeScript is to JavaScript) whilst having similar performance to C and Rust, but with an intuitive GPU acceleration support, Mojo seems particularly promising within the field of bioinformatics.</li>
<li><code>R</code> - If you want a slow language, R is the way to go. With that said, there are seemingly endless R-packages for various bioinformatic applications, such as transcriptomics and metabolomics. In addition, it is actually awesome for generating beautiful plots with <a href="https://ggplot2.tidyverse.org/">ggplot2</a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="about-ai"><a class="header" href="#about-ai">About AI</a></h1>
<p>I want to start this section by stating that I strongly opted out of vibe-coding this project. If I did, I’d probably been done in a day or two. Instead, I chose the proper (and difficult) path of trying things out, failing, swearing, reading documentation and finally (somewhat) understanding. This probably means there are some text and code-snippets in this book that are not 100% correct. I’m okay with that, because it means there is room for improvement.</p>
<p>With that said, I <em>have</em> used AI as a tool for the following:</p>
<ul>
<li>Asking questions about my code to find potential bugs, weaknesses and edge cases.</li>
<li>Explain Rust concepts that I did not fully understand (such as declarative macros).</li>
<li>Asking for suggestions on performance improvements and implemented them only if I can understand why it makes the code more performant.</li>
<li>Sometimes to check for spelling and grammar as well as fixing logical and factual inconsistencies.</li>
</ul>
<h2 id="the-future-of-ai"><a class="header" href="#the-future-of-ai">The Future of AI</a></h2>
<p>My take on AI is that we are in a hype at the moment. I think that the hype might not live up to the expectations. In recent time, we have seen multiple disappointing releases of models and agents from companies that drive the AI train.</p>
<p>Ultimately, I don’t think AI is bad. It can be incredibly useful. What I do think is that people are using it incorrectly. Multiple news channels have reported a MIT report, showing that 95% of organizations gain zero return using tools such as ChatGPT and Copilot. The report also shows that the primary productivity gain is on the individual level and not necessarily on large scale.</p>
<p>With that said, Claude is very, very good at writing lots of code.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h1>
<p>If you have never heard of programming or bioinformatics, this book is probably not for you.</p>
<p>If you have a lot of experience with both Rust and bioinformatics, this book is also probably not for you (and you probably have more knowledge than me, consider becoming a contributor!).</p>
<p>However, if you know a bit about bioinformatics and have worked with programming languages such as Python or C++ then this book will give you an introduction to the Rust ecosystem for building bioinformatic pipelines!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>First and foremost, we need to install Rust and its package manager Cargo. The easiest way to do this is to use <a href="https://rustup.rs/">Rustup</a> and follow the installation instructions.</p>
<p>Second, we need a code editor. If you want to make your life a living hell, you can use notepad. However, then we are missing some important stuff, like syntax highlighting, code formatting and much more. Here are some examples of code editors that can get the job done:</p>
<ul>
<li><a href="https://code.visualstudio.com/">VScode</a> - Easy to use with lots of plugins to make your life easier.</li>
<li><a href="https://zed.dev/">Zed</a> - A text editor written in Rust!</li>
<li><a href="https://www.vim.org/">Vim</a> - For hardcore programmers.</li>
<li><a href="https://neovim.io/">NeoVim</a> - For modern, hardcore programmers.</li>
</ul>
<p>Personally, I prefer Zed. It is fast and has first-class support for Rust.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="rust-basics"><a class="header" href="#rust-basics">Rust Basics</a></h1>
<p>Even though I stated that this book wouldn’t include an introduction to Rust, here we are. This chapter only covers some of the basics and the reader is strongly encouraged to visit <a href="#resources-1">resources</a> for a more comprehensive take on Rust.</p>
<p>Below is a summary of some of the things I personally like and dislike with Rust. This might give the reader some insight into whether or not Rust would be a suitable language for them.</p>
<h2 id="why-i-like-rust"><a class="header" href="#why-i-like-rust">Why I like Rust</a></h2>
<ul>
<li>
<p><strong>The Rust Compiler Is Amazing</strong>. The error messages it produces actually teaches you about Rust and why you cannot do certain things. It even gives you suggestions on how to make changes to your code to make it work correctly.</p>
</li>
<li>
<p><strong>Declarative Mutability</strong>. Variables that are not declared with the <code>mut</code> keyword are immutable, meaning that they cannot change (disregarding interior mutability, which won’t be covered here).</p>
</li>
<li>
<p><strong>Fast Growing Community</strong>. There are endless Rust crates available at <a href="https://crates.io/">crates.io</a>, some of which will make your Rust programming journey much more enjoyable.</p>
</li>
<li>
<p><strong>Cargo</strong>. It just works. Install a crate? Use <code>cargo install</code>. Run your code? Use <code>cargo run</code>.</p>
</li>
</ul>
<h2 id="why-i-dislike-rust"><a class="header" href="#why-i-dislike-rust">Why I dislike Rust</a></h2>
<ul>
<li>
<p><strong>Compile Times</strong>. Compared to languages such as Go, Rust takes ages to compile. This is especially true when the dependencies are piling up.</p>
</li>
<li>
<p><strong>Verbose Syntax</strong>. In my personal opinion, Rust is a rather verbose language. Some people might like that, some people don’t. Luckily, the rust-analyzer VScode extension helps out a lot with auto-completion and other neat features.</p>
</li>
<li>
<p><strong>Steep Learning Curve</strong>. Coming from the Python world, I had a really difficult time with Rust in the beginning. It was not just switching to a compiled language, but also having to learn about lifetimes, ownership and so on. But trust me, it gets easier.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="create-a-project"><a class="header" href="#create-a-project">Create a Project</a></h1>
<p>Time to start! Enter your favorite directory and run <code>cargo new my_rust_project</code>. In the generated directory, you’ll see one file <code>Cargo.toml</code> and one directory <code>src</code>.</p>
<p><code>Cargo.toml</code> is where all of your dependencies go. For more information, visit the <a href="https://doc.rust-lang.org/cargo/reference/manifest.html">official reference</a>.</p>
<p><code>src</code> is where all of your Rust scripts go. For now, we only have <code>main.rs</code>, which is the entrypoint to the program.</p>
<p>Use <code>cargo run</code> to compile and run the program. It should output <q>Hello, world!</q>. The <code>main.rs</code> file is very basic and should look something like this:</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    println!("Hello, world!");
}</code></pre>
<p>Note that we must have a <code>main()</code> function, otherwise it won’t compile.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="syntax"><a class="header" href="#syntax">Syntax</a></h1>
<p>The Rust syntax is similar to other languages such as C and C++. However, here is a brief overview.</p>
<h3 id="variable-declaration"><a class="header" href="#variable-declaration">Variable declaration</a></h3>
<p>Rust is a statically typed language, which means that the type of a variable needs to be known, either explicitly or implicitly. The basic syntax for variable declaration is <code>let name: type = value;</code>. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: usize = 0; // unsigned integer.
    let x: &amp;str = "Hello, world!"; // string slice.
    let x: String = "Hello, world!".to_string(); // string.
    let x: &amp;[u8] = b"Hello, world!"; // byte slice.
    let x: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5]; // vec.
}</code></pre>
<h3 id="scopes"><a class="header" href="#scopes">Scopes</a></h3>
<p><code>{</code> and <code>}</code> define scopes. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() { // start of function scope.
    println!("Hello, world!");
} // end of function scope.</code></pre>
<p>We can also have nested scopes. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: &amp;str = "Hello, world!";

    {
        println!("{x}");
    }
}</code></pre>
<p>Scopes are important for ownership and lifetimes, which will be covered later on.</p>
<h3 id="statement-delimiters"><a class="header" href="#statement-delimiters">Statement delimiters</a></h3>
<p><code>;</code> is used for statement delimiters. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    println!("Hello, world!"); // Defines the println! statement.
} // does not need a ";".</code></pre>
<p>Note that scopes do not need a <code>;</code> terminator.</p>
<h3 id="comments"><a class="header" href="#comments">Comments</a></h3>
<p><code>//</code> is used for code comments.<br>
<code>///</code> is used for docstrings.</p>
<pre class="playground"><code class="language-rust edition2024">/// This is a docstring.
fn main() {
    // This is a comment.
    println!("Hello, world");
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="keywords"><a class="header" href="#keywords">Keywords</a></h1>
<p><code>use</code> - is used for importing. E.g., <code>use std::num::ParseIntError</code></p>
<p><code>let</code> - initializes something immutable. E.g., <code>let x: usize = 10;</code></p>
<p><code>mut</code> - makes something mutable. E.g., <code>let mut x: usize = 10;</code></p>
<p><code>fn</code> - defines a function. This is analogous to Python’s <code>def</code> keyword. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    println!("Hello, world!");
}</code></pre>
<p><code>struct</code> - defines a struct. This is kind of analogous to <code>class</code> in Python. E.g.,</p>
<pre><code class="language-rust noplayground">struct MyStruct {
    field1: usize,
    field2: f32,
    field3: bool,
}</code></pre>
<p><code>enum</code> - defines an enum. This is kind of analogous to <code>Enum</code> in Python. E.g.,</p>
<pre><code class="language-rust noplayground">enum MyEnum {
    Choice1,
    Choice2,
    Choice3,
}</code></pre>
<p><code>pub</code> - makes something like a function or struct public, meaning that other Rust files can access them. E.g.,</p>
<pre><code class="language-rust noplayground">pub struct MyStruct {
    field1: usize,
    field2: f32,
    field3: bool,
}</code></pre>
<p><code>loop</code> - creates an infinite loop until a <code>break</code> statement is encountered. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let mut x: usize = 0;

    loop{
        x += 1;

        println!("{x}");

        if x &gt;= 5{
            break;
        }
    }
}</code></pre>
<p><code>for</code> - creates a loop over an iterator. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    for i in (0..5){
        println!("{i}");
    }
}</code></pre>
<p><code>while</code> - creates a loop that keeps running as long as its condition is true. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let mut x: usize = 0;

    while x &lt;= 5 {
        println!("{x}");
        x += 1;
    }
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="macros"><a class="header" href="#macros">Macros</a></h1>
<p>Macros should have a dedicated book to themselves. Rust supports both declarative and procedural <a href="https://doc.rust-lang.org/book/ch20-05-macros.html">macros</a>, which are either built-in or user created. In this book, we’ll cover some of the most common built-in macros.</p>
<p>For more information about Rust macros, also see <a href="https://lukaswirth.dev/tlborm/">The Little Book of Rust Macros</a></p>
<h2 id="declarative-macros"><a class="header" href="#declarative-macros">Declarative macros</a></h2>
<p><a href="https://doc.rust-lang.org/std/macro.println.html"><code>println!</code></a> - prints to stdout. Requires a formatter depending on the data type. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    println!("This is a string");
    println!("This is an int: {}", 5);
    println!("{:?}", vec!["This", "is", "a", "vec"]); // {:?} means debug mode.
}</code></pre>
<p><a href="https://doc.rust-lang.org/std/macro.vec.html"><code>vec!</code></a> - creates a <code>Vec</code> based on the provided input.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];
    println!("{:?}", x);
}</code></pre>
<p><a href="https://doc.rust-lang.org/rust-by-example/std/panic.html"><code>panic!</code></a> - causes the program to exit and starts unwinding the stack.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    panic!("This will exit the program!")
}</code></pre>
<p><a href="https://doc.rust-lang.org/std/macro.assert.html"><code>assert!</code></a> - runtime assert that a boolean expression evaluates to <code>true</code>. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    assert!(5 &lt; 6);
}</code></pre>
<p><a href="https://doc.rust-lang.org/std/macro.assert_eq.html"><code>assert_eq!</code></a> - runtime equality assert. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    assert_eq!(6, 5 + 1);
}</code></pre>
<h3 id="implementing-our-own-declarative-macro"><a class="header" href="#implementing-our-own-declarative-macro">Implementing our own declarative macro</a></h3>
<p>I want to emphasize that I personally do not know that much about Rust macros. However, in this example we’ll try to implement something that resembles Python’s <code>Path</code>, which is a part of the <code>Pathlib</code> module. Using <code>Path</code>, there is a very handy way to define a file path by chaining multiple directories.</p>
<pre><code class="language-python">from pathlib import Path

outdir = Path("my_outdir")
outfile = outdir / "sub_dir" / "another_sub_dir" / "my_file.txt"
</code></pre>
<p>Essentially, if the top directory <code>outdir</code> is of type <code>Path</code>, we can generate a file path through <code>/</code>. Personally, I think this is way more neat than having to use an f-string or similar. Let’s try to implement something similar using a Rust declarative macro.</p>
<p>There are endless ways of implementing this, but below is one example. We’ll define our macro <code>file_path</code> to require a base directory and at least one more argument. The syntax is a bit strange. It kinda looks like a function, but kinda not.</p>
<p>The <a href="https://doc.rust-lang.org/reference/expressions.html">expression</a> <code>($base:expr $(, $sub:expr)+)</code> defines the pattern that we enforce. In this case, we require one expression <code>$base</code>, followed by one or more comma-separated expressions <code>$sub</code>.</p>
<p>We use import statements with a leading <code>::</code> to signify that we want the root crate <code>std</code> to not accidentally use some locally defined crate called <code>std</code>.</p>
<p>Finally, we create a <code>PathBuf</code> from our base dir and iteratively build up the path.</p>
<pre class="playground"><code class="language-rust edition2024">use std::path::PathBuf;

macro_rules! file_path {
    ($base:expr $(, $sub:expr)+) =&gt; {{
        use ::std::path::PathBuf;
        use ::std::fs;

        let mut full_path = PathBuf::from($base);

        $(
            full_path.push($sub);
        )*

        full_path
    }};
}

fn main(){

    let outdir = "my_outdir".to_string();
    let outfile = file_path!(outdir, "sub_dir", "another_sub_dir", "my_file.txt");

    println!("{:?}", outfile);
}</code></pre>
<p>The point with the simple example above is not to generate a bullet proof, production ready macro but rather showcase that declarative macros can be very handy for defining custom behaviors. If we’d try to implement <code>file_path</code> as a function, we’d probably have to handle the variable number of sub-directories through a <code>Vec</code> or similar.</p>
<h2 id="procedural-macros"><a class="header" href="#procedural-macros">Procedural macros</a></h2>
<p>Are divided into three categories, all of which are outside the scope of this book. Regardless, they are very handy for deriving traits, such as <code>Debug</code>. As an example, assume we’ve created a <code>Struct</code> that we’d want to be able to print to stdout using <code>println!</code>. In this case, we need to derive the <code>Debug</code> trait through <code>#[derive(Debug)]</code>.</p>
<pre class="playground"><code class="language-rust editable edition2024">#[derive(Debug)] // Try commenting out this line!
struct MyStruct{
    my_vec: Vec&lt;usize&gt;,
}

fn main() {
    let my_struct = MyStruct { my_vec: vec![1, 2, 3, 4, 5] };

    println!("{:?}", my_struct);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="data-types"><a class="header" href="#data-types">Data Types</a></h1>
<p>Rust has a lot of <a href="https://doc.rust-lang.org/book/ch03-02-data-types.html">data types</a>. Here is a rundown of the ones I use most often:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Data type</th><th>Rust type</th><th>Example</th></tr>
</thead>
<tbody>
<tr><td>boolean</td><td><code>bool</code></td><td><code>let x: bool = true;</code></td></tr>
<tr><td>string</td><td><code>String</code></td><td><code>let x: String = "Hello".to_string();</code></td></tr>
<tr><td>string slice</td><td><code>&amp;str</code></td><td><code>let x: &amp;str = "Hello";</code></td></tr>
<tr><td>array</td><td><code>[type; len]</code></td><td><code>let x: [usize; 3] = [1, 2, 3];</code></td></tr>
<tr><td>vec</td><td><code>Vec&lt;type&gt;</code></td><td><code>let x: Vec&lt;usize&gt; = vec![1, 2, 3];</code></td></tr>
<tr><td>byte slice</td><td><code>&amp;[u8]</code></td><td><code>let x: &amp;[u8] = b"Hello";</code></td></tr>
<tr><td>unsigned 32-bit int</td><td><code>u32</code></td><td><code>let x: u32 = 0;</code></td></tr>
<tr><td>unsigned 64-bit int</td><td><code>u64</code></td><td><code>let x: u64 = 0;</code></td></tr>
<tr><td>unsigned (32 or 64)<sup class="footnote-reference" id="fr-note-1"><a href="#footnote-note">1</a></sup>-bit int</td><td><code>usize</code></td><td><code>let x: usize = 0;</code></td></tr>
<tr><td>32-bit float</td><td><code>f32</code></td><td><code>let x: f32 = 0.0;</code></td></tr>
<tr><td>64-bit float</td><td><code>f64</code></td><td><code>let x: f64 = 0.0;</code></td></tr>
</tbody>
</table>
</div>
<p>For an interactive map of Rust types, please visit <a href="https://rustcurious.com/elements/">RustCurious</a>.</p>
<hr>
<ol class="footnote-definition">
<li id="footnote-note">
<p>Depends on computer architecture. <a href="#fr-note-1">↩</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="strings"><a class="header" href="#strings">Strings</a></h1>
<p>There are multiple string types in Rust. Two of the ones I use most often are <code>String</code> and <code>&amp;str</code>.</p>
<p><code>String</code> is an owned, mutable and heap-allocated type. We can allow it to be mutable with the <code>mut</code> keyword. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let mut seq: String = "ATCG".to_string();
    seq.push_str("ATCG"); // Mutate.

    assert_eq!(seq, "ATCGATCG".to_string());
}</code></pre>
<p><code>&amp;str</code> is a borrowed and immutable type. We can read from it, but cannot mutate it. <code>&amp;str</code> is suitable when one wants to avoid heap-allocation.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let seq: &amp;str = "ATCG";

    println!("{seq}");
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="array"><a class="header" href="#array">Array</a></h1>
<p>Arrays in Rust are fixed size that need to be known at compile time. In bioinformatic applications, we can use an array as a lookup table for nucleotide encoding, which we’ll see in later chapters.</p>
<p>If we declare the array as mutable, we can change its values but not its size.</p>
<pre class="playground"><code class="language-rust edition2024">fn main(){
    let mut arr: [usize; 5] = [1, 2, 3, 4, 5];

    for i in (0..arr.len()){
        arr[i] = arr[i] * 2;
    }

    assert_eq!(arr, [2, 4, 6, 8, 10]);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="vec"><a class="header" href="#vec">Vec</a></h1>
<p>A <code>Vec</code> is like an array type with dynamic size. There are two common ways to initialize a <code>Vec</code>, either through the <code>vec!</code> macro, or through <code>Vec::new()</code>.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    // Create an empty vec.
    let mut my_vec: Vec&lt;usize&gt; = Vec::new();

    my_vec.push(1);

    assert_eq!(my_vec, vec![1]);
}</code></pre>
<p>We can also collect an iterator into a <code>Vec</code>, which is very convenient.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let my_iterator = 1..5;

    let my_vec: Vec&lt;usize&gt; = my_iterator.collect();

    assert_eq!(my_vec, vec![1, 2, 3, 4]); // my_iterator is right exclusive.
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="control-flow"><a class="header" href="#control-flow">Control Flow</a></h1>
<p>An <code>if</code> statement works very similar to other languages. E.g.,</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: usize = 5;

    if x &gt;= 10 {
        println!("{x} is large");
    }
    else {
        println!("{x} is small");
    }
}</code></pre>
<p>A <a href="https://doc.rust-lang.org/book/ch06-02-match.html"><code>match</code></a> statement works similarly to a <code>switch</code> statement in C and C++ and needs to be exhaustive.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: usize = 1;

    match x {
        1 =&gt; println!("x is 1"),
        2 =&gt; println!("x is 2"),
        _ =&gt; println!("x is something else"),
    }
}</code></pre>
<p>Rust supports relatively advanced <a href="https://doc.rust-lang.org/book/ch19-03-pattern-syntax.html">pattern matching</a> which is extremely useful.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="references"><a class="header" href="#references">References</a></h1>
<p>References in Rust are different from pointers in languages such as C and C++. In Rust, references are always valid and cannot be null. Use <code>&amp;</code> to reference a variable, and <code>*</code> to dereference.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let my_vec: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    println!("{:?}", &amp;my_vec); // Pass my_vec as a reference to the println! macro.
}</code></pre>
<p>References are useful for passing variables to other functions without needing to clone the data. In the following example below, we’ll create a <code>Vec</code> and then pass it by reference to a function. Note the syntax here, we actually don’t pass a reference <code>&amp;Vec&lt;usize&gt;</code>. We could, but a more idiomatic approach (in my opinion) is to pass a slice instead.</p>
<pre class="playground"><code class="language-rust edition2024">fn print_a_vec(x: &amp;[usize]) {
    println!("{:?}", x);
}

fn main() {
    let my_vec: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    print_a_vec(&amp;my_vec[..]);
}</code></pre>
<p>There is an important rule when it comes to references, which I’ll quote from the official Rust <a href="https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html">book</a>:</p>
<p><q><em>At any given time, you can have either one mutable reference or any number of immutable references.</em></q></p>
<p>This makes perfect sense when you think about it. If we are able to mutate a variable, we do not want a bunch of read-only references with unpredictable values when read.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="functions"><a class="header" href="#functions">Functions</a></h1>
<p>As we saw earlier, a function is defined with <code>fn</code>.</p>
<pre class="playground"><code class="language-rust edition2024">fn main(){
    println!("Hello, world!");
}</code></pre>
<p>To define a function that takes arguments, we need to define the argument names and types.</p>
<pre class="playground"><code class="language-rust edition2024">fn my_function(a: usize, b: usize) {
    println!("Arguments are {a} and {b}");
}

fn main() {
    let a: usize = 1;
    let b: usize = 2;

    my_function(a, b);
}</code></pre>
<p>We also need to take into consideration if we are passing values as references and whether or not they are mutable. In the example below, we define a <code>Vec</code> as mutable and pass it by reference to a function <code>mutate_vec</code>. In order for this to work, the argument type of <code>mutate_vec</code> must be <code>&amp;mut Vec&lt;usize&gt;</code> to signify that we are passing a mutable <code>Vec</code> by reference. We call <code>mutate_vec</code> from the main function with <code>&amp;mut my_vec</code> to match the defined argument type <code>&amp;mut Vec&lt;usize&gt;</code>.</p>
<pre class="playground"><code class="language-rust edition2024">fn mutate_vec(a: &amp;mut Vec&lt;usize&gt;) {
    a[0] = 10;

    println!("{:?}", a);
}

fn main() {
    let mut my_vec: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    mutate_vec(&amp;mut my_vec);
}</code></pre>
<p>Finally, we’ll also add a return type, which is done with <code>-&gt;</code> in the function signature. In this example, we mutate the <code>Vec</code> inside <code>mutate_vec</code>, return a mutable reference to it and mutate it again.</p>
<pre class="playground"><code class="language-rust edition2024">fn mutate_vec(a: &amp;mut Vec&lt;usize&gt;) -&gt; &amp;mut Vec&lt;usize&gt; {
    a[0] = 10;

    return a;
}

fn main() {
    let mut my_vec: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    let mut my_mutated_vec: &amp;mut Vec&lt;usize&gt; = mutate_vec(&amp;mut my_vec);

    my_mutated_vec[0] = 20;
    println!("{:?}", my_mutated_vec);

}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="enums"><a class="header" href="#enums">Enums</a></h1>
<p>Rust enums are awesome and also extremely useful, especially in match statements. Assume we have implemented three different alignment functions: local, semi-global and global. We can use an enum as input to decide what alignment function to run for a given query and subject:</p>
<pre class="playground"><code class="language-rust edition2024">enum AlignmentType {
    Local,
    SemiGlobal,
    Global,
}

#[allow(unused)]
fn local_alignment(query: &amp;str, subject: &amp;str){
    println!("Running local alignment...");
}

#[allow(unused)]
fn semi_global_alignment(query: &amp;str, subject: &amp;str){
    println!("Running semi-global alignment...");
}

#[allow(unused)]
fn global_alignment(query: &amp;str, subject: &amp;str){
    println!("Running global alignment...");
}


fn align(query: &amp;str, subject: &amp;str, alignment_type: AlignmentType) {
    match alignment_type {
        AlignmentType::Local =&gt; local_alignment(query, subject),
        AlignmentType::SemiGlobal =&gt; semi_global_alignment(query, subject),
        AlignmentType::Global =&gt; global_alignment(query, subject),
    }
}

fn main(){
    align("ATCG", "ATCG", AlignmentType::Local);
    align("ATCG", "ATCG", AlignmentType::SemiGlobal);
    align("ATCG", "ATCG", AlignmentType::Global);
}</code></pre>
<p>Another use case of enums could be if we have an alignment between two sequences for which we want to calculate an alignment score. We could create an alignment type enum that is associated with increasing or decreasing an alignment score.</p>
<pre class="playground"><code class="language-rust edition2024">enum AlignmentCost {
    Match(usize),
    Mismatch(usize),
    DeletionQuery(usize),
    DeletionSubject(usize),
}

fn update_score(score: &amp;mut i32, alignment_cost: AlignmentCost) {
    match alignment_cost {
        AlignmentCost::Match(c) =&gt; {
            *score += c as i32;
        }
        AlignmentCost::Mismatch(c) =&gt; {
            *score -= c as i32;
        }
        AlignmentCost::DeletionQuery(c) =&gt; {
            *score -= c as i32;
        }
        AlignmentCost::DeletionSubject(c) =&gt; {
            *score -= c as i32;
        }
    };
}

fn main() {
    let mut score: i32 = 0;
    println!("Initial score: {score}");

    // Match will increase the score.
    update_score(&amp;mut score, AlignmentCost::Match(4));
    println!("Score after match: {score}");

    // Mismatch will decrease the score.
    update_score(&amp;mut score, AlignmentCost::Mismatch(1));
    println!("Score after mismatch: {score}");

    // Query deletion will decrease the score.
    update_score(&amp;mut score, AlignmentCost::DeletionQuery(1));
    println!("Score after query deletion: {score}");

    // Subject deletion will decrease the score.
    update_score(&amp;mut score, AlignmentCost::DeletionSubject(1));
    println!("Score after subject deletion: {score}");
}</code></pre>
<p>This is a pretty silly example, but showcases how enums are very convenient for handling and taking action based on a specific set of cases.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="structs"><a class="header" href="#structs">Structs</a></h1>
<p>Implementing structs in Rust is a bit different from languages such as Python. In Python, we have the excellent <a href="https://docs.pydantic.dev/latest/">Pydantic</a> module for data validation and other awesome features. In Rust, we can use something like the <a href="https://docs.rs/validify/latest/validify/">Validify</a> crate, however in this book we won’t bother much with validation.</p>
<p>Pretend we have a fastq parser for filtering and trimming reads. However, we want to change the filtering and trimming parameters based on sequencing platform. Maybe we want different behavior depending on if our data originated from PacBio or Oxford Nanopore. An example of this would be to implement a default function based on a provided platform:</p>
<pre class="playground"><code class="language-rust edition2024">enum Platform {
    PacBio,
    Nanopore,
}

#[allow(unused)]
#[derive(Debug)]
struct Parameters {
    min_len: usize,
    max_len: usize,
    min_phred: usize,
}

impl Parameters {
    fn default(platform: Platform) -&gt; Self {
        match platform {
            Platform::PacBio =&gt; Self {
                min_len: 100,
                max_len: 1000,
                min_phred: 20,
            },
            Platform::Nanopore =&gt; Self {
                min_len: 200,
                max_len: 900,
                min_phred: 15,
            },
        }
    }
}

fn main() {
    let pacbio_parameters = Parameters::default(Platform::PacBio);
    println!("PacBio: {:?}", pacbio_parameters);

    let nanopore_parameters = Parameters::default(Platform::Nanopore);
    println!("Nanopore: {:?}", nanopore_parameters);
}</code></pre>
<p>This works, but might not be very idiomatic. Another way is to leverage Rust’s type traits by implementing <code>from</code>. By specifying our variable as type <code>Parameters</code>, we can call <code>.into()</code> directly.</p>
<pre class="playground"><code class="language-rust edition2024"><span class="boring">enum Platform {
</span><span class="boring">    PacBio,
</span><span class="boring">    Nanopore,
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">#[allow(unused)]
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">struct Parameters {
</span><span class="boring">    min_len: usize,
</span><span class="boring">    max_len: usize,
</span><span class="boring">    min_phred: usize,
</span><span class="boring">}
</span>// [...]

impl From&lt;Platform&gt; for Parameters {
    fn from(platform: Platform) -&gt; Self {
        match platform{
            Platform::PacBio =&gt; Self {
                min_len: 100,
                max_len: 1000,
                min_phred: 20,
            },
            Platform::Nanopore =&gt; Self {
                min_len: 200,
                max_len: 900,
                min_phred: 15
            },
        }
    }
}

fn main(){
    let pacbio_parameters: Parameters = Platform::PacBio.into();
    println!("PacBio: {:?}", pacbio_parameters);

    let nanopore_parameters: Parameters = Platform::Nanopore.into();
    println!("Nanopore: {:?}", nanopore_parameters);
}</code></pre>
<p>Again, note that these are just examples that might not be real-world applicable. However, the point here is that structuring the code in certain ways will be of help in the long run.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="option-and-result"><a class="header" href="#option-and-result">Option and Result</a></h1>
<h2 id="option"><a class="header" href="#option">Option</a></h2>
<p>In contrast to Python, there is no <code>None</code> type in Rust. There is, however, something called <a href="https://doc.rust-lang.org/std/option/"><code>Option</code></a>, which is of type <code>Option&lt;T&gt;</code>. An <code>Option&lt;T&gt;</code> can either be <code>Some(T)</code> (there is a value) or <code>None</code> (there is no value). Usually, one would pattern match to extract the value from an <code>Option</code> if it exists.</p>
<pre class="playground"><code class="language-rust edition2024">fn print_value_if_exist(x: Option&lt;usize&gt;) {
    match x {
        Some(value) =&gt; println!("Value is {value}"),
        None =&gt; println!("No value"),
    };
}

fn main() {
    let x: Option&lt;usize&gt; = Some(5);
    print_value_if_exist(x);

    // We can define x have the value None, but
    // its type will always be Option&lt;T&gt;.
    let x: Option&lt;usize&gt; = None;
    print_value_if_exist(x);
}</code></pre>
<h2 id="result"><a class="header" href="#result">Result</a></h2>
<p>Similarly for errors, there is <code>Result</code>, which is of type <code>Result&lt;T, E&gt;</code>. A <code>Result&lt;T, E&gt;</code> can be either <code>Ok(T)</code> or <code>Err(E)</code>, which we can pattern match against.</p>
<pre class="playground"><code class="language-rust edition2024">use std::num::ParseIntError;

fn parse_to_usize(x: &amp;str) {
    let parsed: Result&lt;usize, ParseIntError&gt; = x.parse::&lt;usize&gt;();

    match parsed {
        Ok(number) =&gt; println!("{number}"),
        Err(err) =&gt; println!("{}: {x}", err),
    }
}

fn main() {
    let x: &amp;str = "5";
    parse_to_usize(x);

    let x: &amp;str = "5ab";
    parse_to_usize(x);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h1>
<p>It took a while for me to understand errors in Rust. However, one day, I came across the concept of <a href="https://doc.rust-lang.org/book/ch09-00-error-handling.html">recoverable and non-recoverable</a> errors and that is when everything started making sense.</p>
<p>An <code>unrecoverable</code> error occurs when it makes sense to terminate the code. One example would be failing to read a file because it is corrupt. If our only goal is to parse the file and print its contents, but we cannot even read it, then we’d classify this as an unrecoverable error.</p>
<p>A <code>recoverable</code> error you can think of as when it is still safe or okay to proceed executing code. One example would be parsing lines from a file and one line has an unexpected structure. If we are okay with this, we can just skip this line and proceed to the next.</p>
<p>There are different ways of handling errors, some of which are listed below:</p>
<ul>
<li>
<p><a href="https://doc.rust-lang.org/rust-by-example/std/panic.html"><code>panic!</code></a> - Is a macro that, in single threaded applications, will cause the program to exit.</p>
</li>
<li>
<p><a href="https://doc.rust-lang.org/rust-by-example/error/option_unwrap.html"><code>unwrap</code></a> - Will panic if an <code>Option&lt;T&gt;</code> is <code>None</code> or if a <code>Result&lt;T, Error&gt;</code> is <code>Error</code>.</p>
</li>
<li>
<p><a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.expect"><code>expect</code></a> - Is similar to <code>unwrap</code> but also displays a provided error message on panic.</p>
</li>
<li>
<p><a href="https://doc.rust-lang.org/rust-by-example/std/result/question_mark.html"><code>?</code></a> - Is used for error propagation and can be handled by e.g., upstream functions. This is a very elegant way of handling errors and is preferred over <code>unwrap</code> and <code>expect</code> in real world applications. <code>?</code> must always be inside a function that returns the <code>Result</code> type.</p>
</li>
</ul>
<h2 id="unrecoverable-errors"><a class="header" href="#unrecoverable-errors">Unrecoverable errors</a></h2>
<p>In the code snippet below, we try to open a file that does not exist. Using <code>.expect()</code> will cause a panic, but this is okay because we allow this to be an unrecoverable error.</p>
<pre class="playground"><code class="language-rust edition2024">use std::fs::File;

fn main() {
    let _ = File::open("file_does_not_exist.txt").expect("Failed to open file.");
}</code></pre>
<h2 id="recoverable-errors"><a class="header" href="#recoverable-errors">Recoverable errors</a></h2>
<p>In the following example, we implement a recoverable error for integer division using the <code>?</code> operator. The code looks quite complex for such a simple example, but the general pattern can be applied to other code as well.</p>
<ul>
<li>
<p>We define a custom error type called <code>MathError</code>. We could define multiple <code>MathError</code> types, but in our case, <code>DivisionByZero</code> will suffice.</p>
</li>
<li>
<p>We implement the <code>Display</code> trait for our custom error to avoid having to use <code>Debug</code> print.</p>
</li>
<li>
<p>We implement a function <code>divide</code> that returns a <code>Result</code>, containing either a <code>f32</code>, or a <code>MathError</code>.</p>
</li>
<li>
<p>We implement a function <code>division</code> that uses the <code>?</code> operator. Think of the <code>?</code> as <q>assume no error</q>, then we can return <code>Ok(result)</code>. If <code>result</code> contains an error, the function <code>division</code> will make an early return.</p>
</li>
<li>
<p>In <code>main</code>, we handle the division result accordingly.</p>
</li>
</ul>
<pre class="playground"><code class="language-rust edition2024">#[derive(Debug)]
enum MathError {
    DivisionByZero,
}

impl std::fmt::Display for MathError {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter) -&gt; std::fmt::Result {
        match self {
            MathError::DivisionByZero =&gt; write!(f, "Cannot divide by zero!"),
        }
    }
}

fn divide(a: usize, b: usize) -&gt; Result&lt;f32, MathError&gt; {
    match b {
        0 =&gt; Err(MathError::DivisionByZero),
        _ =&gt; Ok(a as f32 / b as f32),
    }
}

fn division(a: usize, b: usize) -&gt; Result&lt;f32, MathError&gt; {
    let result = divide(a, b)?;

    return Ok(result);
}

fn main() {
    let values: Vec&lt;(usize, usize)&gt; = vec![(1, 1), (1, 0)];

    for (a, b) in values {
        match division(a, b) {
            Ok(r) =&gt; println!("{r}"),
            Err(e) =&gt; println!("{e}"),
        }
    }
}</code></pre>
<p>The takeaway here is that by handling recoverable errors, we avoid crashing our program when it does not need to.</p>
<p>Visit the <a href="https://doc.rust-lang.org/book/ch09-00-error-handling.html">official documentation</a> for error handling to learn more. In addition, there are crates such as <a href="https://docs.rs/anyhow/latest/anyhow/">anyhow</a> and <a href="https://docs.rs/thiserror/latest/thiserror/">thiserror</a> that simplifies the generation of custom error types.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="ownership-and-borrowing"><a class="header" href="#ownership-and-borrowing">Ownership and Borrowing</a></h1>
<p>Ownership can initially be a rather tricky topic to understand. The reader is advised to read the official <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">reference</a> on ownership.</p>
<p>I like to think of ownership in terms of scopes. A variable is valid when it is inside the scope it was defined in. When the scope ends, the variable is dropped from memory. This might not always be true, but this way of thinking simplified the ownership concept for me quite a lot. Consider the following example:</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    // Create a nested scope.
    {
        let x: usize = 0;
        println!("{x}");
    }
}</code></pre>
<p>It is perfectly valid to use <code>println!</code> whilst we are inside the scope, because <code>x</code> is still valid here. Once we move outside of this scope, <code>x</code> is dropped. This means we cannot move our <code>println!</code> outside of the scope where <code>x</code> is defined.</p>
<pre class="playground"><code class="language-rust editable edition2024">fn main() {
    // Create a nested scope.
    {
        let x: usize = 0;
    }

    // try commenting this out!
    // println!("{x}");
}</code></pre>
<p>The same goes for heap-allocated variables that are passed by value (i.e., we are not passing a reference). In the following example, we’ll create a <code>Vec</code> and pass it by value to a function <code>print_vec</code>. As we will see, the Rust compiler won’t let us print the <code>Vec</code> anymore in the main function.</p>
<pre class="playground"><code class="language-rust editable edition2024">fn print_vec(x: Vec&lt;usize&gt;) {
    println!("[print_vec]: {:?}", x);
}


fn main() {
    let x: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    print_vec(x); // x is passed by value here. Ownership is transferred to print_vec.

    // try commenting this out!
    // println!("[main]: {:?}", x);
}</code></pre>
<p>How do we solve this? We can pass <code>x</code> by reference. This way, <code>x</code> is still owned by <code>main</code> and borrowed by <code>print_vec</code>.</p>
<pre class="playground"><code class="language-rust edition2024">fn print_vec(x: &amp;Vec&lt;usize&gt;) {
    println!("[print_vec]: {:?}", x);
}

fn main() {
    let x: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    print_vec(&amp;x); // x is passed by reference here. main still owns x.
    println!("[main]: {:?}", x);
}</code></pre>
<p>What about mutable references? Remember that a variable can only have one mutable reference existing at a given time. If we pass <code>x</code> as a mutable reference to a new function <code>mutate_vec</code>, <code>main</code> still has ownership of <code>x</code> so we are good.</p>
<pre class="playground"><code class="language-rust edition2024">fn mutate_vec(x: &amp;mut Vec&lt;usize&gt;) {
    x[0] = 10;

    println!("[mutate_vec]: {:?}", x);
}

fn main() {
    let mut x: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    mutate_vec(&amp;mut x); // x is passed by (mutable) reference here. main still owns r.
    println!("[main]: {:?}", x);
}</code></pre>
<p>However, we would run into issues if we try dereferencing <code>x</code> inside <code>mutate_vec</code>. In the example below, we try dereferencing <code>x</code> into a variable <code>y</code> inside <code>mutate_vec</code>. This is not allowed because we don’t own <code>x</code>. We have only borrowed it, so we cannot move its value.</p>
<pre class="playground"><code class="language-rust editable edition2024">fn mutate_vec(x: &amp;mut Vec&lt;usize&gt;) {
    x[0] = 10;

    // try commenting this out!
    // let y = *x;

    println!("[mutate_vec]: {:?}", x);
}

fn main() {
    let mut x: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    mutate_vec(&amp;mut x); // x is passed by (mutable) reference here. main still owns r.
    println!("[main]: {:?}", x);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="lifetimes"><a class="header" href="#lifetimes">Lifetimes</a></h1>
<p>The concept of <a href="https://doc.rust-lang.org/rust-by-example/scope/lifetime.html">lifetimes</a> is related to how long variables are valid. Even though lifetimes are a rather complex concept, there are two common cases one has to consider:</p>
<ul>
<li>Variables are dropped at the end of their defined scope.</li>
<li>References might need an explicit lifetime notation.</li>
</ul>
<h2 id="scopes-1"><a class="header" href="#scopes-1">Scopes</a></h2>
<p>By default, variables are dropped at the end of their defined scope.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: usize = 0;
} // x is dropped here.</code></pre>
<p>The example above gets more interesting if we add a nested scope inside <code>main</code>. Try running the code below and see what happens.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    {
        let x: usize = 0;
    } // x is dropped here.

    println!("{x}");
}</code></pre>
<p>The variable <code>x</code> goes out of scope before we try to print it, which is why the compiler complains. Switching the order around by defining <code>x</code> in the outer scope and printing it in the inner scope works, because <code>x</code> is still valid there.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: usize = 0;

    { // x is still valid here.
        println!("{x}");
    }

} // x is dropped here.</code></pre>
<p>The same principle applies to function scopes. Unless we <code>return</code>, variables defined inside a function scope will be dropped at the end.</p>
<pre class="playground"><code class="language-rust edition2024">fn my_function() -&gt; String {
    let x: String = "my_string".to_string();

    // Anything else we define here and don't return
    // will be dropped at the end of the function scope.

    return x;
}

fn main() {
    let x = my_function();

    println!("{x}");
}</code></pre>
<h2 id="lifetime-notation"><a class="header" href="#lifetime-notation">Lifetime notation</a></h2>
<p>To illustrate explicit lifetime notation, we’ll create a <code>Struct</code> with a single field <code>my_string</code>, which is of type <code>&amp;str</code>.</p>
<pre class="playground"><code class="language-rust edition2024">struct MyStruct {
    my_string: &amp;str
}

fn main() {
    let my_struct = MyStruct {my_string: "Hello, world!"};
}</code></pre>
<p>Try running the code and see what happens. We get a compiler error, stating that we need a lifetime parameter. Why is this? <code>my_string</code> is of type <code>&amp;str</code>, which means that <code>MyStruct</code> does not own it. This also means <code>MyStruct</code> does not control when <code>my_string</code> is no longer valid. This is dangerous, because if <code>my_string</code> would get dropped and we subsequently try to read its value in <code>MyStruct</code>, we’d be in trouble. The Rust compiler needs some kind of assurance that <code>MyStruct</code> and <code>my_string</code> will both be valid for at least as long as each other. This is what lifetimes are for.</p>
<p>Lifetimes are signified with a <code>'</code>, followed by a name. E.g., <code>'a</code> would be a lifetime called <code>a</code>. To make the code run, we’ll bind <code>MyStruct</code> and <code>my_string</code> to the same lifetime, telling the Rust compiler that <code>MyStruct</code> will live for at least as long as <code>my_string</code>.</p>
<pre class="playground"><code class="language-rust edition2024">struct MyStruct&lt;'a&gt; {
    my_string: &amp;'a str
}

fn main() {
    let my_struct = MyStruct {my_string: "Hello, world!"};
}</code></pre>
<p>The same concept applies to functions. In the following example, we’ll define a function that takes no arguments and returns a <code>&amp;str</code>.</p>
<pre class="playground"><code class="language-rust edition2024">fn my_function&lt;'a&gt;() -&gt; &amp;'a str{
    let x: &amp;'a str = "my_string";

    return x;
}

fn main() {
    let x = my_function();

    println!("{x}");
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="iterator-chaining"><a class="header" href="#iterator-chaining">Iterator Chaining</a></h1>
<p>One of my favorite Rust features is its powerful <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html">iterator</a> chaining. One basic example is using <code>map</code> to apply a custom function to each element in the iterator.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: Vec&lt;usize&gt; = vec![1, 2, 3, 4, 5];

    let x_mapped: Vec&lt;usize&gt; = x.iter().map(|v| *v * 2).collect();

    assert_eq!(x_mapped, vec![2, 4, 6, 8, 10]);
}</code></pre>
<p>A slightly more advanced example is trying to parse a <code>Vec</code> of strings, only keeping the values we successfully parsed. In the example below, we use <code>filter_map</code> to both filter and map values at the same time.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let x: Vec&lt;&amp;str&gt; = vec!["3", "hello", "8", "10", "world"];

    let x_parsed: Vec&lt;usize&gt; = x.iter().filter_map(|v| v.parse::&lt;usize&gt;().ok()).collect();

    println!("{:?}", x_parsed);
}</code></pre>
<p><code>filter_map</code> accepts an <code>Option&lt;T&gt;</code> to filter on. In our case, <code>parse</code> returns a <code>Result&lt;T, Err&gt;</code> so we use <code>.ok()</code> to convert <code>Result&lt;T, Err&gt;</code> to <code>Option&lt;T&gt;</code>.</p>
<p>We can also use scopes to create extremely versatile chaining. In the last example, we’ll loop over a <code>Vec</code> that contains some mock fastq reads, gather some stats, and collect into a new <code>Vec</code>. Even though this is a silly example, it shows how we can use iterator chaining to provide structure to unstructured data.</p>
<pre class="playground"><code class="language-rust edition2024">#[allow(unused)]
#[derive(Debug, PartialEq)]
struct FastqRead&lt;'a&gt; {
    name: &amp;'a str,
    seq: &amp;'a [u8],
    qual: &amp;'a [u8],
    length: usize,
    mean_error: f64,
}

fn collect_fastq_reads&lt;'a&gt;(fastq_reads: &amp;'a [(&amp;str, &amp;[u8], &amp;[u8])]) -&gt; Vec&lt;FastqRead&lt;'a&gt;&gt; {
    let fastq_stats: Vec&lt;FastqRead&lt;'a&gt;&gt; = fastq_reads
        .iter()
        .map(|(name, seq, qual)| {
            // Calculate mean error rate.
            let error_sum: f64 = qual
                .iter()
                .map(|q| 10_f64.powf(-1.0 * ((q - 33) as f64) / 10.0))
                .sum();

            let fastq_read = FastqRead {
                name: name,
                seq: seq,
                qual: qual,
                length: seq.len(),
                mean_error: error_sum / qual.len() as f64,
            };

            return fastq_read;
        })
        .collect();

    fastq_stats
}

fn main() {
    let fastq_reads: Vec&lt;(&amp;str, &amp;[u8], &amp;[u8])&gt; = vec![
        ("read_1", b"ATCG", b"????"),
        ("read_2", b"AAAAAAA", b"???????"),
    ];

    let fastq_stats = collect_fastq_reads(&amp;fastq_reads);

    assert_eq!(
        fastq_stats,
        vec![
            FastqRead {
                name: "read_1",
                seq: b"ATCG",
                qual: b"????",
                length: 4,
                mean_error: 0.001
            },
            FastqRead {
                name: "read_2",
                seq: b"AAAAAAA",
                qual: b"???????",
                length: 7,
                mean_error: 0.001
            }
        ]
    );
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="multi-threading"><a class="header" href="#multi-threading">Multi-threading</a></h1>
<p>In bioinformatics, multithreading can be vital and has the potential to decrease runtimes. Sometimes even by several magnitudes. The Rust <a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html">documentation</a> covers concurrency and multithreading in detail and there are also several crates that make multithreading easier to implement. Below is a list of Rust crates that work very well for creating fast and memory-safe bioinformatic applications:</p>
<ul>
<li><a href="https://docs.rs/bio/latest/bio/">Bio</a> - General purpose bioinformatic tool for e.g., parsing fastq/fasta files.</li>
<li><a href="https://docs.rs/rayon/latest/rayon/">Rayon</a> - Data parallelism library that works well together with the Bio crate. Enables parallel processing of sequences through <a href="https://docs.rs/rayon/latest/rayon/iter/trait.ParallelBridge.html#tymethod.par_bridge">par_bridge()</a>.</li>
<li><a href="https://docs.rs/dashmap/latest/dashmap/">DashMap</a> - Concurrent HashMaps and HashSets.</li>
</ul>
<h2 id="tips-and-tricks"><a class="header" href="#tips-and-tricks">Tips And Tricks</a></h2>
<p>Below, I’ve gathered some tips and tricks when it comes to using multithreading with Rust, especially for bioinformatic applications.</p>
<h3 id="start-by-creating-a-mvba"><a class="header" href="#start-by-creating-a-mvba">Start by creating a MVBA</a></h3>
<p>A MVBA (Minimally Viable Bioinformatic Application) is something that runs and produces the expected output. I’ve found that starting out this way is easier, because one can always optimize the code later on. For me, it is tempting to start out writing the most optimized code from the beginning. However, I’ve learned that programming this way takes more time and is less productive.</p>
<h3 id="optimize-the-mvba"><a class="header" href="#optimize-the-mvba">Optimize the MVBA</a></h3>
<p>Once the MVBA is done, it is time to optimize. We must not forget this if we want an application that performs well under heavy loads. Optimization can be done in several ways, such as:</p>
<ul>
<li>Testing the application in release mode <code>cargo build --release</code>.</li>
<li>Use a profiler such as <a href="https://crates.io/crates/samply">Samply</a> to identify bottlenecks.</li>
<li>Implement concurrency and multithreading if applicable.</li>
<li>Using appropriate data structures.</li>
</ul>
<h3 id="multithreading-is-not-always-the-answer"><a class="header" href="#multithreading-is-not-always-the-answer">Multithreading is not always the answer</a></h3>
<p>Even though multithreading is a useful tool within bioinformatics, there are cases where it might hurt more than it helps.</p>
<p>Cases where multithreading shines:</p>
<ul>
<li>CPU heavy loads (such as genome assembly, read alignment, etc).</li>
<li>Tasks can be executed relatively independently.</li>
</ul>
<p>Cases where multithreading might not be the answer:</p>
<ul>
<li>Tasks are extremely small and frequent.</li>
<li>Each task is expected to take up a lot of RAM (risking out of memory error).</li>
</ul>
<h3 id="find-code-examples"><a class="header" href="#find-code-examples">Find code examples</a></h3>
<p>One excellent way to learn about concurrency is to look at code examples. There is plenty of well-established open source Rust projects that use multithreading. As a start, here are some of my own not-so-well-established-and-work-in-progress projects:</p>
<ul>
<li><a href="https://github.com/OscarAspelin95/sintax_rs">sintax_rs</a> - Rust implementation of the SINTAX classifier.</li>
<li><a href="https://github.com/OscarAspelin95/ani_rs">ani_rs</a> - Fast approximate genome similarity.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="trait-bounds-and-generics"><a class="header" href="#trait-bounds-and-generics">Trait Bounds and Generics</a></h1>
<p>Rust supports generic types, but due to its strict type checker we need to put some restrictions on the generic type. In Python, we can use unions to signify that a variable or argument can be of different types.</p>
<pre><code class="language-Python">def display(s: str | int | list[str]):
    print(s)

print('my_string')
print(1)
print(['my', 'string'])

# This will actually run but the linter will complain.
print({'my', 'string'})
</code></pre>
<p>In Rust, this works a bit differently. To print something, the variable needs to implement either the <a href="https://doc.rust-lang.org/rust-by-example/hello/print/print_display.html"><code>Display</code></a> trait (“normal” print) or the <a href="https://doc.rust-lang.org/rust-by-example/hello/print/print_debug.html"><code>Debug</code></a> trait (debug print). By using a <code>trait bound</code>, we can tell the compiler that only generic types which implement the <code>Display</code> or <code>Debug</code> trait are allowed as argument(s) to the function.</p>
<p>In the example below, we implement a function that accepts an argument of a generic type <code>T</code> that implements the <code>Debug</code> trait. Luckily, all Rust types in the <code>std</code> library automatically implement <code>Debug</code>.</p>
<pre class="playground"><code class="language-rust edition2024">use std::fmt::Debug;

fn display&lt;T: Debug&gt;(arg: T) {
    println!("{:?}", arg);
}

fn main() {
    display(1);
    display("my_string");
    display("my_string".to_string());
    display(vec!["my", "string"]);
}</code></pre>
<h2 id="deriving-traits"><a class="header" href="#deriving-traits">Deriving traits</a></h2>
<p>What if we have a type that does not implement <code>Debug</code> by default? We can derive it using the <code>derive</code> macro.</p>
<p>In the following example, we’ll create a <code>Struct</code> that by default does not implement <code>Debug</code>. By using the <code>derive</code> macro, we can subsequently call our <code>display</code> function.</p>
<pre class="playground"><code class="language-rust editable edition2024">use std::fmt::Debug;

#[derive(Debug)] // Try commenting this out!
struct MyStruct&lt;'a&gt; {
    field_1: usize,
    field_2: &amp;'a str,
    field_3: String,
    field_4: Vec&lt;&amp;'a str&gt;,
}

fn display&lt;T: Debug&gt;(arg: T) {
    println!("{:?}", arg);
}

fn main() {
    let my_struct = MyStruct {
        field_1: 1,
        field_2: "my_string",
        field_3: "my_string".to_string(),
        field_4: vec!["my", "string"],
    };

    display(my_struct);
}</code></pre>
<p>Other common Rust traits that can be derived or implemented manually are:</p>
<ul>
<li><a href="https://doc.rust-lang.org/rust-by-example/hello/print/print_display.html"><code>Display</code></a></li>
<li><a href="https://doc.rust-lang.org/rust-by-example/trait/clone.html"><code>Clone</code></a></li>
<li><a href="https://doc.rust-lang.org/nomicon/send-and-sync.html"><code>Send</code></a></li>
<li><a href="https://doc.rust-lang.org/nomicon/send-and-sync.html"><code>Sync</code></a></li>
<li><a href="https://doc.rust-lang.org/std/cmp/trait.Ord.html"><code>Ord</code></a></li>
<li><a href="https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html"><code>PartialOrd</code></a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="smart-pointers"><a class="header" href="#smart-pointers">Smart Pointers</a></h1>
<p>In Rust, there is a set of smart-pointers to make our lives easier when it comes to things such as ownership, references, etc.</p>
<h2 id="box"><a class="header" href="#box">Box</a></h2>
<p>The <code>Box</code> smart-pointer is used to enforce heap allocation of the value, and stack allocation of the reference. It can be used in various applications, two of which are recursive datatypes and dynamic traits.</p>
<h3 id="recursive-datatypes"><a class="header" href="#recursive-datatypes">Recursive Datatypes</a></h3>
<p>Let’s define a <code>Struct</code> which has a field <code>inner</code> that references itself (i.e., a recursive structure). If we try to run this, we’ll get a compiler error.</p>
<pre class="playground"><code class="language-rust edition2024">struct MyStruct{
    inner: Option&lt;MyStruct&gt;,
    value: usize
}

fn main(){
    let my_struct = MyStruct {value: 0, inner: Some(MyStruct { value: 1, inner: None}) };
}</code></pre>
<p>The problem is that the size of <code>MyStruct</code> is not known at compile time, which is a requirement for stack allocation. However, by using a <code>Box</code> we can enforce heap allocation of <code>MyStruct</code>, keeping its reference on the stack. Since references are compile-size-known, this works.</p>
<pre class="playground"><code class="language-rust edition2024">struct MyStruct{
    inner: Option&lt;Box&lt;MyStruct&gt;&gt;,
    value: usize
}

fn main(){
    let my_struct = Box::new(MyStruct {value: 0, inner: Some(Box::new(MyStruct { value: 1, inner: None})) });
}</code></pre>
<p>The obvious downside here is that the code becomes rather verbose.</p>
<h3 id="dynamic-traits"><a class="header" href="#dynamic-traits">Dynamic Traits</a></h3>
<p>Another use of <code>Box</code> is for dynamic traits. One example of this is to create a <code>BufWriter</code> that writes either to file or stdout depending on if we provide an output file. We’ll define a function <code>get_bufwriter</code>, that wraps <code>BufWriter</code> around either <code>File</code> or <code>Stdout</code> depending on the argument <code>outfile</code>. We want something like this (in pseudo-code):</p>
<pre><code class="language-rust noplayground">fn get_bufwriter(outfile: Option&lt;PathBuf&gt;) -&gt; ??? {
    match outfile {
        Some(outfile) =&gt; return BufWriter::new(File::create(outfile).unwrap());
        None =&gt; return BufWriter::New(stdout());
    }
}</code></pre>
<p>However, Rust does not natively allow us to return a value that can be of two different types, <code>BufWriter&lt;File&gt;</code> or <code>BufWriter&lt;Stdout&gt;</code>. Fortunately, both types have the <code>Write</code> trait implemented. By wrapping <code>File</code> and <code>Stdout</code> in a <code>Box</code>, we can change our return type to the more generic <code>BufWriter&lt;Box&lt;dyn Write&gt;&gt;</code>. Conceptually, this signature means that the return type is a <code>BufWriter</code> wrapped around a type that implements the <code>Write</code> trait. The <code>dyn</code> keyword is related a <a href="https://doc.rust-lang.org/std/keyword.dyn.html">trait object</a>’s type. Because the exact size of <code>Write</code> is not known at compile-time, we need to use <code>Box</code>.</p>
<pre class="playground"><code class="language-rust edition2024">use std::{
    fs::File,
    io::{BufWriter, Write, stdout},
    path::PathBuf,
};

fn get_bufwriter(outfile: Option&lt;PathBuf&gt;) -&gt; BufWriter&lt;Box&lt;dyn Write&gt;&gt; {
    match outfile {
        Some(outfile) =&gt; return BufWriter::new(Box::new(File::create(outfile).unwrap())),
        None =&gt; return BufWriter::new(Box::new(stdout())),
    }
}

fn main() {
    // Create a writer that writes to stdout.
    let mut writer = get_bufwriter(None);
    writer.write(b"This will be written to stdout!\n").unwrap();

    // // Commented out for obvious reasons.
    // let mut writer = get_bufwriter(Some(PathBuf::from("file.txt")));
    // writer
    //     .write(b"This will be written to the output file!\n")
    //     .unwrap();
}</code></pre>
<h2 id="rc"><a class="header" href="#rc">Rc</a></h2>
<p><code>Rc</code> stands for <q>Reference Counting</q> and is for single-threaded, multiple ownership. By creating multiple references to a variable (increasing the reference count), we can prevent the variable from being dropped until the reference count reaches zero. A good analogy would be multiple people watching the same TV. We don’t want the TV to turn off until all people stop watching.</p>
<pre class="playground"><code class="language-rust edition2024">use std::rc::Rc;

#[allow(unused)]
fn main() {
    let x: Rc&lt;usize&gt; = Rc::new(0);

    assert_eq!(Rc::strong_count(&amp;x), 1);
    println!("{}", Rc::strong_count(&amp;x));

    {
        let x_clone = x.clone();
        assert_eq!(Rc::strong_count(&amp;x), 2);
        println!("{}", Rc::strong_count(&amp;x));
    } // x_clone is dropped here, reference count to x will decrease by one.

    assert_eq!(Rc::strong_count(&amp;x), 1);
    println!("{}", Rc::strong_count(&amp;x));
}</code></pre>
<h2 id="arc"><a class="header" href="#arc">Arc</a></h2>
<p><code>Arc</code> stands for <q>Atomic Reference Count</q> and is a thread safe alternative to <code>Rc</code>. It is commonly used together with <code>Mutex</code> for exclusive read/write access. One example is trying to push elements from different threads to a shared <code>Vec</code> instance. We need to ensure that our threads do not read and write at the same time since this can cause lockings and undefined behavior.</p>
<p>In the example below, we create a <code>Vec</code> for storing a message from each thread. We wrap it in <code>Arc&lt;Mutex&lt;&gt;&gt;</code> to ensure thread safety. Then we spawn four threads, each of which will push a <code>String</code> to our <code>Vec</code>. By using <code>.lock()</code> we can make sure only one thread can access our <code>Vec</code> at a given time. Finally, we wait for all threads to finish and print the results.</p>
<pre class="playground"><code class="language-rust edition2024">use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let v: Arc&lt;Mutex&lt;Vec&lt;String&gt;&gt;&gt; = Arc::new(Mutex::new(vec![]));

    let mut handles = Vec::new();

    for i in 0..4 {
        // Each thread will get its own reference to the Arc&lt;Mutex&lt;Vec&lt;String&gt;&gt;&gt;.
        let v_clone = v.clone();

        let s = thread::spawn(move || {
            v_clone
                .lock()
                .unwrap()
                .push(format!("Hello from thread {}", i));
        });

        handles.push(s);
    }

    // Wait for and join the spawned threads.
    for h in handles {
        h.join().unwrap();
    }

    // Extract our Vec from the Arc&lt;Mutex&lt;&gt;&gt;.
    let v_done = Arc::into_inner(v).unwrap().into_inner().unwrap();

    for s in v_done {
        println!("{s}");
    }
}</code></pre>
<h2 id="cow"><a class="header" href="#cow">Cow</a></h2>
<p>The Clone-On-Write smart pointer provides immutable access to borrowed data with the ability to lazily clone data when mutability or ownership is required. <code>Cow</code> is usable for cases where most of the time, we don’t need to mutate data.</p>
<p>Consider the example below, where we want to convert a <code>&amp;str</code> to lowercase. If we expect that most of the time our <code>&amp;str</code> is already lowercase, we can return it as is most of the time with <code>Cow::Borrowed()</code>. However, for those rare cases when we need to modify it, we use <code>Cow::Owned()</code>.</p>
<pre class="playground"><code class="language-rust edition2024">use std::borrow::Cow;

fn convert_to_lowercase(x: &amp;str) -&gt; Cow&lt;'_, str&gt; {
    if x.chars().any(|c| c.is_uppercase()) {
        return Cow::Owned(x.to_lowercase());
    }

    return Cow::Borrowed(x);
}

fn make_lowercase(x: &amp;str) -&gt; Cow&lt;'_, str&gt; {
    let x_uppercase = convert_to_lowercase(&amp;x);

    match &amp;x_uppercase {
        Cow::Borrowed(_) =&gt; {
            println!("Is borrowed.");
        }
        Cow::Owned(_) =&gt; {
            println!("Is owned.");
        }
    }

    return x_uppercase;
}

#[allow(unused)]
fn main() {
    // Lowercase conversion not needed.
    let x = "my_string";
    let x_lowercase = make_lowercase(x);

    // Lowercase conversion needed.
    let y = "My_String";
    let y_lowercase = make_lowercase(y);
}</code></pre>
<p>To be honest, I still fully do not understand the details of <code>Cow</code> and I rarely use it in my own code. However, I’m sure it is useful.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="file-formats"><a class="header" href="#file-formats">File Formats</a></h1>
<p>In bioinformatics, there are two commonly encountered file formats, FASTA and FASTQ. They both store biological sequences but contain different amounts of information. In this chapter, we’ll cover both formats briefly.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="fasta"><a class="header" href="#fasta">FASTA</a></h1>
<p>The <a href="https://en.wikipedia.org/wiki/FASTA_format">FASTA</a> format is a standardized way of storing biological sequences such as nucleotides and aminoacids. Each record occupies two lines:</p>
<ol>
<li>Sequence id with an optional description. Must start with the <code>&gt;</code> character.</li>
<li>Actual sequence.</li>
</ol>
<p>A simple example of this is the following record:</p>
<pre><code>&gt;sequence_1
ATCG
</code></pre>
<p>which tells us that there is a record called <code>sequence_1</code> with the sequence <code>ATCG</code>. In this particular example, we actually do not know if these are nucleotides or aminoacids.</p>
<h2 id="multi-fasta-format"><a class="header" href="#multi-fasta-format">Multi FASTA format</a></h2>
<p>There is an alternative to the canonical FASTA format that is commonly referred to as multi FASTA format. Essentially what this means is distributing the sequence over multiple lines of a defined width. E.g., 60 characters per line.</p>
<p>For example, assume we have an arbitrary sequence of length 180. With width 60, it would look something like this.</p>
<pre><code>&gt;sequence_1
ATCG...AGAC # End of bases 1-60.
AGAG...TTTA # End of bases 61-120.
ACGC...AATG # End of bases 121-180.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="fastq"><a class="header" href="#fastq">FASTQ</a></h1>
<p>The <a href="https://en.wikipedia.org/wiki/FASTQ_format">FASTQ</a> format is similar to FASTA, but also associates each nucleotide with an error probability. This is relevant because it enables us to do things such as trimming, filtering and estimating sample quality. Each record takes up four lines:</p>
<ol>
<li>Sequence id with an optional description. Must start with the <code>@</code> character.</li>
<li>Actual sequence.</li>
<li><code>+</code>.</li>
<li>Quality (<a href="https://www.ascii-code.com/">ASCII</a> encoded <a href="https://en.wikipedia.org/wiki/Phred_quality_score">phred scores</a>).</li>
</ol>
<p>In addition, the sequence and quality lines must contain the same number of characters. One simple example of a FASTQ record is:</p>
<pre><code>@sequence_1
ATCG
+
????
</code></pre>
<p>which tells us that there is a record called <code>sequence_1</code> with the nucleotide sequence <code>ATCG</code> and associated qualities <code>????</code>. How do we know that these are nucleotides and not aminoacids? Strictly, we don’t. However, the FASTQ format is almost exclusively used for nucleotides.</p>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>The quality line in a FASTQ file uses ASCII-encoded phred scores. To understand how to convert characters like <code>?</code> to error probabilities, see the <a href="#phred-score">Phred Score</a> chapter.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="phred-score"><a class="header" href="#phred-score">Phred Score</a></h1>
<p>Within bioinformatics, phred quality scores are used in FASTQ files to estimate the error probability for each base.</p>
<p>There are three concepts we need to understand before proceeding:</p>
<ul>
<li><code>Error Probability</code> - The probability that a particular nucleotide was called incorrectly by the sequencing machine. For example, a nucleotide <code>A</code> with error probability <code>0.001</code> means there is a 0.1% likelihood that this <code>A</code> is actually something else, like a <code>C</code>, <code>G</code> or <code>T</code>. There are two issues with this approach:
<ul>
<li>
<p>Assigning a particular error probability to a single called nucleotide might be a bit misleading. The nucleotide is either correct, or it is not. There is no <q>in between</q>. Consider the analogy of blindly throwing a die and guessing the outcome. Once the die has stopped rolling, it has a particular value (1-6). When making a guess, you can either be 100% wrong, or 100% right. However, if you <strong>repeat</strong> the experiment enough times, you’ll be right about <code>1/6</code> of the times.</p>
</li>
<li>
<p>Error probabilities are a bit incomplete. For example, how do we estimate a deleted nucleotide? It won’t be present in the FASTQ file (because it is deleted) so we cannot assign an error probability to this. To be honest, I’m not sure how this is handled (if it even is) by the sequencing machine.</p>
</li>
</ul>
</li>
</ul>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>Error probabilities are statistical estimates across many sequencing events, not absolute truths about individual bases. A base with error probability 0.001 is either correct or incorrect — the probability reflects how often similar bases are miscalled across many reads. Additionally, phred scores only capture substitution errors. Deletion and insertion errors are not represented in the FASTQ quality line, since deleted bases are absent from the read entirely.</p>
</blockquote>
<ul>
<li>
<p><code>Phred Score</code> - Is a logarithmically encoded error probability, expressed as an integer. E.g., a phred score of <code>30</code> corresponds to an error probability of <code>0.001</code>. Why do we care about phred scores? We don’t want to include a bunch of floating point numbers in our FASTQ file because we’ll run into issues such as rounding, etc.</p>
</li>
<li>
<p><code>ASCII Quality</code> - The ASCII character associated with the error probability, and hence, the phred score of a particular nucleotide. This is what is found in the actual FASTQ file. Why an ASCII character? Because they are fixed length characters (of length 1). This gives a very nice mapping of <code>one nucleotide</code> -&gt; <code>one ASCII</code> quality value. The conversion between <code>ASCII</code> and <code>phred score</code> uses a phred score offset. The reason is that the first 31 ASCII characters are non-printable and the 32nd is the space character <code>' '</code>. To account for the fact that our <q>zero</q> or lowest quality value starts as ASCII character 33, an offset of 33 is commonly used. E.g., the ASCII character <code>!</code> has value 33 equates to a phred score of <code>33 - 33 = 0</code>.</p>
</li>
</ul>
<p>Since ASCII, phred scores and error probabilities are related, we can convert between them.</p>
<pre class="mermaid">graph LR
    A["ASCII Character&lt;br/&gt;(e.g. '?' = 63)"] -- "subtract 33" --&gt; B["Phred Score&lt;br/&gt;(e.g. 30)"]
    B -- "10&lt;sup&gt;-ps/10&lt;/sup&gt;" --&gt; C["Error Probability&lt;br/&gt;(e.g. 0.001)"]
    C -- "-10 * log&lt;sub&gt;10&lt;/sub&gt;(p)" --&gt; B
    B -- "add 33" --&gt; A
</pre>

<h2 id="a-quick-look-at-the-maths"><a class="header" href="#a-quick-look-at-the-maths">A Quick Look At The Maths</a></h2>
<h3 id="error-probability"><a class="header" href="#error-probability">Error Probability</a></h3>
<p>We won’t go through the details about the <a href="https://en.wikipedia.org/wiki/Phred_quality_score">maths</a> regarding phred scores and error probabilities, but the equality looks something like this:</p>
<p>\[ error\_probability = 10^{-(ASCII - \text{phred_offset})/10} \]</p>
<p>where</p>
<p>\[ phred\_score = ASCII - \text{phred_offset} = ASCII - 33 \]</p>
<p>We can now test this formula. Assume we’d want to convert <code>?</code> to an error probability using <code>phred_offset = 33</code>. Since the ASCII value of <code>?</code> is <code>63</code>, this would equate to:</p>
<p>\[ error\_probability = 10^{-(63 - 33)/10}  = 10^{-3} = 0.001 \]</p>
<h3 id="phred-score-1"><a class="header" href="#phred-score-1">Phred Score</a></h3>
<p>Similarly, we can get our <code>phred_score</code> through</p>
<p>\[ \text{phred_score} = -10 * log_{10}(\text{error_probability}) \]</p>
<p>E.g., for an error probability of 0.001, we get</p>
<p>\[ \text{phred_score} = -10 * log_{10}(0.001) = 30 \]</p>
<p>which would give an ASCII value of <code>30 + 33 = 63</code>, or <code>?</code></p>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>Now that we understand the relationship between ASCII, phred scores, and error probabilities, the next chapter covers a surprisingly subtle topic: <a href="#calculating-average-errors">how to correctly calculate mean error probabilities</a>.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="calculating-average-errors"><a class="header" href="#calculating-average-errors">Calculating Average Errors</a></h1>
<p>This is (at least according to me) actually a surprisingly interesting topic.</p>
<p>Assume we have a FASTQ record with only three nucleotides with the corresponding ASCII qualities <code>???</code>. How do we calculate the mean error probability across these nucleotides? There are basically two different options:</p>
<ul>
<li>Convert to phred scores <code>[30, 30, 30]</code>, calculate the mean <code>(30 + 30 + 30) / 3 = 30</code> and convert to error probability <code>10^(-30/10) = 10^(-3) = 0.001</code>.</li>
<li>Convert all the way to error probabilities first <code>[0.001, 0.001, 0.001]</code> and then calculate the mean <code>(0.001 + 0.001 + 0.001) / 3 = 0.001</code>.</li>
</ul>
<pre class="mermaid">graph TD
    A["ASCII Qualities"] --&gt; B["Phred Scores"]
    B --&gt; C1["Method 1:&lt;br/&gt;Arithmetic mean of phred scores"]
    B --&gt; C2["Method 2:&lt;br/&gt;Convert each to error probability"]
    C1 --&gt; D1["Convert mean phred&lt;br/&gt;to error probability"]
    C2 --&gt; D2["Arithmetic mean of&lt;br/&gt;error probabilities"]
    D1 --&gt; E1["= Geometric mean&lt;br/&gt;of error probabilities"]
    D2 --&gt; E2["= Arithmetic mean&lt;br/&gt;of error probabilities"]

    style E1 fill:#d44,color:#fff
    style E2 fill:#2a2,color:#fff
</pre>

<p>In this example, we get the same result. This is, however, not always the case. Consider an alternative sequence of only two nucleotides with ASCII qualities <code>+5</code>. Our two options give:</p>
<ul>
<li><code>[10, 20]</code> -&gt; mean is <code>(10 + 20) / 2 = 15</code> which gives an error probability of <code>10^(-15/10) ≈ 0.0316</code>.</li>
<li><code>[0.1, 0.01]</code> -&gt; mean is <code>(0.1 + 0.01) / 2 = 0.055</code>.</li>
</ul>
<p>All of a sudden, the results are quite different based on the method we choose. How do we know which is correct?</p>
<h2 id="different-kinds-of-means"><a class="header" href="#different-kinds-of-means">Different Kinds Of Means</a></h2>
<p>To investigate this, we need to understand that there are different ways of calculating means, neither of which is incorrect.</p>
<h3 id="arithmetic-mean"><a class="header" href="#arithmetic-mean">Arithmetic Mean</a></h3>
<p>The most common way is the <code>arithmetic mean</code>, which has the famous formula
\[\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i\]</p>
<p>E.g., for <code>n=2</code> this would give <code>1/2 * (1 + 2) = 3/2 = 1.5</code>.</p>
<h3 id="geometric-mean"><a class="header" href="#geometric-mean">Geometric Mean</a></h3>
<p>A less common, but equally valid way to calculate means is the <code>geometric mean</code>:
\[
\bar{x} = \sqrt[n]{\prod_{i=1}^{n} x_i} = {\prod_{i=1}^{n} x_i}^{1/n}
\]</p>
<p>E.g., for <code>n=2</code> this would give <code>(1 * 2)^(1/2) = √2 ≈ 1.414</code>.</p>
<h2 id="putting-it-all-together"><a class="header" href="#putting-it-all-together">Putting It All Together</a></h2>
<p>Our two approaches for calculating mean error probabilities, as defined in the start of this chapter, both use the <code>arithmetic mean</code>. However, the first approach has a fundamental flaw. We are calculating the <code>arithmetic mean</code> of log-encoded values that are not equidistant from each other with respect to error probabilities. As an example, the difference between phred scores <code>10</code> and <code>20</code> (with respect to error probabilities) is <code>0.1 - 0.01 = 0.09</code> whilst the difference between <code>20</code> and <code>30</code> is <code>0.01 - 0.001 = 0.009</code>.</p>
<p>Mathematically, we can derive the following formulas for our two approaches. Assume we have a set of phred scores \[{ps_{1}, ps_{2}, …, ps_{n}}\]</p>
<ul>
<li>
<p>In the first method, we calculate a mean phred score and finally convert to an error probability.
\[
\text{mean_error_probability} = 10^{-\bar{ps} / 10}
\]</p>
<p>where
\[
\bar{ps} = \frac{1}{n} \sum_{i=1}^{n} ps_i
\]</p>
<p>which gives
\[
\text{mean_error_probability} = 10^{-\frac{1}{n} \sum_{i=1}^{n} ps_i / 10} = \left(10^{\sum_{i=1}^{n} -ps_i / 10}\right)^{1/n} = \left(10^{-ps_{1} / 10} \times \text{…} \times 10^{-ps_{n} / 10}\right)^{1/n} = \left(\prod_{i=1}^{n} 10^{-ps_i/10}\right)^{1/n}
\]</p>
<p>This is the <strong>geometric mean</strong> of the individual error probabilities!</p>
</li>
<li>
<p>In the second method, we first convert each phred score to an error probability and then calculate the arithmetic mean.</p>
<p>\[
\text{mean_error_probability} = \frac{1}{n} \sum_{i=1}^{n} 10^{-ps_i / 10}
\]</p>
<p>This is simply the <strong>arithmetic mean</strong> of the individual error probabilities.</p>
</li>
</ul>
<h2 id="which-mean-to-choose"><a class="header" href="#which-mean-to-choose">Which Mean To Choose</a></h2>
<p>The natural question is which mean to choose. I’d argue that the arithmetic mean is correct, and here’s why.</p>
<p>One way to think about this is: the <strong>expected number of errors</strong> in a read is the sum of all individual error probabilities.</p>
<p>To illustrate with a concrete example, consider a read of length <code>100</code> where <code>50</code> bases have phred score <code>20</code> and the other <code>50</code> have phred score <code>30</code>:
\[   \underbrace{20, \text{…}, 20}_{50}, \underbrace{30, \text{…}, 30}_{50} \]</p>
<p>Converting to error probabilities:
\[   \underbrace{0.01, \text{…}, 0.01}_{50}, \underbrace{0.001, \text{…}, 0.001}_{50} \]</p>
<p>The expected number of errors in this read is:
\[   50 \times 0.01 + 50 \times 0.001 = 0.5 + 0.05 = 0.55 \]</p>
<p>So the mean error probability per base should be <code>0.55 / 100 = 0.0055</code>. Now let’s see what our two methods give:</p>
<ul>
<li><strong>Geometric mean (method 1):</strong> <code>mean_phred = (20 * 50 + 30 * 50) / 100 = 25</code>, so <code>mean_error_probability = 10^(-25/10) ≈ 0.0032</code>. This predicts <code>0.32</code> expected errors — an <strong>underestimate</strong>.</li>
<li><strong>Arithmetic mean (method 2):</strong> <code>mean_error_probability = (0.01 * 50 + 0.001 * 50) / 100 = 0.0055</code>. This predicts <code>0.55</code> expected errors.</li>
</ul>
<p>The geometric mean systematically underestimates the error rate because it is always less than or equal to the arithmetic mean (this is known as the <a href="https://en.wikipedia.org/wiki/AM%E2%80%93GM_inequality">AM-GM inequality</a>). In practice, this means that if you average phred scores directly, you will be overly optimistic about your data quality.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="nucleotides"><a class="header" href="#nucleotides">Nucleotides</a></h1>
<p>When dealing with DNA sequences, nucleotides are everything. Fundamentally, we are usually dealing with four canonical bases:</p>
<ul>
<li><code>A</code> - Adenine.</li>
<li><code>C</code> - Cytosine.</li>
<li><code>G</code> - Guanine.</li>
<li><code>T</code> - Thymine.</li>
</ul>
<p>However, there are some important concepts to be aware of.</p>
<h2 id="soft-masking"><a class="header" href="#soft-masking">Soft masking</a></h2>
<p>A lower case nucleotide indicates <em>soft masking</em> and is used to indicate a soft clipped alignment or a region which is low complexity or repetitive.</p>
<p>In the example below, the last part of the upper sequence is soft masked to indicate that this region is not part of the actual alignment. This is commonly encountered in local read aligners such as <a href="https://github.com/lh3/minimap2">Minimap2</a>.</p>
<pre>
  AAAGTGCCAGTGACGCTTagtcgatcgatg
  ||||||||||||||||||
  AAAGTGCCAGTGACGCTT
</pre>

<h2 id="hard-masking"><a class="header" href="#hard-masking">Hard masking</a></h2>
<p>A capital <code>N</code> indicates <em>hard masking</em>. This means there is probably a base here, but we don’t know exactly what it is. This is usually for indicating uncertainty or gaps in a sequence.</p>
<h2 id="ambiguous-nucleotides"><a class="header" href="#ambiguous-nucleotides">Ambiguous nucleotides</a></h2>
<p>In addition to our four canonical nucleotides, there are also ambiguous nucleotides. Ambiguous in this case, means uncertainty or ambiguity:</p>
<ul>
<li><code>R</code> = <code>A</code> | <code>G</code></li>
<li><code>Y</code> = <code>C</code> | <code>T</code></li>
<li><code>K</code> = <code>G</code> | <code>T</code></li>
<li><code>M</code> = <code>A</code> | <code>C</code></li>
<li><code>S</code> = <code>G</code> | <code>C</code></li>
<li><code>W</code> = <code>A</code> | <code>T</code></li>
<li><code>H</code> = <code>A</code> | <code>C</code> | <code>T</code></li>
<li><code>V</code> = <code>A</code> | <code>C</code> | <code>G</code></li>
<li><code>B</code> = <code>C</code> | <code>G</code> | <code>T</code></li>
<li><code>D</code> = <code>A</code> | <code>G</code> | <code>T</code></li>
<li><code>N</code> = <code>A</code> | <code>C</code> | <code>G</code> | <code>T</code></li>
</ul>
<p>We won’t deal much with ambiguous nucleotides in this book. However, make sure not to confuse these nucleotides with one-letter amino acid abbreviations, which have overlapping naming conventions.</p>
<h2 id="programmatic-representations"><a class="header" href="#programmatic-representations">Programmatic representations</a></h2>
<p>There are many different ways to represent nucleotide sequences in a programming language. In this book, we’ll mainly deal with these different representations:</p>
<ul>
<li><code>String</code> and <code>&amp;str</code>.</li>
<li><code>&amp;[u8]</code> (byte slice).</li>
<li>Binary.</li>
</ul>
<pre class="playground"><code class="language-rust edition2024">/// Assume we want to represent the sequence ATCG.
fn main() {
  let nt_seq_string: String = "ATCG".to_string();
  let nt_seq_str: &amp;str = "ATCG";
  let nt_seq_byte_slice: &amp;[u8] = b"ATCG";
  let nt_seq_binary: u8 = 0b00110110; // Binary, where A = 00, T = 11, C = 01 and G = 10.

  println!("{}", nt_seq_string);
  println!("{}", nt_seq_str);
  println!("{:?}", nt_seq_byte_slice);
  println!("{:08b}", nt_seq_binary);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="create-a-nucleotide-sequence"><a class="header" href="#create-a-nucleotide-sequence">Create A nucleotide sequence</a></h1>
<h2 id="string"><a class="header" href="#string">String</a></h2>
<p>There are many different string types in Rust, but the two most common ones are <code>String</code> and <code>&amp;str</code>. Both can be used to store nucleotide sequences, but they have different characteristics. Usually, use <code>String</code> if you intend to mutate the sequence, otherwise use <code>&amp;str</code>. For more information, visit the rust docs for <a href="https://doc.rust-lang.org/std/string/struct.String.html"><code>String</code></a> and <a href="https://doc.rust-lang.org/std/primitive.str.html"><code>&amp;str</code></a> respectively.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let nt_string: String = "ACGT".to_string();
    let nt_string: &amp;str = "ACGT";
}</code></pre>
<h2 id="byte-slice"><a class="header" href="#byte-slice">Byte slice</a></h2>
<p>Usually when reading nucleotide sequences from a FASTA/Q file, we get it as a byte slice, <code>&amp;[u8]</code>, which is a more convenient format.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let nt_string: &amp;[u8] = b"ACGT";

    println!("{:?}", nt_string);
}</code></pre>
<p>Run the code and examine the output. We get a bunch of numbers. This is the ASCII representation of our nucleotides, where <code>A/T/C/G</code> corresponds to an 8-bit representation. For more information, visit <a href="https://www.ascii-code.com/">this link</a>.</p>
<p>We can check that the following representations are equivalent:</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    assert_eq!(b'A', 65);
    assert_eq!(b'C', 67);
    assert_eq!(b'G', 71);
    assert_eq!(b'T', 84);
}</code></pre>
<h2 id="binary"><a class="header" href="#binary">Binary</a></h2>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>Binary encoding of nucleotides is covered in detail in the <a href="#encoding">Encoding</a> chapter, and becomes essential for the <a href="#kmers">Kmer</a> chapters where bit-shift operations enable extremely efficient kmer generation.</p>
</blockquote>
<p>In short, using 8-bits is overkill for representing only four nucleotides. Instead, we can map <code>A/C/G/T</code> to the corresponding binary representation:</p>
<ul>
<li><code>A</code> =&gt; <code>00</code></li>
<li><code>C</code> =&gt; <code>01</code></li>
<li><code>G</code> =&gt; <code>10</code></li>
<li><code>T</code> =&gt; <code>11</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="counting-nucleotides"><a class="header" href="#counting-nucleotides">Counting nucleotides</a></h1>
<p>We’ll start off with something relatively easy - counting nucleotides. We’ll create a <code>HashMap</code> for storing the counts of the nucleotides we encounter in the sequence.</p>
<pre class="playground"><code class="language-rust edition2024">use std::collections::HashMap;

fn count_nucleotides(seq: &amp;[u8]) {
    // Note: HashMap::with_capacity(4) would be better here since we know
    // there are at most 4 canonical nucleotides. See the Increasing Performance chapter.
    let mut map: HashMap&lt;&amp;u8, usize&gt; = HashMap::new();

    // Iterate over each nucleotide.
    seq.iter().for_each(|nt| match nt {
        // If we have a canonical nucleotide, we bind it to the variable c.
        c @ (b'A' | b'C' | b'G' | b'T') =&gt; match map.contains_key(c) {
            // If nucleotide is already in HashMap, increment its count.
            true =&gt; {
                let v = map.get_mut(c).unwrap();
                *v += 1;
            }
            // Otherwise, add it.
            false =&gt; {
                map.insert(c, 1);
            }
        },
        _ =&gt; panic!("Invalid nt {nt}"),
    });

    assert_eq!(map.values().sum::&lt;usize&gt;(), seq.len());
    println!("{:?}", map);
}

fn main() {
    count_nucleotides(b"ATCG");
    count_nucleotides(b"AAAA");
}</code></pre>
<p>Run the code and inspect the output. The resulting HashMap will have the ASCII encoded nucleotides as keys.</p>
<p>Note that there are lots of alternative solutions and further optimizations we can do. For example, when we input <code>b"AAAA"</code> we see that our <code>HashMap</code> only contains one key, <code>b'A'</code>. One alternative here would be to initialize the <code>HashMap</code> with empty counts for A, T, C and G.</p>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>For a more efficient approach to nucleotide counting using fixed-size arrays instead of HashMaps, see the <a href="#using-appropriate-data-structures">Using Appropriate Data Structures</a> chapter.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="gc-content"><a class="header" href="#gc-content">GC content</a></h1>
<p>With the previous section in mind, it is relatively straightforward to implement a function that calculates the GC-content for a given nucleotide sequence.</p>
<pre class="playground"><code class="language-rust edition2024">fn gc_content(nt_seq: &amp;[u8]) -&gt; f32 {
    let gc_count = nt_seq.iter().filter(|&amp;&amp;nt| {
        nt == b'C' || nt == b'G'
    }).count();

    return gc_count as f32 / nt_seq.len() as f32;

}

fn main() {
   assert_eq!(gc_content(b"ATCG"), 0.5);
   assert_eq!(gc_content(b"ATTC"), 0.25);
   assert_eq!(gc_content(b"AAAA"), 0.0);
   assert_eq!(gc_content(b"CGCGCG"), 1.0);
}</code></pre>
<p>In this code example, we use the filter method to count the number of Gs and Cs. This is not necessarily the fastest way, but it works for now.</p>
<p>Also, note that we are only filtering for uppercase G and C. In a real life application, we’d probably also check for <code>b'c'</code> and <code>b'g'</code>, e.g., softmasked bases.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="homopolymers"><a class="header" href="#homopolymers">Homopolymers</a></h1>
<p>A <em>homopolymer</em> is a defined stretch of consecutive, identical nucleotides. One example is the sequence below, in which there is a A-homopolymer of length 7.</p>
<pre>
...ATCG<u>AAAAAAA</u>CACA...
</pre>

<p>Why are homopolymers important? Biologically, they play a role in multiple functions, such as promoters and other regulatory regions. In addition, homopolymer regions have been shown to introduce systematic errors in Oxford Nanopore data, which is why these regions are important to identify and inspect.</p>
<p>In the code-snippet below, we implement a simple function for identifying homopolymer regions of a defined minimum length in a sequence.</p>
<pre class="playground"><code class="language-rust edition2024">fn find_homopolymers(seq: &amp;[u8], min_hp_len: usize) -&gt; Vec&lt;&amp;[u8]&gt; {
    let mut homopolymers: Vec&lt;&amp;[u8]&gt; = Vec::new();

    let seq_len = seq.len();

    // Skip checking if seq length is too short.
    if seq_len &lt; min_hp_len {
        return homopolymers
    }

    let mut i = 0;
    let mut j = 1;

    // We only need to check homopolymers until our start index
    // is closer than min_hp_len to the end of the sequence.
    while i &lt;= seq_len - min_hp_len {
        while j &lt; seq_len &amp;&amp; seq[j] == seq[i] {
            j += 1;
        }

        // We have a homopolymer of required length.
        if j - i &gt;= min_hp_len{
            homopolymers.push(&amp;seq[i..j]);
        }

        i = j;
        j += 1;
    }


    return homopolymers
}

fn main() {
    // Find all homopolymers of length &gt;= 5.
    assert_eq!(find_homopolymers(b"AAAAA", 5), vec![b"AAAAA"]);

    // Find all homopolymers of length &gt;= 3.
    assert_eq!(find_homopolymers(b"AAACCCTTTGGG", 3), vec![b"AAA", b"CCC", b"TTT", b"GGG"]);

    // Find all homopolymers of length &gt;= 5.
    assert_eq!(find_homopolymers(b"ATCGAAAAAAAAAAGCTA", 5), vec![b"AAAAAAAAAA"]);

    // Find every nucleotide (makes no sense).
    assert_eq!(find_homopolymers(b"ATC", 1), vec![b"A", b"T", b"C"]);

}</code></pre>
<p>In a real life application, we’d most likely do more than this such as saving the positions for identified homopolymers.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="entropy"><a class="header" href="#entropy">Entropy</a></h1>
<p>Typically, one associates entropy with the physical term for the measure of disorder. In bioinformatics, entropy can be used for quantifying the diversity or randomness of nucleotide sequences.</p>
<p>Although there are different kinds of entropies, the <em>Shannon</em> entropy is probably the most famous one. It is defined by the following equation:</p>
<p>\[ -\sum_{i=\{A,T,C,G\}} p_i \cdot log_2(p_i) \quad log_2(p_i) = \begin{cases} log_2(p_i) \; if \; p_i &gt; 0 \\ 0 \; if \; p_i \; == \; 0 \end{cases} \ \]</p>
<p>That is, we calculate the proportions of each nucleotide {A, T, C, G} and calculate the sum of the probability times its logarithm. For example, consider the sequence “AAAAA”. Calculating the Shannon entropy would result in:</p>
<p>\[ -(1 \cdot log_2(1) + 0 + 0 + 0) = 0\]</p>
<p>Which tells us there is very little disorder or randomness. This makes sense, because we have the same nucleotide repeated five times. The code snippet below implements the Shannon entropy for a given nucleotide sequence. We’ll reuse the previous code for counting nucleotides (with a few modifications) and add the entropy calculation.</p>
<pre class="playground"><code class="language-rust edition2024"><span class="boring">use std::collections::HashMap;
</span><span class="boring">
</span><span class="boring">fn count_nucleotides(seq: &amp;[u8]) -&gt; HashMap&lt;u8, usize&gt; {
</span><span class="boring">    let mut map: HashMap&lt;u8, usize&gt; = HashMap::with_capacity(4);
</span><span class="boring">
</span><span class="boring">    // Pre-fill with empty counts for all expected nucleotides.
</span><span class="boring">    map.insert(b'A', 0);
</span><span class="boring">    map.insert(b'T', 0);
</span><span class="boring">    map.insert(b'C', 0);
</span><span class="boring">    map.insert(b'G', 0);
</span><span class="boring">
</span><span class="boring">    // Iterate over each nucleotide.
</span><span class="boring">    seq.iter().for_each(|nt| match nt {
</span><span class="boring">        // If we have a canonical nucleotide, we bind it to the variable c.
</span><span class="boring">        c @ (b'A' | b'C' | b'G' | b'T') =&gt; match map.contains_key(c) {
</span><span class="boring">            // If nucleotide is already in HashMap, increment its count.
</span><span class="boring">            true =&gt; {
</span><span class="boring">                let v = map.get_mut(c).unwrap();
</span><span class="boring">                *v += 1;
</span><span class="boring">            }
</span><span class="boring">            // Otherwise, add it.
</span><span class="boring">            false =&gt; {
</span><span class="boring">                map.insert(*c, 1);
</span><span class="boring">            }
</span><span class="boring">        },
</span><span class="boring">        _ =&gt; panic!("Invalid nt {nt}"),
</span><span class="boring">    });
</span><span class="boring">
</span><span class="boring">    return map;
</span><span class="boring">}
</span><span class="boring">
</span>// [...]

fn shannon_entropy(counts: &amp;HashMap&lt;u8, usize&gt;) -&gt; f32 {
    let sum_count: usize = counts.values().sum();

    // Probabilities of each nucleotide.
    let probs: Vec&lt;f32&gt; = counts
        .values()
        .map(|count| (*count as f32 / sum_count as f32))
        .collect();

    let shannon: f32 = probs
        .iter()
        .map(|prob| match prob {
            0_f32 =&gt; return 0 as f32,
            // This is safe because prob is never negative since
            // both count and sum_count are of type usize.
            _ =&gt; {
                return prob * prob.log2();
            }
        })
        .sum();

    return -shannon;
}

fn get_shannon_entropy(seq: &amp;[u8]) -&gt; f32 {
    let counts = count_nucleotides(seq);
    let shannon = shannon_entropy(&amp;counts);

    return shannon;
}

fn main() {
    assert_eq!(get_shannon_entropy(b"AAAAA"), 0.0_f32);
    assert_eq!(get_shannon_entropy(b"ATCG"), 2.0_f32);
    assert_eq!(get_shannon_entropy(b"ATCGATCGATCG"), 2.0_f32);
    assert_eq!(get_shannon_entropy(b"AAAAAAG"), 0.5916728_f32);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="manipulating"><a class="header" href="#manipulating">Manipulating</a></h1>
<p>The art of manipulating nucleotide sequences has numerous applications. Essentially what it means is somehow changing or modifying the sequence to better fit the application at hand. In this chapter, we’ll get acquainted with two different methods: <code>compression</code> and <code>reverse complement</code>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="compression"><a class="header" href="#compression">Compression</a></h1>
<p>Compression algorithms have been around for a long time. Examples span everything from <a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman encoding</a> (used in e.g., <code>gzip</code>) to <a href="https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform">Burrows Wheeler</a>. In this section, we’ll just cover some very basic ways of compressing a nucleotide sequence.</p>
<p>One very straightforward way to implement nucleotide compression would be to save how many times the same nucleotide appears in a row. E.g., <code>ATAAAAAGGCGCTTTA</code> -&gt; <code>AT5A2GCGC3TA</code>. Since we preserve the order, this compression is easily reversible.</p>
<p>Another way of compression is nucleotide encoding, which is covered in more detail later on. It turns out that if we only allow <code>{A, C, G, T, a, c, g, t}</code>, we can map each base to 2 bits. E.g., <code>ATCG</code> -&gt; <code>00110110</code>, which is extremely efficient when generating kmers.</p>
<h2 id="homopolymer-compression"><a class="header" href="#homopolymer-compression">Homopolymer Compression</a></h2>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>Homopolymers are discussed in more detail in the dedicated <a href="#homopolymers">Homopolymers</a> chapter, which covers identification and why they matter for sequencing technologies like Oxford Nanopore.</p>
</blockquote>
<p>A similar, non reversible approach is homopolymer compression. We define a length <code>k</code>, at which we cap the maximum number of allowed adjacent identical nucleotides. E.g., with <code>k=3</code> we get <code>ATAAAAAGGCGCTTTA</code> -&gt; <code>ATAAAGGCGCTTTA</code> and with <code>k=1</code> we get <code>ATAAAGGCGCTTTA</code> -&gt; <code>ATAGCGCTA</code>. If we also store positional information, we can make this compression reversible.</p>
<p>In the code example below, we implement the non-reversible version of homopolymer compression for <code>k=1</code>, inspired by <a href="https://github.com/aljpetri/isONclust3">isONclust3</a>.</p>
<pre class="playground"><code class="language-rust edition2024">fn homopolymer_compression(seq: &amp;[u8]) -&gt; String {
    let mut hp_compressed = String::new();

    let mut previous: Option&lt;&amp;u8&gt; = None;

    for nt in seq {
        // We are safe to unwrap because we checked if previous is None.
        if previous.is_none() || previous.unwrap() != nt {
            hp_compressed.push(*nt as char);
        }
        previous = Some(nt);
    }

    return hp_compressed;
}

fn main() {
    assert_eq!(homopolymer_compression(b"").as_bytes(), b"");
    assert_eq!(homopolymer_compression(b"AAAAAAAAAAAAA").as_bytes(), b"A");
    assert_eq!(homopolymer_compression(b"AATTCCGG").as_bytes(), b"ATCG");
    assert_eq!(homopolymer_compression(b"AAATTTTTT").as_bytes(), b"AT");
}</code></pre>
<p>We can improve on this idea slightly to allow for arbitrary numbers of <code>k</code>. Instead of just checking if the previous nucleotide is the same as the current, we keep track of the number of adjacent nucleotides and write maximally <code>k</code> identical, adjacent nucleotides to our string.</p>
<pre class="playground"><code class="language-rust edition2024">fn homopolymer_compression(seq: &amp;[u8], k: usize) -&gt; String {
    assert!(k &gt; 0, "value of k must be &gt; 0.");

    let mut hp_compressed: String = String::new();
    let mut i: usize = 0;

    while i &lt; seq.len() {
        let mut j = i + 1;

        while j &lt; seq.len() &amp;&amp; seq[j] == seq[i] {
            j += 1;
        }

        for _ in 0..std::cmp::min(j-i, k){
            hp_compressed.push(seq[i] as char);
        }
        i = j;
    }

    hp_compressed
}

fn main() {
    assert_eq!(homopolymer_compression(b"AAAAAAAAAAAA", 1).as_bytes(), b"A");
    assert_eq!(homopolymer_compression(b"AAAAAAAAAAAA", 2).as_bytes(), b"AA");
    assert_eq!(homopolymer_compression(b"AAATTTCCCGGG", 1).as_bytes(), b"ATCG");
    assert_eq!(homopolymer_compression(b"AAATTTCCCGGG", 2).as_bytes(), b"AATTCCGG");
    assert_eq!(homopolymer_compression(b"AAATTTCCCGGG", 3).as_bytes(), b"AAATTTCCCGGG");
    assert_eq!(homopolymer_compression(b"AAATTTCCCGGG", 100).as_bytes(), b"AAATTTCCCGGG");
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="reverse-complement"><a class="header" href="#reverse-complement">Reverse complement</a></h1>
<p>Next, we cover a fundamental topic, which is reverse complementing. Why is this important?</p>
<p>DNA is (generally) double stranded, where bases are paired:</p>
<ul>
<li>A pairs with T and vice versa.</li>
<li>G pairs with C and vice versa.</li>
</ul>
<p>5’ <code>[...]ACGAGCTTTGTGACGCGATGCGACGAGCTGCAGCGT[...]</code> 3’<br>
3’ <code>[...]TGCTCGAAACACTGCGCTACGCTGCTCGACGTCGCA[...]</code> 5’</p>
<p>Pretend this is a bacterial genome we want to sequence. Before sequencing, we need to separate the strands and break this molecule into smaller pieces. When doing this, we don’t know which pieces are from which strand.</p>
<p>When we want to align the pieces back to a reference sequence (which is defined in the 5’ to 3’ direction), we need to take both strands into consideration. Otherwise, we lose out on information. We do this by reverse complementing, in which we first reverse the sequence, and then replace each base with the corresponding matching base.</p>
<pre class="playground"><code class="language-rust edition2024">fn reverse(nt: &amp;u8) -&gt; u8 {
    match nt {
        b'A' =&gt; b'T',
        b'C' =&gt; b'G',
        b'G' =&gt; b'C',
        b'T' =&gt; b'A',
        _ =&gt; panic!("Invalid nt {nt}"),
    }
}

fn reverse_complement(nt_string: &amp;[u8]) -&gt; Vec&lt;u8&gt; {
    let rev_comp: Vec&lt;u8&gt; = nt_string
        // Iterate over each character.
        .iter()
        // Reverse the iteration order.
        .rev()
        .map(|nt| {
            return reverse(nt);
        })
        .collect();

    return rev_comp;
}

fn main() {
    assert_eq!(reverse_complement(b"AAA"), b"TTT");
    assert_eq!(reverse_complement(b"GGG"), b"CCC");
    assert_eq!(reverse_complement(b"ATCG"), b"CGAT");
    assert_eq!(reverse_complement(b"ACACGT"), b"ACGTGT");
}</code></pre>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>A more elegant approach to reverse complementing uses 2-bit nucleotide encoding, where the complement of a base is simply <code>3 - encoded_value</code>. This is covered in the <a href="#encoding">Encoding</a> chapter and becomes critical for efficient kmer generation.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="encoding"><a class="header" href="#encoding">Encoding</a></h1>
<p>Being able to encode and decode nucleotides is a vital part of writing high performance bioinformatic code. What it means is essentially converting nucleotides into a more compact form. There are multiple ways of doing nucleotide encoding. However if we assume we only have to deal with <code>{A,C,G,T}</code> then there is a straightforward way for this:</p>
<ul>
<li><code>A</code> is encoded as <code>0</code> (binary <code>00</code>).</li>
<li><code>C</code> is encoded as <code>1</code> (binary <code>01</code>).</li>
<li><code>G</code> is encoded as <code>2</code> (binary <code>10</code>).</li>
<li><code>T</code> is encoded as <code>3</code> (binary <code>11</code>).</li>
</ul>
<p>The advantages of this approach are:</p>
<ul>
<li>Each nucleotide only takes up 2 bits.</li>
<li>Reverse complementing a base is as easy as:
<ul>
<li><code>rev_nt = 3 - nt</code></li>
</ul>
</li>
<li>With some bit-shifting, we can very efficiently generate kmers from our sequences (covered in a later topic).</li>
</ul>
<pre class="mermaid">graph LR
    A["ASCII character&lt;br/&gt;(e.g. 'A' = 65)"] --&gt; B["Lookup table&lt;br/&gt;(256 entries)"]
    B --&gt; C["2-bit encoding&lt;br/&gt;(e.g. 0b00)"]
    D["Lowercase&lt;br/&gt;(e.g. 'a' = 97)"] --&gt; B
    E["Already encoded&lt;br/&gt;(e.g. 0)"] --&gt; B
    B --&gt; F["Unknown → 4"]

    style F fill:#d44,color:#fff
</pre>

<p>The following code is just a very straightforward encoding/decoding protocol. However, this enables us to do some more advanced stuff in future topics.</p>
<pre class="playground"><code class="language-rust edition2024">/// Convert ASCII to our own 2-bit encoded nt.
fn encode(nt_decoded: u8) -&gt; u8 {
    match nt_decoded {
        b'A' =&gt; 0,
        b'C' =&gt; 1,
        b'G' =&gt; 2,
        b'T' =&gt; 3,
        _ =&gt; panic!("Invalid nt {nt_decoded}"),
    }
}

/// Convert our own 2-bit encoded nt to ASCII.
fn decode(nt_encoded: u8) -&gt; u8 {
    match nt_encoded {
        0 =&gt; b'A',
        1 =&gt; b'C',
        2 =&gt; b'G',
        3 =&gt; b'T',
        _ =&gt; panic!("Invalid nt {nt_encoded}"),
    }
}

/// Reverse complement an ASCII base.
fn reverse(nt: u8) -&gt; u8 {
    return decode(3 - encode(nt));
}

/// Reverse complement a nucleotide sequence.
fn reverse_complement(nt_string: &amp;[u8]) -&gt; Vec&lt;u8&gt; {
    nt_string.iter().rev().map(|nt| reverse(*nt)).collect()
}

fn main() {
    // Reverse complement a single nucleotide.
    assert_eq!(reverse(b'A'), b'T');
    assert_eq!(reverse(b'T'), b'A');
    assert_eq!(reverse(b'C'), b'G');
    assert_eq!(reverse(b'G'), b'C');

    // We can also reverse complement a nucleotide sequence.
    assert_eq!(reverse_complement(b"AAAA"), b"TTTT");
    assert_eq!(reverse_complement(b"ATCG"), b"CGAT");
}
</code></pre>
<h2 id="using-a-lookup-table"><a class="header" href="#using-a-lookup-table">Using a lookup table</a></h2>
<p>We used match statements to encode and decode nucleotides, which works. However, we only handle the canonical bases <code>{A,C,G,T}</code>. This is not ideal, because our FASTA/Q file might contain soft masked bases <code>{a,c,g,t}</code> or hard masked bases <code>N</code>.</p>
<p>We could just extend our match statement to handle this, but we still have not safe-guarded against any other ambiguous nucleotide that we might encounter. A better approach is to use a compile-time lookup table that supports all 256 ASCII characters, where all irrelevant characters are set to 4.</p>
<pre class="playground"><code class="language-rust edition2024">const LOOKUP_TABLE: [u8; 256] = [
	0, 1, 2, 3,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 0, 4, 1,  4, 4, 4, 2,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  3, 3, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 0, 4, 1,  4, 4, 4, 2,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  3, 3, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4
];

fn main() {
    LOOKUP_TABLE.iter().enumerate().for_each(|(index, value)| {
        if *value != 4 {
            println!("[{index}] {} -&gt; {}", index as u8 as char, value);
        }
    });
}</code></pre>
<p>Run the code and inspect the output. Using a lookup table, we are able to map <code>{A,C,G,T,U,a,c,g,t,u}</code> to their corresponding encodings. This means we handle both upper and lowercase nucleotides, and also get U/u for free, meaning that we can now handle RNA as well.</p>
<p>However, we see that the first four values at index <code>[0], [1], [2], [3]</code> map to some weird characters. ASCII characters less than 32 are not actually printable characters, but rather control characters where <code>0, 1, 2, 3</code> correspond to null, start of heading, start of text and end of text respectively.</p>
<p>That does not make any sense. However, it does enable us to map already encoded nucleotides to themselves, which could serve as some kind of redundancy if we ever would have a mix of encoded and non-encoded nucleotides.</p>
<pre class="playground"><code class="language-rust edition2024"><span class="boring">const LOOKUP_TABLE: [u8; 256] = [
</span><span class="boring">	0, 1, 2, 3,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 0, 4, 1,  4, 4, 4, 2,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  3, 3, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 0, 4, 1,  4, 4, 4, 2,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  3, 3, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,
</span><span class="boring">	4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4,  4, 4, 4, 4
</span><span class="boring">];
</span>// [...]

fn main() {
    // We have a mix of non-encoded and encoded nucleotides.
    let mix_encoded: &amp;[u8] = &amp;[65, 65, 0, 0]; // AAAA

    // Encode all nucleotides.
    let all_encoded: Vec&lt;u8&gt; = mix_encoded.iter().map(|nt| LOOKUP_TABLE[*nt as usize]).collect();

    assert_eq!(all_encoded, vec![0, 0, 0, 0]);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="basics-of-alignment"><a class="header" href="#basics-of-alignment">Basics Of Alignment</a></h1>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>In bioinformatics, alignment is the process of determining how well biological sequences match to each other. Usually, we refer to the sequences as the <code>query</code> and <code>subject</code> respectively. For simplicity, we’ll assume that the <code>query</code> and <code>subject</code> both are single sequences.</p>
<p>There are three important alignment features to understand:</p>
<ul>
<li>Match.</li>
<li>Mismatch.</li>
<li>Insertion/Deletion.</li>
</ul>
<p>In the following alignment, matches are shown with a vertical bar <code>|</code>, mismatches as asterisks <code>*</code> and insertions or deletions as hyphens <code>-</code>.</p>
<pre>
query   AGCGACTCGTGCTCGA-CTT
        | |||||||*|||||| |||
subject A-CGACTCGAGCTCGAGCTT
</pre>

<h2 id="definitions"><a class="header" href="#definitions">Definitions</a></h2>
<ul>
<li>
<p><code>Query length</code> - The length of the query sequence. Here, we need to be a bit careful about if we mean either the original query length, or the length of the aligned part of the query.</p>
</li>
<li>
<p><code>Subject length</code> - The length of the subject sequence (either original or aligned, same reasoning as for query).</p>
</li>
<li>
<p><code>Alignment length</code> - The length of the aligned part between the query and subject.</p>
</li>
<li>
<p><code>Percent identity</code> - <code>100 * (num_matches / alignment_length)</code>. Here, we also need to be a bit careful since this metric only considers the aligned part of the query and subject. Theoretically, if our query and subject are of length 100, but they align only in the first 10 bases with no mismatches, this would be <code>percent identity</code> = <code>100</code> * (<code>10</code> / <code>10</code>) = <code>100</code>.</p>
</li>
<li>
<p><code>Fraction aligned (query)</code> - <code>alignment_length / query_length</code> (how much of the query is aligned). Here, we use the original query length.</p>
</li>
<li>
<p><code>Fraction aligned (subject)</code> - <code>alignment_length / subject_length</code> (how much of the subject is aligned). Here, we use the original subject length.</p>
</li>
</ul>
<p>In the example below, we have the following alignment metrics:</p>
<pre>
query   CATCGT
         ||||
subject  ATCG
</pre>

<ul>
<li><code>Query length</code> = <code>6</code> (original) or <code>4</code> (aligned).</li>
<li><code>Subject length</code> = <code>4</code> (original and aligned).</li>
<li><code>Alignment length</code> = <code>4</code>.</li>
<li><code>Percent Identity</code> = <code>100</code>.</li>
<li><code>Fraction aligned (query)</code> = <code>4</code> / <code>6</code> = <code>0.67</code>.</li>
<li><code>Fraction aligned (subject)</code> = <code>4</code> / <code>4</code> = <code>1.0</code>.</li>
</ul>
<h2 id="types-of-alignments"><a class="header" href="#types-of-alignments">Types Of Alignments</a></h2>
<p>There are three basic types of alignments:</p>
<ul>
<li><code>Global Alignment</code> - Aligns the entire query against the entire subject. Suitable if query and subject are of similar length, or one expects the entire query to align against the entire subject. An example is aligning two very similar genomes of roughly the same length.</li>
</ul>
<pre>
        ATCGATCG
        ||||||||
        ATCGATCG
</pre>

<ul>
<li><code>Semi Global Alignment</code> - Fully aligns the shorter of query/subject. An example is trying to align a gene (shorter) against an entire genome (longer).</li>
</ul>
<pre>
        CCCATCGTTT
           ||||
           ATCG
</pre>

<ul>
<li><code>Local Alignment</code> - Allows partial alignment of the query against the subject. This is the type of alignments that <a href="https://pubmed.ncbi.nlm.nih.gov/2231712/">BLAST</a> outputs.</li>
</ul>
<pre>
        CCCATCGTTT
           ||||
        GGGATCGAAA
</pre>

<div style="break-before: page; page-break-before: always;"></div>
<h1 id="hamming-distance"><a class="header" href="#hamming-distance">Hamming Distance</a></h1>
<p>The <a href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming distance</a> is defined as the number of positions between two strings of equal length that are different. Hence, it measures the number of substitutions needed to convert one string to the other. This also means that it is a kind of <code>global alignment</code> that only supports substitutions.</p>
<p>In the example below, the Hamming distance is 1.</p>
<pre>
query   ATCTACCG
        |||||*||
subject ATCTATCG
</pre>

<pre class="playground"><code class="language-rust edition2024">use std::iter::zip;

fn hamming_distance(query: &amp;str, subject: &amp;str) -&gt; usize {
    assert_eq!(query.len(), subject.len());

    let mut distance = 0;

    for (query_nt, subject_nt) in zip(query.chars(), subject.chars()) {
        if query_nt != subject_nt {
            distance += 1;
        }
    }

    return distance;
}

fn main() {
    assert_eq!(hamming_distance("ATCG", "ATCG"), 0);
    assert_eq!(hamming_distance("ATCG", "TTCG"), 1);
    // Our function can actually handle non-nucleotide strings.
    assert_eq!(hamming_distance("Hello", "Heiol"), 3);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="edit-distance"><a class="header" href="#edit-distance">Edit Distance</a></h1>
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<p>In contrast to the Hamming distance, the <a href="https://en.wikipedia.org/wiki/Edit_distance">Edit distance</a> allows for the query and subject to be different lengths, but it is still a global alignment. There are multiple kinds of Edit distances, of which the <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> is probably the most common. This distance allows for insertions, deletions and substitutions, which is highly suitable for alignment of biological sequences.</p>
<p>The implementation of the Levenshtein distance is more complex than the Hamming distance and requires us to use some dynamic programming. The goal is to use as few insertions, deletions and substitutions as possible to turn one string into the other. We need to be <em>exhaustive</em> since we do not know beforehand what is the optimal solution to this problem.</p>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<p>To solve this problem, we need a two dimensional array (two dimensions because we have two sequences). The layout will look something like this:</p>
<pre>
    A   T   C   G (query)

A   -   -   -   -

T   -   -   -   -

C   -   -   -   -

G   -   -   -   -

(subject)
</pre>

<p>We want to traverse this array from the start, until we have used up the entire query and subject. We can do this in three different ways:</p>
<pre class="mermaid">graph LR
    A["(i-1, j-1)"] -- "Diagonal&lt;br/&gt;Match / Mismatch&lt;br/&gt;consume both" --&gt; D["(i, j)"]
    B["(i, j-1)"] -- "Right →&lt;br/&gt;Deletion in subject&lt;br/&gt;consume query" --&gt; D
    C["(i-1, j)"] -- "Down ↓&lt;br/&gt;Deletion in query&lt;br/&gt;consume subject" --&gt; D
</pre>

<ul>
<li>A diagonal step means we take a step in both the query and subject (we “consume” both the query and the subject). Depending on the nucleotide we have in the current column (query) and row (subject), this is either a <em>match</em> or a <em>mismatch</em>.</li>
<li>A step to the right means we take a step only in the query direction (we “consume” the query). This signifies a <em>deletion</em> in the subject sequence (we don’t consume it).</li>
<li>A step downwards means we take a step only in the subject direction (we “consume” the subject). This signifies a <em>deletion</em> in the query sequence (we don’t consume it).</li>
</ul>
<hr>
<p>The following path corresponds only to matches between the query and the subject:</p>
<pre>
    A   T   C   G

A   *   -   -   -

T   -   *   -   -

C   -   -   *   -

G   -   -   -   *
</pre>

<p>With the equivalent alignment:</p>
<pre>
query   ATCG
        ||||
subject ATCG
</pre>

<hr>
<p>The following path corresponds to another alignment between the query and the subject:</p>
<pre>
    A   T   C   G

A   *   -   -   -

T   *   -   -   -

C   *   -   -   -

G   *   *   *   *
</pre>

<p>With the equivalent alignment:</p>
<pre>
query   A---TCG
        |
subject ATCG---
</pre>

<hr>
<p>With this in mind, how do we choose the best alignment? We clearly see that the first alignment is a lot better than the second. However, we need to quantify this somehow. The solution is to associate costs:</p>
<ul>
<li>Match costs 0.</li>
<li>Mismatch costs 1.</li>
<li>Insertion/Deletion costs 1.</li>
</ul>
<p>The goal is to minimize this cost to generate the best alignment possible.</p>
<p>We can make another observation, which is that for a given position <code>(i, j)</code> the value in this position, <code>array[i][j]</code>, is dependent on the three adjacent values <code>array[i-1][j-1]</code>, <code>array[i][j-1]</code> and <code>array[i-1][j]</code>. Namely, we want the minimum value from either of these three values, plus the additional cost to get to <code>(i, j)</code>, which can be match, mismatch, insertion or deletion:</p>
<pre><code>array[i][j] = min(array[i-1][j-1] + cost_of_match_or_mismatch,
                  array[i][j-1] + cost_of_insertion_deletion,
                  array[i-1,j] + cost_of_insertion_deletion)
</code></pre>
<p>Here, we might realize something. What if there are multiple alignments that generate the same final score? This depends on how we define the costs for matches, mismatches and insertions/deletions AND actually on the order of the arguments in the min function. Min functions usually return the first minimum value if there is a tie. This is something to keep in mind. For now however, we’ll just ignore this.</p>
<p>Finally, it also makes sense to initialize a starting position outside of the query and the subject because we could potentially have insertions and deletions at the start. We’ll set this value to 0, because there is a match of nothing against nothing. Our final array will look like:</p>
<pre>
            A   T   C   G (query)

        0   -   -   -   -

    A   -   -   -   -   -

    T   -   -   -   -   -

    C   -   -   -   -   -

    G   -   -   -   -   -

(subject)
</pre>

<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>Here is a very naive implementation of the Levenshtein distance. There are many, many ways to optimize this, however it is out of scope in this book.</p>
<pre class="playground"><code class="language-rust edition2024">#[derive(Clone, Copy)]
enum AlignmentType {
    Match,
    Mismatch,
    DeletionQuery,
    DeletionSubject,
}

fn print_array(array: &amp;Vec&lt;Vec&lt;usize&gt;&gt;) {
    for v in array {
        let values: String = v
            .iter()
            .map(|v| v.to_string())
            .collect::&lt;Vec&lt;_&gt;&gt;()
            .join("\t");
        println!("{values}");
    }
    println!("\n");
}

fn get_alignment_cost(aln: AlignmentType) -&gt; usize {
    match aln {
        AlignmentType::Match =&gt; 0,
        AlignmentType::Mismatch =&gt; 1,
        AlignmentType::DeletionQuery =&gt; 1,
        AlignmentType::DeletionSubject =&gt; 1,
    }
}

fn levenshtein_distance(s1: &amp;str, s2: &amp;str) -&gt; usize {
    // We take the number of rows from the subject.
    let m = s2.len();

    // We take the number of columns from the query.
    let n = s1.len();

    // Store array as a vector of vectors.
    let mut array: Vec&lt;Vec&lt;usize&gt;&gt; = Vec::new();

    // Initialize array.
    for _ in 0..m + 1 {
        array.push(vec![0; n + 1]);
    }

    assert!(array[0].len() == s1.len() + 1);
    assert!(array.len() == s2.len() + 1);

    // We move in the i direction (down), subject is consumed and query is deleted.
    for i in 1..m + 1 {
        array[i][0] = i * get_alignment_cost(AlignmentType::DeletionQuery);
    }
    // We move in the j direction (right), query is consumed and subject is deleted.
    for j in 1..n + 1 {
        array[0][j] = j * get_alignment_cost(AlignmentType::DeletionSubject);
    }

    for i in 1..m + 1 {
        for j in 1..n + 1 {
            // For a diagonal move, we need to check if we have a match or mismatch.
            let match_or_mismatch = match s1.chars().nth(j - 1) == s2.chars().nth(i - 1) {
                true =&gt; array[i - 1][j - 1] + get_alignment_cost(AlignmentType::Match),
                false =&gt; array[i - 1][j - 1] + get_alignment_cost(AlignmentType::Mismatch),
            };

            // We have moved in the j direction so query is consumed and subject is deleted
            let deletion_subject =
                array[i][j - 1] + get_alignment_cost(AlignmentType::DeletionSubject);

            // We have moved in the j direction so subject is consumed and query is deleted
            let deletion_query = array[i - 1][j] + get_alignment_cost(AlignmentType::DeletionQuery);

            // Collect these into a vector.
            let previous_values: Vec&lt;usize&gt; =
                vec![match_or_mismatch, deletion_query, deletion_subject];

            // NOTE - depending on how we define the order of previous_values
            // and our alignment costs, we might get different alignment results.
            let previous_min_value = previous_values.iter().min().unwrap();

            // Update array for current value.
            array[i][j] = *previous_min_value;
        }
    }

    return array[m][n];
}

fn main() {
    assert_eq!(levenshtein_distance("ATCG", "ATCG"), 0);
    assert_eq!(levenshtein_distance("AAAAA", "A"), 4);
    assert_eq!(levenshtein_distance("ATATAT", "GGGGGG"), 6);
    assert_eq!(levenshtein_distance("ATCGATCG", "ATCGTTCG"), 1);
}</code></pre>
<p>Yay! We have now implemented another kind of <em>global aligner</em> that supports matches, mismatches, insertions and deletions.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="adding-traceback"><a class="header" href="#adding-traceback">Adding Traceback</a></h1>
<h2 id="introduction-3"><a class="header" href="#introduction-3">Introduction</a></h2>
<p>We have successfully created a basic edit distance aligner! However, we don’t just want to return a simple usize of the distance between two strings. We also want to <em>visualize</em> the alignment.</p>
<p>To make this work, we need to implement a traceback that enables us to generate the optimal alignment after we are done filling out the array. Let’s look at the final array after aligning <code>ATCG</code> to <code>ATCG</code>:</p>
<pre>
            A   T   C   G (query)

        0   1   2   3   4

    A   1   0   1   2   3

    T   2   1   0   1   2

    C   3   2   1   0   1

    G   4   3   2   1   0 last cell

(subject)
</pre>

<p>In this example, we clearly see that the traceback should be just traversing diagonally. But how do we implement this programmatically?</p>
<p>We know the origin for each cell in the array, because we have defined it as <code>array[i][j] = min(diagonal, left, up)</code>. We can store the origin of each cell in a <code>HashMap</code> and start the traceback from the last cell until we reach the start. This is rather inefficient, but it’ll work for now.</p>
<p>For simplicity, we’ll save each cells origin along with the alignment type.</p>
<h2 id="implementation-1"><a class="header" href="#implementation-1">Implementation</a></h2>
<pre class="playground"><code class="language-rust editable edition2024">use std::collections::HashMap;

#[derive(Clone, Copy)]
enum AlignmentType {
    Match,
    Mismatch,
    DeletionQuery,
    DeletionSubject,
}

fn print_array(array: &amp;Vec&lt;Vec&lt;usize&gt;&gt;) {
    for v in array {
        let values: String = v
            .iter()
            .map(|v| v.to_string())
            .collect::&lt;Vec&lt;_&gt;&gt;()
            .join("\t");
        println!("{values}");
    }
    println!("\n");
}

/// We could modify these if we want.
fn get_alignment_cost(aln: AlignmentType) -&gt; usize {
    match aln {
        AlignmentType::Match =&gt; 0,
        AlignmentType::Mismatch =&gt; 1,
        AlignmentType::DeletionQuery =&gt; 1,
        AlignmentType::DeletionSubject =&gt; 1,
    }
}

fn levenshtein_distance(
    s1: &amp;str,
    s2: &amp;str,
) -&gt; (
    Vec&lt;Vec&lt;usize&gt;&gt;,
    HashMap&lt;(usize, usize), ((usize, usize), AlignmentType)&gt;,
) {
    // We take the number of rows from the subject.
    let m = s2.len();

    // We take the number of columns from the query.
    let n = s1.len();

    // Store array as a vector of vectors.
    let mut array: Vec&lt;Vec&lt;usize&gt;&gt; = Vec::new();

    // Initialize array.
    for _ in 0..m + 1 {
        array.push(vec![0; n + 1]);
    }

    assert!(array[0].len() == s1.len() + 1);
    assert!(array.len() == s2.len() + 1);

    // We store the origin of each element in the array.
    let mut traceback: HashMap&lt;(usize, usize), ((usize, usize), AlignmentType)&gt; = HashMap::new();

    // We move in the i direction (down), subject is consumed and query is deleted.
    for i in 1..m + 1 {
        array[i][0] = i * get_alignment_cost(AlignmentType::DeletionQuery);
        // Remember to add trace.
        traceback.insert((i, 0), ((i - 1, 0), AlignmentType::DeletionQuery));
    }
    // We move in the j direction (right), query is consumed and subject is deleted.
    for j in 1..n + 1 {
        array[0][j] = j * get_alignment_cost(AlignmentType::DeletionSubject);
        // Remember to add trace.
        traceback.insert((0, j), ((0, j - 1), AlignmentType::DeletionSubject));
    }

    for i in 1..m + 1 {
        for j in 1..n + 1 {
            // For a diagonal move, we need to check if we have a match or mismatch.
            let match_or_mismatch = match s1.chars().nth(j - 1) == s2.chars().nth(i - 1) {
                true =&gt; (
                    (i - 1, j - 1),
                    array[i - 1][j - 1] + get_alignment_cost(AlignmentType::Match),
                    AlignmentType::Match,
                ),
                false =&gt; (
                    (i - 1, j - 1),
                    array[i - 1][j - 1] + get_alignment_cost(AlignmentType::Mismatch),
                    AlignmentType::Mismatch,
                ),
            };

            // We have moved in the j direction so query is consumed and subject is deleted
            let deletion_subject = (
                (i, j - 1),
                array[i][j - 1] + get_alignment_cost(AlignmentType::DeletionSubject),
                AlignmentType::DeletionSubject,
            );

            // We have moved in the j direction so subject is consumed and query is deleted
            let deletion_query = (
                (i - 1, j),
                array[i - 1][j] + get_alignment_cost(AlignmentType::DeletionQuery),
                AlignmentType::DeletionQuery,
            );

            // EDIT ME! Try switching the order of the
            // elements and see if this changes the traceback.
            let previous_values: Vec&lt;((usize, usize), usize, AlignmentType)&gt; =
                vec![match_or_mismatch, deletion_query, deletion_subject];


            let (previous_index, previous_value, alignment_type) =
                previous_values.iter().min_by_key(|x| x.1).unwrap();

            // Add trace for current element.
            traceback.insert((i, j), (*previous_index, *alignment_type));

            // Update array for current value.
            array[i][j] = *previous_value;
        }
    }

    return (array, traceback);
}

fn get_traceback(
    traceback: HashMap&lt;(usize, usize), ((usize, usize), AlignmentType)&gt;,
    s1: &amp;str,
    s2: &amp;str,
) {
    let mut m = s2.len();
    let mut n = s1.len();

    // Aligned part of s1 and s2 (including deletions).
    let mut s1_aln: Vec&lt;char&gt; = Vec::new();
    let mut s2_aln: Vec&lt;char&gt; = Vec::new();

    // We'll use "|" for match, "*" for mismatch and " " for deletion.
    let mut matches_aln: Vec&lt;char&gt; = Vec::new();

    loop {
        if (m, n) == (0, 0) {
            break;
        }

        let ((i, j), aln_type) = traceback.get(&amp;(m, n)).unwrap();

        match aln_type {
            AlignmentType::Match =&gt; {
                let s1_char = s1.chars().nth(*j).unwrap();
                let s2_char = s2.chars().nth(*i).unwrap();
                s1_aln.push(s1_char);
                s2_aln.push(s2_char);
                matches_aln.push('|');
            }
            AlignmentType::Mismatch =&gt; {
                let s1_char = s1.chars().nth(*j).unwrap();
                let s2_char = s2.chars().nth(*i).unwrap();
                s1_aln.push(s1_char);
                s2_aln.push(s2_char);
                matches_aln.push('*');
            }
            AlignmentType::DeletionQuery =&gt; {
                s1_aln.push('-');
                s2_aln.push(s2.chars().nth(*i).unwrap());
                matches_aln.push(' ');
            }
            AlignmentType::DeletionSubject =&gt; {
                s1_aln.push(s1.chars().nth(*j).unwrap());
                s2_aln.push('-');
                matches_aln.push(' ');
            }
        }
        m = *i;
        n = *j;
    }

    let s1_aln_fwd: String = s1_aln.iter().rev().collect();
    let s2_aln_fwd: String = s2_aln.iter().rev().collect();
    let matches_aln_fwd: String = matches_aln.iter().rev().collect();

    println!("{}", s1_aln_fwd);
    println!("{}", matches_aln_fwd);
    println!("{}\n", s2_aln_fwd);
}

fn align(s1: &amp;str, s2: &amp;str) {
    let (_, traceback) = levenshtein_distance(s1, s2);

    get_traceback(traceback, s1, s2);
}

fn main() {
    align("ATCG", "ATCG");
    align("A", "T");
    align("ATCG", "ATCGATCG");
    align("TTTTTTTTTTTTTTTTA", "ATTTTTTTTTTTTT");
}</code></pre>
<p>This is awesome! We have created a basic aligner that uses the Levenshtein distance and supports non-equal length strings. Some good exercises (left up to the reader) would be:</p>
<ul>
<li>Calculating percent identity and other relevant alignment metrics.</li>
<li>Thinking about how the code can be optimized (trust me, it is not).
<ul>
<li>For example, do we really need to keep track of all rows and columns at the same time?</li>
<li>How can we optimize the traceback strategy?</li>
</ul>
</li>
<li>Writing a bunch of tests to make sure our code works (and fix it if it doesn’t).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="smith-waterman-algorithm"><a class="header" href="#smith-waterman-algorithm">Smith-Waterman algorithm</a></h1>
<h2 id="introduction-4"><a class="header" href="#introduction-4">Introduction</a></h2>
<p>In the previous section, we implemented a global aligner with traceback. Now, we want to improve on this approach to handle local alignment. The difference here is that we do not require the entire query and subject to be aligned end-to-end.</p>
<p>In the example below, we just align the middle part of the query and subject and ignore (softmask) the surrounding regions because we have no significant match there.</p>
<pre>
query   ttATCGtt
          ||||
subject ggATCGgg
</pre>

<h2 id="modifications"><a class="header" href="#modifications">Modifications</a></h2>
<p>We need to make some changes to our global aligner in order for it to handle local alignments. We’ll change the concept of cost and instead call it a score.</p>
<ul>
<li>
<p>We define the scoring procedure as:</p>
<ul>
<li>A match increases the score by 1.</li>
<li>A mismatch decreases the score by 1.</li>
<li>An insertion/deletion decreases the score by 1.</li>
</ul>
</li>
<li>
<p>We also make the following changes:</p>
<ul>
<li>A score value must be non-negative (&gt;= 0).</li>
<li>All cells (i, 0) and (0, j) are initialized to 0.</li>
<li>Traceback starts at the cell with the highest score and ends when we reach a 0.</li>
</ul>
</li>
</ul>
<p>A local alignment array for aligning <code>TTATCGTT</code> to <code>GGATCGGG</code> would look like:</p>
<pre>
            T   T   A   T   C   G   T   T   (query)

        0   0   0   0   0   0   0   0   0

    G   0   -   -   -   -   -   -   -   -

    G   0   -   -   -   -   -   -   -   -

    A   0   -   -   -   -   -   -   -   -

    T   0   -   -   -   -   -   -   -   -

    C   0   -   -   -   -   -   -   -   -

    G   0   -   -   -   -   -   -   -   -

    G   0   -   -   -   -   -   -   -   -

    G   0   -   -   -   -   -   -   -   -

(subject)
</pre>

<p>The procedure will be:</p>
<ul>
<li>Fill out the entire array.</li>
<li>Identify the cell with the highest score.</li>
<li>Traceback from there until we reach a 0.</li>
</ul>
<h2 id="implementation-2"><a class="header" href="#implementation-2">Implementation</a></h2>
<p>It turns out that implementing the Smith-Waterman algorithm and then printing out the alignment, including the soft masked parts of the query and subject, is not straightforward and includes a bit of extra lines of code. However, here is an example of an implementation:</p>
<pre class="playground"><code class="language-rust editable edition2024">use std::collections::HashMap;

#[derive(Clone, Copy)]
enum AlignmentType {
    Match,
    Mismatch,
    DeletionQuery,
    DeletionSubject,
}

fn print_array(array: &amp;Vec&lt;Vec&lt;i32&gt;&gt;) {
    for v in array {
        let values: String = v
            .iter()
            .map(|v| v.to_string())
            .collect::&lt;Vec&lt;_&gt;&gt;()
            .join("\t");
        println!("{values}");
    }
    println!("\n");
}

/// We could modify these if we want.
fn get_alignment_cost(aln: AlignmentType) -&gt; i32 {
    match aln {
        AlignmentType::Match =&gt; 1,
        AlignmentType::Mismatch =&gt; -1,
        AlignmentType::DeletionQuery =&gt; -1,
        AlignmentType::DeletionSubject =&gt; -1,
    }
}

fn levenshtein_distance(
    s1: &amp;str,
    s2: &amp;str,
) -&gt; (
    Vec&lt;Vec&lt;i32&gt;&gt;,
    HashMap&lt;(usize, usize), ((usize, usize), AlignmentType)&gt;,
    (usize, usize),
) {
    // We take the number of rows from the subject.
    let m = s2.len();

    // We take the number of columns from the query.
    let n = s1.len();

    assert!(m &gt; 0);
    assert!(n &gt; 0);

    // Store array as a vector of vectors.
    let mut array: Vec&lt;Vec&lt;i32&gt;&gt; = Vec::new();

    // Initialize array.
    for _ in 0..m + 1 {
        array.push(vec![0; n + 1]);
    }

    assert!(array[0].len() == s1.len() + 1);
    assert!(array.len() == s2.len() + 1);

    let mut max_score: (i32, (usize, usize)) = (0, (0, 0));

    // We store the origin of each element in the array.
    let mut traceback: HashMap&lt;(usize, usize), ((usize, usize), AlignmentType)&gt; = HashMap::new();

    // We move in the i direction (down), subject is consumed and query is deleted.
    for i in 1..m + 1 {
        array[i][0] = 0;
        // Remember to add trace.
        traceback.insert((i, 0), ((i - 1, 0), AlignmentType::DeletionQuery));
    }
    // We move in the j direction (right), query is consumed and subject is deleted.
    for j in 1..n + 1 {
        array[0][j] = 0;
        // Remember to add trace.
        traceback.insert((0, j), ((0, j - 1), AlignmentType::DeletionSubject));
    }

    for i in 1..m + 1 {
        for j in 1..n + 1 {
            // For a diagonal move, we need to check if we have a match or mismatch.
            let match_or_mismatch = match s1.chars().nth(j - 1) == s2.chars().nth(i - 1) {
                true =&gt; (
                    (i - 1, j - 1),
                    std::cmp::max(
                        0,
                        array[i - 1][j - 1] + get_alignment_cost(AlignmentType::Match),
                    ),
                    AlignmentType::Match,
                ),
                false =&gt; (
                    (i - 1, j - 1),
                    std::cmp::max(
                        0,
                        array[i - 1][j - 1] + get_alignment_cost(AlignmentType::Mismatch),
                    ),
                    AlignmentType::Mismatch,
                ),
            };

            // We have moved in the j direction so query is consumed and subject is deleted
            let deletion_subject = (
                (i, j - 1),
                std::cmp::max(
                    0,
                    array[i][j - 1] + get_alignment_cost(AlignmentType::DeletionSubject),
                ),
                AlignmentType::DeletionSubject,
            );

            // We have moved in the j direction so subject is consumed and query is deleted
            let deletion_query = (
                (i - 1, j),
                std::cmp::max(
                    0,
                    array[i - 1][j] + get_alignment_cost(AlignmentType::DeletionQuery),
                ),
                AlignmentType::DeletionQuery,
            );

            // EDIT ME! Try switching the order of the
            // elements and see if this changes the traceback.
            let previous_values: Vec&lt;((usize, usize), i32, AlignmentType)&gt; =
                vec![match_or_mismatch, deletion_query, deletion_subject];

            let (previous_index, previous_value, alignment_type) =
                previous_values.iter().max_by_key(|x| x.1).unwrap();

            // Add trace for current element.
            traceback.insert((i, j), (*previous_index, *alignment_type));

            // Update array for current value.
            array[i][j] = *previous_value;

            // Update max array value and its index
            max_score = *vec![(array[i][j], (i, j)), max_score]
                .iter()
                .max_by_key(|x| x.0)
                .unwrap();
        }
    }

    return (array, traceback, max_score.1);
}

fn to_lowercase(nt: char) -&gt; char {
    match nt {
        'A' =&gt; 'a',
        'C' =&gt; 'c',
        'G' =&gt; 'g',
        'T' =&gt; 't',
        _ =&gt; panic!(),
    }
}

fn get_traceback(
    array: &amp;Vec&lt;Vec&lt;i32&gt;&gt;,
    traceback: HashMap&lt;(usize, usize), ((usize, usize), AlignmentType)&gt;,
    max_index: (usize, usize),
    s1: &amp;str,
    s2: &amp;str,
) {
    let (mut m, mut n) = max_index;

    // Aligned part of s1 and s2 (including deletions).
    let mut s1_aln: Vec&lt;char&gt; = Vec::new();
    let mut s2_aln: Vec&lt;char&gt; = Vec::new();

    // We'll use "|" for match, "*" for mismatch and " " for deletion.
    let mut matches_aln: Vec&lt;char&gt; = Vec::new();

    let mut m_c = m.clone();
    let mut n_c = n.clone();

    // Fill the left unaligned, we do this first because we iterate the alignment backwards.
    while m_c &lt;= s2.len() - 1 || n_c &lt;= s1.len() - 1 {
        match s1.chars().nth(n_c) {
            // We are still within s1, so we push the soft masked base.
            Some(nt) =&gt; s1_aln.push(to_lowercase(nt)),
            // We have reached the end of s1, so we push a placeholder.
            // Must be empty, otherwise the end of the alignment looks weird.
            None =&gt; s1_aln.push('\0'),
        }

        match s2.chars().nth(m_c) {
            // We are still within s2, so we push the soft masked base.
            Some(nt) =&gt; s2_aln.push(to_lowercase(nt)),
            // We have reached the end of s2, so we push a placeholder.
            // Must be empty, otherwise the end of the alignment looks weird.
            None =&gt; s2_aln.push('\0'),
        }

        matches_aln.push(' ');
        m_c += 1;
        n_c += 1;
    }

    s1_aln.reverse();
    s2_aln.reverse();

    loop {
        if array[m][n] == 0 {
            break;
        }

        let ((i, j), aln_type) = traceback.get(&amp;(m, n)).unwrap();

        match aln_type {
            AlignmentType::Match =&gt; {
                let s1_char = s1.chars().nth(*j).unwrap();
                let s2_char = s2.chars().nth(*i).unwrap();

                s1_aln.push(s1_char);
                s2_aln.push(s2_char);
                matches_aln.push('|');
            }
            AlignmentType::Mismatch =&gt; {
                let s1_char = s1.chars().nth(*j).unwrap();
                let s2_char = s2.chars().nth(*i).unwrap();
                s1_aln.push(s1_char);
                s2_aln.push(s2_char);
                matches_aln.push('*');
            }
            AlignmentType::DeletionQuery =&gt; {
                s1_aln.push('-');
                s2_aln.push(s2.chars().nth(*i).unwrap());
                matches_aln.push(' ');
            }
            AlignmentType::DeletionSubject =&gt; {
                s1_aln.push(s1.chars().nth(*j).unwrap());
                s2_aln.push('-');
                matches_aln.push(' ');
            }
        }
        m = *i;
        n = *j;
    }

    // Fill the right unaligned part, we do this last because we iterate the alignment backwards.
    let mut m = m as i32;
    let mut n = n as i32;

    // We iterate until we have reached the end of both s1 and s2.
    while m &gt;= 1 || n &gt;= 1 {
        // We are still within s1, so we push the soft masked base.
        if n &gt;= 1 {
            match s1.chars().nth((n-1) as usize) {
                Some(nt) =&gt; s1_aln.push(to_lowercase(nt)),
                None =&gt; panic!("Position {n} is invalid."),
            }
        }
        // We have reached the end of s1, so we push a placeholder.
        else {
            s1_aln.push(' ');
        }

        // We are still within s2, so we push the soft masked base.
        if m &gt;= 1 {
            match s2.chars().nth((m-1) as usize) {
                Some(nt) =&gt; s2_aln.push(to_lowercase(nt)),
                None =&gt; panic!("Position {m} is invalid."),
            }
        }
        // We have reached the end of s2, so we push a placeholder.
        else {
            s2_aln.push(' ');
        }

        matches_aln.push(' ');
        m -= 1;
        n -= 1;
    }

    let s1_aln_fwd: String = s1_aln.iter().rev().collect();
    let s2_aln_fwd: String = s2_aln.iter().rev().collect();
    let matches_aln_fwd: String = matches_aln.iter().rev().collect();

    println!("{}", s1_aln_fwd);
    println!("{}", matches_aln_fwd);
    println!("{}\n", s2_aln_fwd);
}

fn align(s1: &amp;str, s2: &amp;str) {
    let (array, traceback, max_index) = levenshtein_distance(s1, s2);

    get_traceback(&amp;array, traceback, max_index, s1, s2);
}

fn main() {
    align("ATCG", "ATCG");
    align("CCCATCGCCC", "GGGATCGGGTT");
    align("AAAAATAAAAA", "CCCCCTCCCCC");
    align("ATCG", "CCCATCGTTT");
}</code></pre>
<p>This is a very simple implementation of a local aligner. In practice, as a bioinformatician, one would use a highly optimized and widely established tool. Some examples are:</p>
<ul>
<li><a href="https://github.com/jeffdaily/parasail">Parasail</a> - A SIMD accelerated C library.</li>
<li><a href="https://blast.ncbi.nlm.nih.gov/Blast.cgi">BLAST</a> - Uses the seed-and-extend approach.</li>
<li><a href="https://github.com/lh3/minimap2">Minimap2</a> - One of the fastest aligners out there.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="creating-a-desktop-app"><a class="header" href="#creating-a-desktop-app">Creating a desktop app</a></h1>
<p>We have now made our own local aligner, implemented entirely in Rust. It might not be the most efficient, but it works. Now, let us take this a step further and generate a desktop application that can visualize the alignment.</p>
<p>What we need to build it from scratch:</p>
<ul>
<li>Our alignment code (which we implemented in the previous section).</li>
<li>The <a href="https://dioxuslabs.com/">Dioxus</a> framework.</li>
<li>A bit of knowledge about HTML and CSS.</li>
</ul>
<p>We won’t go through the entire implementation from scratch. Instead:</p>
<ul>
<li>Make sure you are using a Linux operating system.</li>
<li>Install the Dioxus cli version <code>v0.7.0-alpha.3</code>.</li>
<li>Clone the <a href="https://github.com/OscarAspelin95/alignment_rs">repository</a>.</li>
<li>Enter the <code>alignment_rs</code> directory and run <code>dx serve</code>.</li>
<li>It might take several minutes to compile, but when done the desktop app should launch.</li>
</ul>
<p>Inspect the code to familiarize yourself with Dioxus. If you have used React before, the syntax might look familiar. Think of Dioxus as React for Rust. In short, the code:</p>
<ul>
<li>Checks the input for updates to the query and the subject.</li>
<li>Calls the aligner when Dioxus detects that the query or subject has changed.</li>
<li>Renders the alignment in real time.</li>
</ul>
<p>Note that calling the aligner every time either the query or subject has changed might be extremely inefficient for long sequences. However, in our case we have limited the input length to 80 nucleotides, which is short enough for the UI to be responsive.</p>
<p>Below is a preview of what the desktop app looks like.</p>
<img src="assets/alignment.gif" style="border-radius: 2em;">
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="resources"><a class="header" href="#resources">Resources</a></h1>
<p>Understanding the details of alignment can be tricky. However, here are some good resources for further reading:</p>
<ul>
<li><a href="https://www.youtube.com/@BenLangmead">Ben Langmead</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sequence_alignment">Wikipedia</a></li>
<li><a href="https://doi.org/10.1016/s0022-2836(05)80360-2">Original BLAST paper</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="kmers"><a class="header" href="#kmers">Kmers</a></h1>
<p>The concept of kmers is widely used in bioinformatics and is applied in concepts such as alignment and genome assembly. Here, we’ll just go through the basics.</p>
<p>Basically, kmers are just subsequences of a specific length. For example, in the following sequence we generate all consecutive kmers of length 3:</p>
<pre>
5' ATCGATCGATCG 3'

   ATC ATC ATC
    TCG TCG TCG
     CGA CGA
      GAT GAT
</pre>

<p>Note that our sequence length is 12 and the kmer length is 3. How many consecutive kmers can we generate? The answer is <code>len(sequence) - kmer_size + 1</code>, which in our case would <code>12 - 3 + 1 = 10</code>. But why this exact formula?</p>
<p>If we had <code>kmer_size = 1</code>, the number of kmers would be equal to the sequence length. We just slide along the sequence with a window size of 1. We are losing out on <em>zero</em> nucleotides.</p>
<p>If we had <code>kmer_size = 2</code>, we use a sliding window of length 2. However, we cannot use the last nucleotide in the sequence, because we need two nucleotides for our sliding window. We are losing out on <em>one</em> nucleotide.</p>
<p>We see a pattern here, which is that the number of kmers we can generate is the length of our sequence minus how many nucleotides in the end we are missing out on (which is one less than our kmer size).</p>
<p><code>num_kmers = len(sequence) - (kmer_size - 1) = len(sequence) - kmer_size + 1.</code></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="a-first-implementation"><a class="header" href="#a-first-implementation">A First Implementation</a></h1>
<p>For a naive implementation of kmers, we’ll just use a sliding window of the specified kmer size in the forward direction. For now, we skip the reverse complement.</p>
<pre class="playground"><code class="language-rust edition2024">fn kmerize(nt_string: &amp;[u8], kmer_size: usize) -&gt; Vec&lt;&amp;[u8]&gt; {
    assert!(kmer_size &lt;= nt_string.len());

    // Rust has a very handy windows function that works perfectly here.
    let kmers: Vec&lt;&amp;[u8]&gt; = nt_string.windows(kmer_size).collect();

    // Make sure we generated the correct number of kmers.
    assert_eq!(kmers.len(), nt_string.len() - kmer_size + 1);
    return kmers;
}

fn main() {
    assert_eq!(kmerize(b"AAAA", 2), vec![b"AA", b"AA", b"AA"]);
    assert_eq!(kmerize(b"ATCGATCG", 7), vec![b"ATCGATC", b"TCGATCG"]);
    assert_eq!(
        kmerize(b"AATTCCGG", 2),
        vec![b"AA", b"AT", b"TT", b"TC", b"CC", b"CG", b"GG"]
    );
}</code></pre>
<p>This naive implementation has several flaws that we need to handle:</p>
<ul>
<li>We currently don’t consider the reverse complement.</li>
<li>Once the reverse complement is handled, should we use all forward and all reverse kmers, or can we be smart about which kmers to pick?</li>
<li>We still use ASCII encoding, which takes up unnecessary amounts of storage.</li>
<li>Using a window function is not feasible when dealing with huge amounts of data. We need another approach.</li>
</ul>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>These flaws are addressed in the following chapters: <a href="#bit-shift-encoding">Bit Shift Encoding</a> replaces ASCII with 2-bit encoding, <a href="#forward-strand">Forward Strand</a> and <a href="#reverse-strand">Reverse Strand</a> handle both strands, and the <a href="#final-implementation">Final Implementation</a> combines everything into a canonical kmer generator.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="using-phred-scores"><a class="header" href="#using-phred-scores">Using Phred Scores</a></h1>
<p>Before we proceed with more efficient nucleotide encoding strategies, we’ll cover how phred scores can be used in kmer applications. For samples such as Oxford Nanopore, where the quality generally is lower than say Illumina, we can use phred scores to identify highly erroneous kmers. Use cases could be:</p>
<ul>
<li>Only keep high quality kmers for downstream analyses.</li>
<li>Sort a FASTQ file based on the number of high quality kmers in each read.</li>
<li>Calculate the expected number of error free kmers.</li>
</ul>
<p><a href="https://github.com/aljpetri/isONclust3">isONclust3</a> fundamentally uses some of these approaches as preprocessing steps. In the code below, we’ll re-implement isONclust3’s implementation of calculating the expected number of error free kmers.</p>
<p>In essence, we convert phred scores to error probabilities <code>p_e</code> for every nucleotide in the sequence. We can calculate the probability of the nucleotide being correctly called as <code>1-p_e</code>. For an arbitrary kmer of length <code>k</code>, we can calculate the probability of the entire kmer being correctly called as the product of the individual nucleotide probabilities.</p>
<p>\[ \prod_{i=1}^k 1-\text{p_e}_i \]</p>
<p>By repeating this calculation for every kmer across a sequence, we get the collection of all kmer probabilities. To get the expected number of error free kmers, we simply calculate the sum. Since we can generate <code>l-k+1</code> kmers of size <code>k</code> from a sequence of length <code>l</code>, we get:</p>
<p>\[ \sum_{n=1}^{l-k+1}\prod_{i=1}^k 1-\text{p_e}_i \]</p>
<p>where <code>n</code> is the position in the sequence and <code>i</code> is the position in a kmer.</p>
<pre class="playground"><code class="language-rust edition2024">fn phred_to_err(phred: u8) -&gt; f64 {
    10_f64.powf(-1.0 * ((phred - 33) as f64) / 10.0)
}

/// Re-implementation of
/// https://github.com/aljpetri/isONclust3/blob/main/src/main.rs#L59
fn exp_error_free_kmers(qual: &amp;[u8], kmer_size: usize) -&gt; f64 {
    let mut sum_exp = 0.0_f64;

    // Current probability product for a rolling kmer.
    let mut current_prod = 1.0_f64;

    // We'll use a circular buffer to store up to one kmer at a time.
    let mut buf = vec![1.0_f64; kmer_size];

    // We need to keep track of the index to know when to circle back in our buffer.
    let mut idx = 0_usize;

    for i in 0..qual.len() {
        let q = qual[i];
        let p_e = phred_to_err(q);

        // Probability that the base is correct.
        let p_corr = 1.0_f64 - p_e;

        // Include new base in kmer probability.
        current_prod *= p_corr;

        // We have reached the capacity of our circular buffer.
        // Adjust by dividing (remove) the value we'll overwrite.
        if i &gt;= kmer_size {
            let to_remove = buf[idx];
            current_prod /= to_remove;
        }

        // Add to our expected probability sum only for whole kmers.
        if i &gt;= kmer_size - 1 {
            sum_exp += current_prod;
        }

        // Add base probability to our circular buffer and adjust index.
        buf[idx] = p_corr;
        idx = (idx + 1) % kmer_size;
    }

    sum_exp
}

fn main() {
    let high_qual = exp_error_free_kmers(b"??????????", 5);
    let mid_qual = exp_error_free_kmers(b"5555555555", 5);
    let low_qual = exp_error_free_kmers(b"++++++++++", 5);

    println!("{}", high_qual);
    println!("{}", mid_qual);
    println!("{}", low_qual);

    // Higher quality scores should yield more expected error-free kmers.
    assert!(high_qual &gt; mid_qual);
    assert!(mid_qual &gt; low_qual);

    // All values should be between 0 and the maximum possible kmers (10 - 5 + 1 = 6).
    assert!(high_qual &gt; 0.0 &amp;&amp; high_qual &lt;= 6.0);
    assert!(low_qual &gt; 0.0 &amp;&amp; low_qual &lt;= 6.0);
}</code></pre>
<p>We see from the output that we get <code>f64</code> values out for the expected number of error free kmers. This might look odd, but it is in fact the <em>expected</em> value. Depending on what we want to do with the expected value, we may or may not want to round it.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="bit-shift-encoding"><a class="header" href="#bit-shift-encoding">Bit Shift Encoding</a></h1>
<h2 id="introduction-5"><a class="header" href="#introduction-5">Introduction</a></h2>
<p>To streamline our kmer generation function, we need to understand a bit about bit shifting and how computers interpret data. Computers are ridiculously fast at <a href="https://www.geeksforgeeks.org/dsa/all-about-bit-manipulation/">bitwise operations</a>. We won’t cover the details in this book, but we’ll go over the things we need in order for our kmer script to work properly.</p>
<p>In our case, we’ll use 2-bit encoding for our nucleotides:</p>
<ul>
<li><code>A</code> =&gt; <code>0b00</code> (0 in base 10)</li>
<li><code>C</code> =&gt; <code>0b01</code> (1 in base 10)</li>
<li><code>G</code> =&gt; <code>0b10</code> (2 in base 10)</li>
<li><code>T</code> =&gt; <code>0b11</code> (3 in base 10)</li>
</ul>
<h3 id="bit-shift"><a class="header" href="#bit-shift">Bit shift</a></h3>
<p>A <code>left shift</code> is defined as an operation in which the bits in a binary number are shifted to the left. The most significant bit (leftmost) is lost, and the least significant bit (rightmost) is shifted after which a zero is added.</p>
<ul>
<li>Example: <code>0010 &lt;&lt; 1 = 0100</code></li>
</ul>
<p>A <code>right shift</code> does the opposite.</p>
<ul>
<li>Example: <code>0100 &gt;&gt; 1 = 0010</code></li>
</ul>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    // Perform a left shift.
    assert_eq!(0b0010 &lt;&lt; 1, 0b0100);

    // Perform a right shift.
    assert_eq!(0b0100 &gt;&gt; 1, 0b0010);
}</code></pre>
<p>A left shift by one is equivalent to multiplying by 2. It makes sense by considering 10-based numbers. Left shifting the number 10 by one results in 100, which is equivalent to multiplying by 10. The same is true for binary numbers.</p>
<h3 id="bitor"><a class="header" href="#bitor">BitOR</a></h3>
<p>The bitor operation (usually denoted with a pipe character <code>|</code>) applies the OR operation to two binary numbers. Assume we want to insert a <code>T</code> (<code>0b11</code>) into an integer with value <code>0b00</code>. We apply the bitor operation for this:</p>
<pre><code>0b00 // Storage.
bitor
0b11 // T.
=
0b11 // Result.
</code></pre>
<p>because applying the OR bitwise, we’ll get 0b(0 OR 1)(0 OR 1) = 0b11</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    // Insert A
    assert_eq!(0b00 | 0b00, 0b00);
    // Insert C
    assert_eq!(0b00 | 0b01, 0b01);
    // Insert G
    assert_eq!(0b00 | 0b10, 0b10);
    // Insert T.
    assert_eq!(0b00 | 0b11, 0b11);
}</code></pre>
<h3 id="bit-masks"><a class="header" href="#bit-masks">Bit masks</a></h3>
<p>Bit masks can be used to manipulate a binary number certain ways. In our context, we’ll use it to mask certain parts of our storage integer to ensure proper kmer length <code>k</code>. Say we have inserted three Gs <code>0b101010</code>, but we want to “mask” the upper two bits (the “oldest” <code>G</code>) because <code>k=2</code>. Masking the upper two bits is the same as saying we only want to keep the lower 4 bits (two Gs).</p>
<p>For this, we’ll use the AND operator, which only returns 1 if both bits at a given position in our numbers are 1. This way, we can use 1 for every bit we want to keep, and 0 for the rest.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    // Only keep the lower 4 bits, mask the rest (e.g., set to zero).
    assert_eq!(0b101010 &amp; 0b001111, 0b001010);
}</code></pre>
<p>How do we construct this mask programmatically? If we know our kmer size, we can do it. In the previous example, if our kmer size is 2, we want to keep 4 bits and mask the upper two.</p>
<p>We start with the number 1 (<code>0b000001</code>) and shift it 4 bits to the left, we get <code>0b010000</code>. This is not what we want. Our target is <code>0b001111</code>. However, subtracting 1 from <code>0b010000</code> gives us the correct answer.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    // Kmer size.
    let k = 2;

    // Equivalent to multiplying by 2.
    let nbits = k &lt;&lt; 1;
    assert_eq!(nbits, 4);

    // We start with a 1 (0b000001) and shifts it nbits to the left.
    // this results in 0b010000, hence we overshoot since we wanted 0b001111.
    // This is why we subtract one, because 0b010000 - 0b000001 = 0b001111.
    let mask: u64 = (1 &lt;&lt; nbits) - 1;

    assert_eq!(mask, 0b1111);
}</code></pre>
<h2 id="choosing-storage-size"><a class="header" href="#choosing-storage-size">Choosing storage size</a></h2>
<p>We use unsigned integers to store our kmers. Remember that each nucleotide, with our encoding, occupies two bits. The following types are available in Rust:</p>
<ul>
<li><code>u8</code> - can store kmers of max size 8/2 = 4.</li>
<li><code>u16</code> - can store kmers of max size 16/2 = 8.</li>
<li><code>u32</code> - can store kmers of max size 32 / 2 = 16.</li>
<li><code>u64</code> - can store kmers of max size 64/2 = 32.</li>
<li><code>u128</code> - can store kmers of max size 128/2 = 64.</li>
</ul>
<p>Can we store a kmer of size 2 in, say, a <code>u16</code>? Yes we can, but we’ll waste space. Unfortunately, Rust does not yet provide arbitrary integer size, so these are the choices.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="forward-strand"><a class="header" href="#forward-strand">Forward Strand</a></h1>
<p>In order to insert a nucleotide, we need two things:</p>
<ul>
<li>A left shift by two to make room for the two new bits.</li>
<li>Insert the actual nucleotide, which is done with the <code>|</code> operator (BitOR).</li>
</ul>
<p>Hence, for the forward strand we add nucleotides from the <strong>right side</strong>.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let mut storage: u32 = 0b0;

    // Insert a T.
    storage = storage &lt;&lt; 2 | 0b11;
    assert_eq!(storage, 0b11);

    // Insert another T.
    storage = storage &lt;&lt; 2 | 0b11;
    assert_eq!(storage, 0b1111);

    // Insert a G.
    storage = storage &lt;&lt; 2 | 0b10;
    assert_eq!(storage, 0b111110);

    println!("{:032b}", storage);
}</code></pre>
<p><strong>Note</strong> - it seems like new digits magically appear in our test cases. However, when we print the full u32, we see the leading zeros.</p>
<h2 id="handling-the-kmer-size"><a class="header" href="#handling-the-kmer-size">Handling the kmer size</a></h2>
<p>Our approach kinda works, but it has a fundamental flaw. We want our storage variable to only contain k nucleotides at one time, all other leading bits should be zero. As an example:</p>
<pre><code>nt_string = "GTGT"
kmer_size = 2

# start
0b00000000

# insert G
0b00000010

# insert T
0b00001011
</code></pre>
<p>At this point, we have inserted two nucleotides, which also is our target kmer length. In order to keep our target kmer size of 2, we need to:</p>
<ul>
<li>Insert the next nucleotide, G, resulting in a kmer of length 3.</li>
<li>Mask anything above our kmer length to keep the length of 2.</li>
</ul>
<p>We solve this by applying a bit-mask (as discussed previously). In the code example below, we also take care of invalid nucleotides.</p>
<pre class="playground"><code class="language-rust edition2024"><span class="boring">const LOOKUP: [u8; 256] = [
</span><span class="boring">    0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">];
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">fn decode(byte: u64) -&gt; char {
</span><span class="boring">    match byte {
</span><span class="boring">        0 =&gt; return 'A',
</span><span class="boring">        1 =&gt; return 'C',
</span><span class="boring">        2 =&gt; return 'G',
</span><span class="boring">        3 =&gt; return 'T',
</span><span class="boring">        _ =&gt; panic!("Invalid nucleotide."),
</span><span class="boring">    };
</span><span class="boring">}
</span>// [...]

/// Print a u64 encoded nucleotide with some bit manipulation.
fn print_nt_string(kmer: u64, k: usize) {
    let mut result = String::with_capacity(k);

    for i in 0..k {
        // Shift to extract the 2 bits corresponding to the current nucleotide
        let shift = 2 * (k - i - 1);
        let bits = (kmer &gt;&gt; shift) &amp; 0b11;

        result.push(decode(bits));
    }

    println!("{}", result);
}

fn kmerize(kmer_size: usize, nt_string: &amp;[u8]) {
    assert!(kmer_size &lt;= nt_string.len());

    // Forward related kmer stuff
    let mut storage: u64 = 0;

    // Mask for bits above kmer size.
    let nbits = kmer_size &lt;&lt; 1;
    let mask: u64 = (1 &lt;&lt; nbits) - 1;

    // We keep track of how many valid nucleotides we
    // have in our storage and reset if we find an invalid nt.
    let mut valid_kmer_index: usize = 0;

    nt_string.iter().for_each(|nt_char| {
        // Forward kmer.
        let nt = LOOKUP[*nt_char as usize] as u64;

        // Reset if we found an invalid nucleotide.
        if nt &gt;= 4 {
            valid_kmer_index = 0;
            storage = 0;
            return;
        }
        storage = (storage &lt;&lt; 2 | nt) &amp; mask;

        if valid_kmer_index &gt;= kmer_size - 1 {
            print_nt_string(storage, kmer_size);
        }

        valid_kmer_index += 1;
    });
}

fn main() {
    // We expect just one kmer.
    kmerize(5, b"AAAAA");

    // We expect no kmers.
    kmerize(5, b"AAAANAAAA");

    // We expect AAA, AAT, ATT, TTT.
    kmerize(3, b"AAATTT");
}</code></pre>
<h2 id="converting-kmer-to-string"><a class="header" href="#converting-kmer-to-string">Converting kmer to string</a></h2>
<p>Finally, it would also be nice to be able to convert an encoded kmer to a string. We can do this by leveraging the <code>kmer_size</code> and a suitable bitmask.</p>
<p>Consider the kmer <code>0b00111010</code>. Here, we are using an <code>u8</code> as storage and <code>kmer_size = 3</code>. We have inserted nucleotides in the following order: <code>T</code>, <code>G</code>, <code>G</code> and would like to get the same order back. Even though there are multiple ways to do this, one is to extract the nucleotides in the order they appear in the kmer, which is the reverse of how they were inserted, and then reverse the result. We would like to:</p>
<ul>
<li>Find the lowest two bits (latest inserted nucleotide).</li>
<li>Convert these to a stringified nucleotide and append it to something like a <code>Vec</code> or <code>String</code>.</li>
<li>Eject these bits from the kmer by a left shift.</li>
<li>Continue until we have processed all nucleotides (which is <code>kmer_size</code> number of times).</li>
</ul>
<p>We need a suitable bitmask for this. To only keep the lowest two bits, we’ll use <code>0b11</code> with and <code>&amp;</code> operator. This roughly looks like:</p>
<pre><code>0b00111010
&amp;
0b00000011
---
0b00000010
</code></pre>
<p>The result can subsequently be matched against, and converted to the appropriate nucleotide. <code>0b10</code> in this case would translate to <code>G</code>. The code below is one way of achieving this:</p>
<pre class="playground"><code class="language-rust edition2024">fn extract_nucleotides(mut kmer: u8, kmer_size: u8) -&gt; String {
    let mut s = String::with_capacity(kmer_size as usize);
    let mask: u8 = 0b11;

    for _ in 0..kmer_size {
        let lowest_two_nts = kmer &amp; mask;

        match lowest_two_nts {
            0b00 =&gt; s.push('A'),
            0b01 =&gt; s.push('C'),
            0b10 =&gt; s.push('G'),
            0b11 =&gt; s.push('T'),
            _ =&gt; unreachable!(),
        }
        kmer &gt;&gt;= 2;
    }

    s.chars().rev().collect()
}

fn main(){
	assert!(extract_nucleotides(0b00111010, 3) == "TGG");
	assert!(extract_nucleotides(0b00000010, 3) == "AAG");
	assert!(extract_nucleotides(0b00000011, 1) == "T");	
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="reverse-strand"><a class="header" href="#reverse-strand">Reverse Strand</a></h1>
<p>As mentioned in a previous section, we also need to handle the reverse complement. How do we do this in an efficient way? We can insert the reverse complement from the left side instead of the right, ensuring the correct order. To insert from the left side, we first need to shift the two least significant bits, our nucleotide, to the upper most significant bits of our kmer. Then, we shift our storage to the right by 2 and finally apply BitOR to insert.</p>
<p>The following pseudo-code shows how to insert a nucleotide A whilst using <code>k=4</code>.</p>
<pre><code>// Define variables.
k = 4
nt      =   0b0000000000 # A
nt_rev  =   0b0000000011 # T (reverse complement)
storage =   0b0000000000

// Shift reverse nucleotide to the upper two bits of the kmer size.
0b0000000011 &lt;&lt; (k-1) * 2 = 0b0011000000

// Shift storage to the right to make room (empty at the moment).
0b0000000000 &gt;&gt; 2 = 0b0000000000

// Insert.
0b0000000000 | 0b0011000000 = 0b0011000000
</code></pre>
<p>The following code is an example of inserting the reverse complement of <code>AGT</code> into a <code>u32</code>. We’ll make it easy for us and use a <code>k=3</code> to exactly fit the entire reverse complement into the kmer.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    let mut storage: u32 = 0b0;

    // Use kmer size 3 to exactly fit our three nucleotides
    // In the least significant bits.
    let k: u32 = 3;

    let forward = b"AGT";

    let shift: u32 = (k - 1) * 2;

    forward.iter().for_each(|nt| {
        let nt_encoded = match nt {
            b'A' =&gt; 0 as u32,
            b'C' =&gt; 1 as u32,
            b'G' =&gt; 2 as u32,
            b'T' =&gt; 3 as u32,
            _ =&gt; panic!(""),
        };
        // Use 3 - nt_encoded to get the reverse base.
        storage = storage &gt;&gt; 2 | (3 - nt_encoded) &lt;&lt; shift;
    });

    // Print the full u32-bit.
    println!("{:032b}", &amp;storage);

    // Verify: reverse complement of AGT is ACT, encoded as 00 01 11.
    assert_eq!(storage, 0b000111);
}</code></pre>
<p>Run the code and inspect the result. Our output is:</p>
<pre>
00 [...] 00 01 11
         A  C  T

</pre>

<p>Which is the reverse complement of <code>AGT</code>, inserted in the correct order.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="final-implementation"><a class="header" href="#final-implementation">Final Implementation</a></h1>
<p>The code below combines the previous sections and adds an additional feature, which is canonical kmers. We define a canonical kmer as the lexicographically smallest kmer of the forward and reverse. This is a way to avoid keeping all kmers from the forward and the reverse strand.</p>
<pre class="mermaid">graph LR
    A["Nucleotide"] --&gt; B["Encode via&lt;br/&gt;lookup table"]
    B --&gt; C["Forward kmer&lt;br/&gt;(left shift + OR + mask)"]
    B --&gt; D["Reverse kmer&lt;br/&gt;(right shift + OR)"]
    C --&gt; E{"forward &lt; reverse?"}
    D --&gt; E
    E -- "Yes" --&gt; F["Canonical = forward"]
    E -- "No" --&gt; G["Canonical = reverse"]
</pre>

<pre class="playground"><code class="language-rust edition2024"><span class="boring">const LOOKUP: [u8; 256] = [
</span><span class="boring">    0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">];
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">fn decode(byte: u64) -&gt; char {
</span><span class="boring">    match byte {
</span><span class="boring">        0 =&gt; return 'A',
</span><span class="boring">        1 =&gt; return 'C',
</span><span class="boring">        2 =&gt; return 'G',
</span><span class="boring">        3 =&gt; return 'T',
</span><span class="boring">        _ =&gt; panic!("Invalid nucleotide."),
</span><span class="boring">    };
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">/// Print a u64 encoded nucleotide with some bit manipulation.
</span><span class="boring">pub fn print_nt_string(kmer: u64, k: usize) {
</span><span class="boring">    let mut result = String::with_capacity(k);
</span><span class="boring">    for i in 0..k {
</span><span class="boring">        // Shift to extract the 2 bits corresponding to the current nucleotide
</span><span class="boring">        let shift = 2 * (k - i - 1);
</span><span class="boring">        let bits = (kmer &gt;&gt; shift) &amp; 0b11;
</span><span class="boring">
</span><span class="boring">        result.push(decode(bits));
</span><span class="boring">    }
</span><span class="boring">    println!("{}", result);
</span><span class="boring">}
</span>// [...]

pub fn kmerize(k: usize, nt_string: &amp;[u8]) -&gt; Vec&lt;u64&gt; {
    assert!(k &lt;= nt_string.len());

    // Forward related kmer stuff
    let mut kmer_forward: u64 = 0;

    let nbits = k &lt;&lt; 1;
    let mask: u64 = (1 &lt;&lt; nbits) - 1;

    // Reverse related kmer stuff.
    let mut kmer_reverse: u64 = 0;
    let shift = ((k - 1) * 2) as u64;

    let mut valid_kmer_index: usize = 0;
    let mut canonical_kmers: Vec&lt;u64&gt; = Vec::new();

    nt_string.iter().for_each(|nt_char| {
        let nt = LOOKUP[*nt_char as usize] as u64;

        // Check for invalid nucleotides.
        if nt &gt;= 4 {
            valid_kmer_index = 0;
            kmer_forward = 0;
            kmer_reverse = 0;
            return;
        }
        // Forward kmer.
        kmer_forward = (kmer_forward &lt;&lt; 2 | nt) &amp; mask;

        // Reverse kmer.
        let nt_rev = 3 - nt;
        kmer_reverse = kmer_reverse &gt;&gt; 2 | nt_rev &lt;&lt; shift;

        if valid_kmer_index &gt;= k - 1 {
            let canonical = match kmer_forward &lt; kmer_reverse {
                true =&gt; kmer_forward,
                false =&gt; kmer_reverse,
            };

            print_nt_string(canonical, k);
            canonical_kmers.push(canonical);
        }

        valid_kmer_index += 1;
    });

    canonical_kmers
}

fn main(){
    let kmers_a = kmerize(5, b"AAAAAA");
    println!("");

    let kmers_t = kmerize(5, b"TTTTTT");
    println!("");

    // AAAAAA and TTTTTT are reverse complements, so they
    // should produce the same canonical kmers.
    assert_eq!(kmers_a, kmers_t);

    // Expected to not generate any kmers since we have an
    // invalid nucleotide interrupting every kmer.
    let kmers_n = kmerize(5, b"AAAANTTTT");
    assert!(kmers_n.is_empty());
    println!("");
}</code></pre>
<p>When we run the code, we see that <code>AAAAAA</code> and <code>TTTTTT</code> generates the same canonical kmers which is expected since they are reverse complements of each other.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="fracminhash"><a class="header" href="#fracminhash">FracMinHash</a></h1>
<p>Previously, we implemented an efficient way of generating canonical kmers from nucleotide strings. Now, we’ll take this a step further by covering FracMinHash. Briefly, FracMinHash is a clever way of downsampling a large set of kmers into a representative set. For a more detailed explanation, please check out this <a href="https://doi.org/10.1186/s13015-025-00276-8">paper</a>.</p>
<p>Essentially, we only add two steps to our canonical kmer pipeline:</p>
<ul>
<li>We hash our canonical kmer using an appropriate hashing function.</li>
<li>We add our hashed kmer only if its hash is less than or equal to a defined threshold.</li>
</ul>
<p>We define our threshold as the maximum possible integer value (in our case we’ll use <code>u64</code>), divided by a downsampling factor.</p>
<pre class="playground"><code class="language-rust edition2024"><span class="boring">use std::collections::HashSet;
</span><span class="boring">
</span><span class="boring">const LOOKUP: [u8; 256] = [
</span><span class="boring">    0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
</span><span class="boring">];
</span><span class="boring">
</span><span class="boring">fn decode(byte: u64) -&gt; char {
</span><span class="boring">    match byte {
</span><span class="boring">        0 =&gt; return 'A',
</span><span class="boring">        1 =&gt; return 'C',
</span><span class="boring">        2 =&gt; return 'G',
</span><span class="boring">        3 =&gt; return 'T',
</span><span class="boring">        _ =&gt; panic!("Invalid nucleotide."),
</span><span class="boring">    };
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">/// Print a u64 encoded nucleotide with some bit manipulation.
</span><span class="boring">pub fn print_nt_string(kmer: u64, k: usize) {
</span><span class="boring">    let mut result = String::with_capacity(k);
</span><span class="boring">    for i in 0..k {
</span><span class="boring">        // Shift to extract the 2 bits corresponding to the current nucleotide
</span><span class="boring">        let shift = 2 * (k - i - 1);
</span><span class="boring">        let bits = (kmer &gt;&gt; shift) &amp; 0b11;
</span><span class="boring">
</span><span class="boring">        result.push(decode(bits));
</span><span class="boring">    }
</span><span class="boring">    println!("{}", result);
</span><span class="boring">}
</span>// [...]

/// https://github.com/bluenote-1577/sylph
fn mm_hash64(kmer: u64) -&gt; u64 {
    let mut key = kmer;
    key = !key.wrapping_add(key &lt;&lt; 21);
    key = key ^ key &gt;&gt; 24;
    key = (key.wrapping_add(key &lt;&lt; 3)).wrapping_add(key &lt;&lt; 8);
    key = key ^ key &gt;&gt; 14;
    key = (key.wrapping_add(key &lt;&lt; 2)).wrapping_add(key &lt;&lt; 4);
    key = key ^ key &gt;&gt; 28;
    key = key.wrapping_add(key &lt;&lt; 31);
    key
}

fn kmerize(k: usize, ds_factor: u64, nt_string: &amp;[u8]) -&gt; HashSet&lt;u64&gt; {
    if k &gt;= nt_string.len() {
        panic!("kmer: {k}, nt_string: {}", nt_string.len());
    };

    // Forward related kmer stuff
    let mut kmer_forward: u64 = 0;

    let nbits = k &lt;&lt; 1;
    let mask: u64 = (1 &lt;&lt; nbits) - 1;

    // Reverse related kmer stuff.
    let mut kmer_reverse: u64 = 0;
    let shift = ((k - 1) * 2) as u64;

    // Storage.
    let mut canonical_hashes: HashSet&lt;u64&gt; = HashSet::with_capacity(nt_string.len() - k + 1);

    let mut valid_kmer_index: usize = 0;

    nt_string.iter().for_each(|nt_char| {
        // Forward kmer.
        let nt = LOOKUP[*nt_char as usize] as u64;

        if nt &gt;= 4 {
            valid_kmer_index = 0;
            kmer_forward = 0;
            kmer_reverse = 0;
            return;
        }
        kmer_forward = (kmer_forward &lt;&lt; 2 | nt) &amp; mask;

        // Reverse kmer.
        let nt_rev = 3 - nt;
        kmer_reverse = kmer_reverse &gt;&gt; 2 | nt_rev &lt;&lt; shift;

        if valid_kmer_index &gt;= k - 1 {
            let canonical = match kmer_forward &lt; kmer_reverse {
                true =&gt; kmer_forward,
                false =&gt; kmer_reverse,
            };
            // MinFracHash
            if canonical &lt;= u64::MAX / ds_factor {
                canonical_hashes.insert(mm_hash64(canonical));
            }
        }

        valid_kmer_index += 1;
    });

    return canonical_hashes;
}

fn print_canonical_hashes(canonical_hashes: &amp;HashSet&lt;u64&gt;) {
    for canonical_hash in canonical_hashes{
        println!("{canonical_hash}");
    }
}

/// In these examples, we don't downsample because our
/// nucleotide strings are very short and have low complexity.
fn main(){
    let canonical_hashes_a = kmerize(5, 1, b"AAAAAAAAAA");
    print_canonical_hashes(&amp;canonical_hashes_a);

    let canonical_hashes_t = kmerize(5, 1, b"TTTTTTTTTT");
    print_canonical_hashes(&amp;canonical_hashes_t);

    // Both should produce non-empty hash sets.
    assert!(!canonical_hashes_a.is_empty());
    assert!(!canonical_hashes_t.is_empty());

    // Reverse complements should produce the same canonical hashes.
    assert_eq!(canonical_hashes_a, canonical_hashes_t);
}</code></pre>
<p>The result is a seemingly nonsensical number for each sequence. However, we note two important things:</p>
<ul>
<li>Each sequence only generated one hash.</li>
<li>Both sequences generated the same hash.</li>
</ul>
<p>The reasons for this are:</p>
<ul>
<li>The sequences are reverse complements, so they generate the same canonical kmers.</li>
<li>Both sequences generate only one unique canonical kmer, <code>AAAAA</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="minimizers"><a class="header" href="#minimizers">Minimizers</a></h1>
<p>We saw earlier how FracMinHash could be used to downsample the number of kmers generated from our sequences. Another approach is to use so called minimizers. First introduced in 2004, <a href="https://doi.org/10.1093/bioinformatics/bth408">minimizers</a> are very commonly used in bioinformatic applications to reduce storage requirements for DNA sequences.</p>
<p>The basic idea is to use a sliding window of w consecutive kmers in a sequence and in each window identify one representative kmer to keep. Since we choose a reduced set of kmers, these will act as an approximate representation for the original sequence. There are multiple ways to choose a representative kmer inside the sliding window, but typically the lexicographically smallest kmer is chosen. We need to define some terms to make things more clear:</p>
<ul>
<li><code>k</code> - length of a kmer.</li>
<li><code>w</code> - number of consecutive kmers to check for minimizers in.</li>
<li><code>|w|</code> - The actual length (in nucleotides) we need for our sliding window to accommodate <code>w</code> consecutive kmers of length <code>k</code>.</li>
</ul>
<p>We can calculate |<em>w</em>| since we know how many kmers we can generate from a given sequence.<br>
<code>w = |w| - k + 1</code></p>
<p>See the example below, where we set w=4 and k=3, hence calculating |<em>w</em>| = 6.</p>
<pre>
AAACCCGGGAAACCCGGGAAACCCGGG
AAACCC
 AACCCG    ...        ...
  ACCCGG
   CCCGGG            CCCGGG
</pre>

<p>Let’s consider the first window <code>AAACCC</code>. The possible kmers we can generate in the forward direction are <code>AAA</code>, <code>AAC</code>, <code>ACC</code>, <code>CCC</code>. Out of these, the lexicographically smallest one is AAA and we choose this kmer as this windows minimizer. We then do the same for the remaining windows.</p>
<p>We can get even more space efficient by storing the minimizers in a hashset, since this removes duplicates. However, this is not suitable if we also want to store information such as the minimizers positions. We also have to take the reverse complement into consideration, similarly to what we did in the bit shift encoding section.</p>
<p>There are several Rust crates, such as <a href="https://docs.rs/needletail/0.6.3/needletail/">Needletail</a> and <a href="https://docs.rs/bio-seq/latest/bio_seq/">bio-seq</a> that implement minimizers quite efficiently. In the code snippet below, we just implement a minimally viable prototype.</p>
<pre class="playground"><code class="language-rust edition2024">use std::{cmp::min, vec};

fn reverse(nt: &amp;u8) -&gt; u8 {
    match nt {
        b'A' =&gt; b'T',
        b'C' =&gt; b'G',
        b'G' =&gt; b'C',
        b'T' =&gt; b'A',
        _ =&gt; panic!("Invalid nt."),
    }
}

/// Find the lexicographically smallest kmers from
/// either the forward or reverse window.
fn minimizer_from_windows&lt;'a&gt;(
    w_forward: &amp;'a [u8],
    w_reverse: &amp;'a [u8],
    kmer_size: usize,
) -&gt; &amp;'a [u8] {
    let min_fwd = w_forward.windows(kmer_size).min().unwrap();
    let min_rev = w_reverse.windows(kmer_size).min().unwrap();

    return min(min_fwd, min_rev);
}

fn get_minimizers(seq: &amp;[u8], window_size: usize, kmer_size: usize) -&gt; Vec&lt;String&gt; {
    // This is the actual length (in nucleotides) of the sliding
    // window we need for w consecutive kmers of length k.
    let sliding_window_size = window_size + kmer_size - 1;
    assert!(sliding_window_size &lt;= seq.len());

    // We'll store the minimizers as strings convenience.
    let mut m: Vec&lt;String&gt; = Vec::new();

    let rev_comp: Vec&lt;u8&gt; = seq.iter().rev().map(|nt| reverse(nt)).collect();

    // Create windows for both forward and reverse sequences.
    seq.windows(sliding_window_size)
        .zip(rev_comp.as_slice().windows(sliding_window_size))
        // Iterate over forward/reverse windows at the same time.
        .for_each(|(w_forward, w_reverse)| {
            let minimizer = minimizer_from_windows(w_forward, w_reverse, kmer_size);
            m.push(String::from_utf8(minimizer.to_vec()).unwrap());
        });

    return m;
}

fn main() {
    assert_eq!(get_minimizers(b"AAATTT", 4, 3), vec!["AAA"]);

    // Use all canonical kmers as minimizers.
    assert_eq!(
        get_minimizers(b"AAATTT", 1, 3),
        vec!["AAA", "AAT", "ATT", "TTT"]
    );
}</code></pre>
<p>For a more thorough review on minimizers, check out this awesome <a href="https://doi.org/10.1186/s13059-024-03414-4">paper</a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="syncmers"><a class="header" href="#syncmers">Syncmers</a></h1>
<p>Minimizers are widely used in bioinformatics by softwares such as <a href="https://github.com/lh3/minimap2">Minimap2</a> and <a href="https://github.com/DerrickWood/kraken2">Kraken2</a>. Recently, the concept of <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC7869670/">syncmers</a> was proposed as an alternative to minimizers. To quote the paper:<br></p>
<p><q><em>Syncmers are defined here as a family of alternative methods which select k-mers by inspecting the position of the smallest-valued substring of length s &lt; k within the k-mer.</em></q></p>
<p>Basically what this means is:</p>
<ul>
<li>Take a kmer of length <code>k</code>.</li>
<li>Check for the smallest substring (by value) of length <code>s</code> in the kmer.</li>
<li>If the location of this substring fulfills a given criteria, classify the kmer as a syncmer.</li>
</ul>
<p>A very simplified example is a nucleotide <code>ATCG</code> of length 4. Let <code>k = 3</code> and <code>s = 2</code>. Let’s assume that our criteria is that the smallest valued substring must be located at the start of the kmer.</p>
<p>We can generate two kmers and for each of them, we check if the smallest valued substring of length <code>s = 2</code> is located at the start of the kmer.</p>
<pre><code>ATCG    # nucleotide sequence.

ATC     # kmer_1
 TCG    # kmer_2
</code></pre>
<p>We see that:</p>
<ul>
<li><code>ATC</code> has <code>AT</code> as its smallest valued substring and <code>AT</code> is located at the start. <code>ATC</code> is a syncmer.</li>
<li><code>TCG</code> has <code>CG</code> as its smallest valued substring and <code>CG</code> is not located at the start. <code>TCG</code> is not a syncmer.</li>
</ul>
<h2 id="closed-syncmers"><a class="header" href="#closed-syncmers">Closed syncmers</a></h2>
<p>In this section, we’ll go through <em>closed syncmers</em> where the location criteria is that the smallest value substring must be located at either the start or end of the kmer. Expanding our previous example with this location criteria, we get</p>
<pre><code>ATCG    # nucleotide sequence.

ATC     # kmer_1
 TCG    # kmer_2
</code></pre>
<p>We see that:</p>
<ul>
<li><code>ATC</code> has <code>AT</code> as its smallest valued substring and <code>AT</code> is located at the start. <code>ATC</code> is a closed syncmer.</li>
<li><code>TCG</code> has <code>CG</code> as its smallest valued substring and <code>CG</code> is located at the end. <code>TCG</code> is a closed syncmer.</li>
</ul>
<h2 id="implementation-3"><a class="header" href="#implementation-3">Implementation</a></h2>
<p>In the example below, we won’t bother with nucleotide encoding. Rather, we’ll just find closed syncmers by iterate over the kmers, using the <code>.windows()</code> function and check the location of the smallest valued substring.</p>
<pre class="playground"><code class="language-rust edition2024">fn get_closed_syncmers&lt;'a&gt;(seq: &amp;'a [u8], k: usize, s: usize) -&gt; Vec&lt;&amp;'a [u8]&gt; {
    assert!(k &lt;= seq.len());
    assert!(s &lt;= k);

    let closed_syncmers: Vec&lt;&amp;[u8]&gt; = seq
        .windows(k) // Generate kmers.
        .filter_map(|kmer| {

            let (smallest_index, _) = kmer
                .windows(s) // Substrings of length s for a given kmer.
                .enumerate()
                .min_by_key(|substring| substring.1) // Find smallest valued substring.
                .unwrap();

            // Location criteria.
            if smallest_index == 0 || smallest_index == (k - s) {
                return Some(kmer);
            }

            return None;
        })
        .collect();

    return closed_syncmers;
}

fn main() {
    // Generate one single kmer. Syncmer "AT" is not in the start or end.
    assert_eq!(get_closed_syncmers(b"TTATT", 5, 2), Vec::&lt;&amp;[u8]&gt;::new());

    // The example from the introduction to this chapter.
    assert_eq!(get_closed_syncmers(b"ATCG", 3, 2), vec![b"ATC", b"TCG"]);

    // Example from the syncmer paper.
    assert_eq!(get_closed_syncmers(b"GGCAAGTGACA", 5, 2), vec![b"GGCAA", b"AAGTG", b"AGTGA", b"GTGAC"]);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="advanced-topics"><a class="header" href="#advanced-topics">Advanced Topics</a></h1>
<p>In this section, we explore more advanced techniques that build on the foundations covered earlier in the book. These topics focus on pushing performance further and solving problems that arise when working with large-scale genomic data. We cover SIMD vectorization for parallel kmer processing and reverse indices for efficient sequence search.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="simd-vectorization"><a class="header" href="#simd-vectorization">SIMD Vectorization</a></h1>
<p>Full disclosure - I’m not a computer science expert. Not even close actually. This will not be a heavy theoretical introduction. Rather, I will try to explain how SIMD can be used to significantly speed up bioinformatic analyses. Finally, I think these resources are valuable with respect to SIMD and Rust:</p>
<ul>
<li>SIMD on <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">Wikipedia</a>.</li>
<li>Rust <a href="https://doc.rust-lang.org/std/simd/index.html">std::simd</a>.</li>
<li>Rust <a href="https://doc.rust-lang.org/core/arch/index.html">core::arch</a>.</li>
<li>Rust <a href="https://doc.rust-lang.org/core/arch/x86_64/index.html">x86_64</a>.</li>
</ul>
<h2 id="introduction-6"><a class="header" href="#introduction-6">Introduction</a></h2>
<p>SIMD (<strong>S</strong>ingle <strong>I</strong>nstruction <strong>M</strong>ultiple <strong>D</strong>ata) enables certain CPU instructions to be executed in parallel. In contrast to threads, SIMD is more primitive, low level and allows for a more restricted set of operations.</p>
<p>What makes SIMD a bit tricky is that it is architecture specific. Hence, the instruction sets we can use depend on what architecture our computer runs. We’ll skip the details here, partially because it is out of scope in this book and partially because I personally don’t know enough on this topic.</p>
<p>In the subsequent paragraphs, we assume we are running on the <code>x86_64</code> architecture.</p>
<h3 id="simd-registers-and-instruction-set-extensions"><a class="header" href="#simd-registers-and-instruction-set-extensions">SIMD Registers and Instruction Set Extensions</a></h3>
<p>SIMD operates on fixed-width registers. On <code>x86_64</code>, the main SIMD extensions are:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Extension</th><th>Register width</th><th><code>u64</code> lanes</th></tr>
</thead>
<tbody>
<tr><td>SSE2</td><td>128-bit</td><td>2</td></tr>
<tr><td>AVX/AVX2</td><td>256-bit</td><td>4</td></tr>
<tr><td>AVX-512</td><td>512-bit</td><td>8</td></tr>
</tbody>
</table>
</div>
<p>Even though AVX-512 might be the widest and most powerful, it is not universally supported. SSE2 is effectively ubiquitous on <code>x86_64</code>.</p>
<h2 id="a-pragmatic-view"><a class="header" href="#a-pragmatic-view">A Pragmatic View</a></h2>
<p>Going back to the previous chapter, we constructed a relatively efficient algorithm for generating kmers from a nucleotide sequence. How can we make this algorithm even more efficient with SIMD?</p>
<p>First, let’s look at some pseudo code, inspired by the previous chapter for processing the forward strand.</p>
<pre><code class="language-rust noplayground">
fn kmerize(kmer_size: usize, nt_string: &amp;[u8]) {
	
    let nbits = kmer_size &lt;&lt; 1;
    let mask: u64 = (1 &lt;&lt; nbits) - 1;

	// iterate over each nt.
    nt_string.iter().for_each(|nt_char| {
    	// encode
        let nt = LOOKUP[*nt_char as usize] as u64;
        
        // bit shift (add nt)
        storage = (storage &lt;&lt; 2 | nt) &amp; mask;
    
    });
}</code></pre>
<p>It is obvious that this function handles a single sequence. What if we could process multiple sequences at once? Conceptually (and with pseudo code) it could look something like this</p>
<pre><code class="language-rust noplayground">fn kmerize(kmer_size: usize, nt_strings: &amp;[&amp;[u8]]){
	let nbits = kmer_size &lt;&lt; 1;
    let mask: u64 = (1 &lt;&lt; nbits) - 1;
    
	let storage_simd = create_simd_vector[0_u64; nt_strings.len()];
	
	// assume all nt_string have equal length. 
	let seq_len = nt_strings[0].len();
	
	for i in 0..seq_len {
		let nt_simd = simd_vector::from(nt_strings.iter().map(|s: &amp;[u8]| s[i]));
		
		storage_simd = (storage_simd &lt;&lt; 2 | nt_simd) &amp; mask;
	}
}</code></pre>
<p>We start with an initial storage SIMD vector the same length as the number of sequences. This way, each sequence gets its own <code>slot</code>. In each iteration <code>i</code> we extract the <code>ith</code> nucleotide from every sequence, create a nucleotide SIMD vector and apply the bit shift in parallel. Schematically, it could look something like this:</p>
<pre><code class="language-rust noplayground">nt_strings = [b"ATCA", b"GTGA", b"TCGA"]

storage_simd = [0_u64, 0_u64, 0_u64]

for i in 0..4{
	// for i=0, we extract:
	// * the b'A' from b"ATCA"
	// * the b'G' from b"GTGA"
	// * the b'T' from b"TCGA".
	nt_simd = [0, 2, 3] = [0b00, 0b10, 0b11];
	storage_simd = ([0_u64, 0_u64, 0_u64] &lt;&lt; 2 | [0b00, 0b10, 0b11]) &amp; mask = [0b00, 0b10, 0b11]
	
	// for i=1, we extract:
	// * the b'T' from b"ATCA"
	// * the b'T' from b"GTGA"
	// * the b'C' from b"TCGA".
	nt_simd = [3, 3, 1] = [0b11, 0b11, 0b01];
	storage_simd = ([0b00, 0b11, 0b11] &lt;&lt; 2 | [0b11, 0b11, 0b01]) &amp; mask = [0b0011, 0b1011, 0b1101]
}</code></pre>
<p>Our implementation has a fundamental flaw. What if the sequences don’t have the same length? We have to rethink our approach.</p>
<h2 id="chunking"><a class="header" href="#chunking">Chunking</a></h2>
<p>Instead of trying to process separate, unrelated sequences at once, what if we can process a single sequence at once?</p>
<pre class="mermaid">graph TD
    A["Long sequence"] --&gt; B["Split into N overlapping chunks&lt;br/&gt;(overlap = k - 1)"]
    B --&gt; C["Load one nucleotide per chunk&lt;br/&gt;into SIMD vector"]
    C --&gt; D["Parallel bit-shift encoding&lt;br/&gt;across all N lanes"]
    D --&gt; E["Collect kmers&lt;br/&gt;from each lane"]
    B --&gt; F["Handle residual&lt;br/&gt;separately"]
    E --&gt; G["All kmers"]
    F --&gt; G
</pre>

<p>What if we can cleverly chop our sequence into N equal size chunks (where N is the number of SIMD lanes available) and process them in parallel? We can, with some requirements:</p>
<ul>
<li>The sequence has to be reasonably long for this to make sense.</li>
<li>We have to handle cases where a sequence is not evenly divisible into exactly 8 chunks.</li>
</ul>
<p>We must first investigate how to chop our sequence. As an example, take the sequence <code>b"AAATTTCCC"</code>. With a kmer size of length 3, we want to generate</p>
<pre><code>AAA, AAT, ATT, TTT, TTC, TCC, CCC
</code></pre>
<p>Also, pretend we have 3 SIMD lanes available. We need to chop our sequence into 3 chunks, each of which can be processed in parallel. We must ensure that:</p>
<ul>
<li>Each chunk is longer than, or equal to the kmer size.</li>
<li>We have to handle the residual if the sequence cannot be exactly chunked into 3.</li>
</ul>
<p>The key is to generate chunks that overlap by <code>kmer_size - 1</code> nucleotides. A short motivation for this is that it generates our target kmers. The more nuanced motivation is the following - try chunking into non-overlapping chunks. This would yield <code>AAA</code>, <code>TTT</code> and <code>CCC</code>. Kmerizing these (k=3) would simply give <code>AAA</code>, <code>TTT</code> and <code>CCC</code>, which is fewer kmers than the <code>sequence_length - kmer_size + 1 = 9 - 3 + 1 = 7</code> kmers we listed above. One (kinda) correct way to chunk would be
<code>AAAT</code>, <code>ATTT</code> and <code>TTCC</code>, where each sub-sequence is overlapping by <code>kmer_size - 1 = 3 - 1 = 2</code>. Kmerizing these would give</p>
<pre><code>AAAT -&gt; AAA, AAT
ATTT -&gt; ATT, TTT
TTCC -&gt; TTC, TCC
</code></pre>
<p>Which is 6 out of the 7 kmers we wanted. We are missing one kmer because the last <code>C</code> was excluded from the chunking. But since we know this, we can easily generate the last kmer.</p>
<p>Regardless, with some clever maths (see a semi-clever example below) we can ensure that the residual is kmerizable as well.</p>
<h2 id="deriving-a-mathematical-formula"><a class="header" href="#deriving-a-mathematical-formula">Deriving A Mathematical formula</a></h2>
<p>In order to derive a proper formula, we need to investigate the behavior of chunking. Assume we have the 34 length sequence <code>AAAATTTTGGGGCCCCAAAATTTTGGGGCCCCTT</code>. Also assume we are running on <code>AVX-512</code>, which means we can have (at most) a 512-bit SIMD register. Since we use <code>u64</code> as storage for each kmer, we can have at most <code>512 / 64 = 8</code> SIMD lanes. With <code>kmer_size = 3</code> we need each chunk to overlap by <code>kmer_size - 1 = 2 nucleotides</code>. Manually chopping this sequence into <code>8</code> equal length chunks gives the following:</p>
<pre><code>AAAATTTTGGGGCCCCAAAATTTTGGGGCCCCTT (len = 34)

AAAAT
   ATTTT
      TTGGG
         GGGCC
            CCCCA
               CAAAA
                  AATTT
                     TTTGG
                        GGGGCCCCTT (residual, len = 10)
             
</code></pre>
<p>Observe that:</p>
<ul>
<li>We have a chunk size of 5 (of which the formula we’ll derive soon).</li>
<li>We have 7 points of overlap between the 8 chunks (not including the residual).</li>
<li>For each overlap, we only add 3 new nucleotides to the effective length. We derive 3 as <code>num_new_nucleotides = chunk_size - overlap = 5 - 2 = 3</code>.</li>
<li>The effective length of all 8 chunks gives room for a residual with a length <code>10</code> that is greater than our kmer size <code>3</code>. This is good, because we need to kmerize the residual as well.</li>
</ul>
<p>We can formulate the constraint as <q><em>the effective length of all chunks must be less than or equal to <code>sequence_length - residual_length</code></em></q> with an additional constraint that <code>residual_length &gt;= kmer_size</code>.</p>
<p>Mathematically, we can formulate this as</p>
<p>\[
C + (N - 1) \cdot \bigl(C - (k - 1)\bigr) \leq L - R
\]</p>
<p>where \( C \) is the chunk size, \( N \) is the number of SIMD lanes, \( k \) is the kmer size, \( L \) is the sequence length, and \( R \) is the residual length.</p>
<p>Here, \( L - R \) is the maximum effective length we allow for the chunks, leaving at least \( R \) positions for the residual.</p>
<p>Re-arranging the expression, and substituting \( R = k \) (since the residual must be at least kmer-sized) we get</p>
<p>\[
C \leq \frac{L - k + (N - 1)(k - 1)}{N}
\]</p>
<p>Because we need an even length for the chunk size, we’ll use integer division (rounded down), which finally gives us</p>
<p>\[
C = \left\lfloor \frac{L - k + (N - 1)(k - 1)}{N} \right\rfloor
\]</p>
<p>We can now test this formula. We’ll plug in \( L = 34 \), \( k = 3 \) and \( N = 8 \):</p>
<p>\[
C = \left\lfloor \frac{34 - 3 + 7 \cdot 2}{8} \right\rfloor = \left\lfloor \frac{45}{8} \right\rfloor = 5
\]</p>
<p>Since we used integer division, we can re-calculate the residual to check its length. The effective length covered by 8 chunks is \( 5 + 7 \cdot 3 = 26 \), so the residual starts at position \( 26 - (k - 1) = 24 \) and has length \( 34 - 24 = 10 \), which is greater than our kmer size of 3.</p>
<h2 id="using-the-formula"><a class="header" href="#using-the-formula">Using The Formula</a></h2>
<p>We can codify this formula to generate SIMD chunks for the example sequence discussed above. In the code example below, we’ve also added a constraint for the chunk size to be larger than the kmer size.</p>
<pre class="playground"><code class="language-rust edition2024">fn get_chunk_size(kmer_size: usize, seq_len: usize, num_lanes: usize) -&gt; Option&lt;usize&gt; {
    let chunk_size = (seq_len - kmer_size + ((num_lanes - 1) * (kmer_size - 1))) / num_lanes;

    if chunk_size &lt;= kmer_size {
        return None;
    }

    Some(chunk_size)
}

fn chunk_seq&lt;'a&gt;(seq: &amp;'a [u8], kmer_size: usize, num_lanes: usize) -&gt; (Vec&lt;&amp;'a [u8]&gt;, &amp;'a [u8]) {
    let chunk_size = get_chunk_size(kmer_size, seq.len(), num_lanes).expect("sequence not long enough for kmer size {kmer_size}");

    let mut start = 0;
    let mut chunks: Vec&lt;&amp;[u8]&gt; = Vec::new();

    for _ in 0..num_lanes {
        let end = start + chunk_size;
        chunks.push(&amp;seq[start..end]);

        start += chunk_size - (kmer_size - 1);
    }

    let residual = &amp;seq[start..];

    (chunks, residual)
}

fn main() {
    let seq = b"AAAATTTTGGGGCCCCAAAATTTTGGGGCCCCTT";
    let kmer_size = 3;
    let num_lanes = 8;

    let (chunks, residual) = chunk_seq(seq, kmer_size, num_lanes);

    assert_eq!(
        chunks,
        vec![
            b"AAAAT", b"ATTTT", b"TTGGG", b"GGGCC", b"CCCCA", b"CAAAA", b"AATTT", b"TTTGG"
        ]
    );
    assert_eq!(residual, b"GGGGCCCCTT");
}</code></pre>
<h2 id="in-practice"><a class="header" href="#in-practice">In Practice</a></h2>
<p>From a practical aspect, one would typically use a crate that fully supports all of this out of the box. One example is <a href="https://docs.rs/simd-minimizers/latest/simd_minimizers/">simd-minimizers</a> which I’ve personally used for a few projects.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="building-a-reverse-index"><a class="header" href="#building-a-reverse-index">Building a Reverse Index</a></h1>
<p>Enough with SIMD, let’s talk about another very useful concept within bioinformatics - the reverse index.</p>
<p>But before this, what even is a “forward” index? Imagine you have a FASTA file, which contains your database sequences. This could be e.g., resistance genes, MLST alleles or something else. A “forward” index stores information about what database sequence contains what kmer hash. For example a simple <code>HashMap</code> with keys and values.</p>
<pre><code class="language-json">{
	"seq_1": [14184540469240097163, 18446744073709551615, ...],
	"seq_2": [4512398701234987123, 3141592653589793238, ...],
	...
	"seq_n": [6672914039128457702, 14184540469240097163, ...],
}
</code></pre>
<p>Remember, a kmer hash is simply a kmer (e.g., <code>b"AAA"</code>) that is u64 encoded and that has been fed into a hash function to generate a new u64.</p>
<p>Why would we store information like this? One reason is that if we have a bunch of kmer hashes from a query sequence, we can check which database sequence matches and how well. One way would be to loop over each (key, value) pair in the index (possibly in parallel) and check how many of the query kmer hashes are identical. This gives us an approximate sequence similarity.</p>
<h2 id="why-a-reverse-index-is-better"><a class="header" href="#why-a-reverse-index-is-better">Why A Reverse Index Is Better</a></h2>
<p>A reverse index is simply the reverse of a “forward” index, meaning that kmer hashes are the keys and the IDs of the database sequences that contain each hash are the values. E.g.,</p>
<pre><code class="language-json">{
	"14184540469240097163": ["seq_1", "seq_n"],
	"18446744073709551615": ["seq_1"],
	"4512398701234987123":  ["seq_2"],
	...
	"6672914039128457702":  ["seq_n"]
}
</code></pre>
<p>For the first entry, the reverse index above reads: “kmer hash <code>14184540469240097163</code> is found in <code>seq_1</code> and <code>seq_n</code>”.</p>
<p>We can do better. If we know the number of sequences, e.g., from reading the FASTA file, we can define a fixed size for the length of the value arrays. We can set them to exactly length <code>n</code> since each kmer hash can be present in at most <code>n</code> unique sequences. Also, let’s switch out the array of strings to a bitset. A bitset is essentially an array where each element can have one of two values, either 0 or 1:</p>
<ul>
<li><code>0</code> at index <code>i</code> means that sequence <code>i</code> does not contain the kmer hash.</li>
<li><code>1</code> at index <code>i</code> means that sequence <code>i</code> does contain the kmer hash.</li>
</ul>
<p>This refined reverse index would look something like:</p>
<pre><code class="language-json">{
	"14184540469240097163": [1, 0, ..., 1],
	"18446744073709551615": [1, 0, ..., 0],
	"4512398701234987123":  [0, 1, ..., 0],
	...
	"6672914039128457702":  [0, 0, ..., 1]
}
</code></pre>
<p>For the first entry, the reverse index now reads: “kmer hash <code>14184540469240097163</code> exists at index <code>0</code> and <code>n-1</code>”. If we originally had all sequences stored as something like a <code>sequences: Vec&lt;FastaRecord&gt; = [record_1, record_2, ..., record_n]</code> it would be as easy as to access the ids as <code>sequences[0].id</code> and <code>sequences[n-1].id</code>.</p>
<p>Why is this better than a forward index? Because using fixed size bitsets enables very efficient processing and minimal storage.</p>
<h2 id="using-a-reverse-index-in-practice"><a class="header" href="#using-a-reverse-index-in-practice">Using A Reverse Index In Practice</a></h2>
<p>Reverse indices are a cornerstone of many state-of-the-art bioinformatics tools that need to search or classify sequences at scale. For example, <a href="https://github.com/bingmann/cobs">COBS</a> (Compact Bit-Sliced Signature Index) uses a compressed reverse index to enable fast approximate membership queries across massive sequence collections. Similarly, <a href="https://github.com/sourmash-bio/sourmash">sourmash</a> leverages FracMinHash sketches with reverse index structures for rapid genome search and taxonomic classification. Other tools like <a href="https://github.com/Phelimb/BIGSI">BIGSI</a> and <a href="https://github.com/bluenote-1577/sylph">sylph</a> also rely on variations of this pattern. The core idea remains the same: by indexing kmer hashes and mapping them back to their source sequences, we can quickly identify which database entries share content with a query — without aligning every sequence pair.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="increasing-performance"><a class="header" href="#increasing-performance">Increasing Performance</a></h1>
<p>In this chapter, we’ll look at a few ways to improve the performance of our code. Some of these methods can be used to make significant improvements to code we have seen previously in this book (an exercise left to the reader).</p>
<p>Optimizing code is not always straightforward and might require something like <a href="https://github.com/flamegraph-rs/flamegraph">flamegraph</a> to identify bottlenecks. Usually, however, there are a few things that are always good to keep in mind. We’ll explore some of these in the following sections.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="using-appropriate-data-structures"><a class="header" href="#using-appropriate-data-structures">Using Appropriate Data Structures</a></h1>
<p>It is easy to default to using e.g., a <code>HashMap</code> or other variable sized data structures for convenience. This is usually fine until it isn’t. Below we’ll go through some data structures and why they might not be an optimal choice.</p>
<h2 id="hashmap"><a class="header" href="#hashmap">HashMap</a></h2>
<p>A <code>HashMap</code> is a very convenient way of storing data as key-value pairs. For example, if we want to count nucleotides in a string, we can use the nucleotide as the key and the count as the value. For the sequence <code>ACTTCC</code> it would look something like (pretty printed):</p>
<pre><code class="language-json">{
	"A": 1,
	"C": 3,
	"G": 0,
	"T": 2
}
</code></pre>
<p>Performance wise, a <code>HashMap</code> might provide some overhead due to:</p>
<ul>
<li>The need of hashing the key.</li>
<li>Potential memory re-allocation when it reaches its maximum capacity.</li>
</ul>
<p>These are not really of concern in the example above because the sequence is short and we are only concerned with four unique keys. In other instances however, it might be more relevant.</p>
<p>We can improve our <code>HashMap</code> by:</p>
<ul>
<li>Choosing a fast hash function such as <a href="https://docs.rs/rustc-hash/latest/rustc_hash/struct.FxHasher.html">FxHasher</a>.</li>
<li>Initializing our <code>HashMap</code> with a specified capacity. In our case, we could use <code>HashMap::with_capacity(4)</code> to ensure it can accommodate all our keys without having to re-allocate.</li>
</ul>
<p>With that said, there are cases when a <code>HashMap</code> is probably justified, such as in the chapter about <a href="#building-a-reverse-index">building a reverse index</a>.</p>
<h2 id="vec-1"><a class="header" href="#vec-1">Vec</a></h2>
<p><code>Vec</code> is another familiar and convenient data structure. Similar to a <code>HashMap</code>, a <code>Vec</code> is also dynamically sized and requires re-allocation when its capacity is reached. Consider the case where we’d like to kmerize the sequence <code>ATCATC</code> with <code>k=3</code> and store the kmers in a <code>Vec</code>. Since we know that the number of kmers we can generate is <code>6 - 3 + 1 = 4</code>, we can initialize a <code>Vec</code> with a capacity of <code>4</code> to avoid re-allocations when adding kmers.</p>
<h2 id="fixed-size-array"><a class="header" href="#fixed-size-array">Fixed Size Array</a></h2>
<p>In the case of counting nucleotides, using a fixed size array is much better than both a <code>HashMap</code> and a <code>Vec</code>. This data structure is of type <code>[&lt;dtype&gt;; &lt;length&gt;]</code> where <code>&lt;length&gt;</code> must be known at compile time.</p>
<p>The trick here is to utilize the nucleotide encoding, first encountered in the <a href="#encoding">encoding</a> chapter. If we assume that our sequence only consists of <code>{"A", "C", "G", "T"}</code> we can use a fixed size array of length <code>4</code>. The encoding maps each nucleotide <code>A, C, G, T</code> to <code>0, 1, 2, 3</code> which exactly corresponds to the indices we have in our array. Conceptually, we’d:</p>
<ul>
<li>Initialize a fixed size array of length <code>4</code> with all values set to <code>0</code>.</li>
<li>Loop over each nucleotide and encode.</li>
<li>Increment that index in the array.</li>
</ul>
<pre class="playground"><code class="language-rust edition2024">fn main(){
	let seq = b"AATCG";
	
	let mut counts: [usize; 4] = [0; 4];
	
	for nt in seq{
		let encoding = match nt{
			b'A' =&gt; 0,
			b'C' =&gt; 1,
			b'G' =&gt; 2,
			b'T' =&gt; 3,
			_ =&gt; continue
		};
		
		counts[encoding] += 1;
	}
	
	assert_eq!(counts, [2, 1, 1, 1]);
}</code></pre>
<p>It is not elegant to just skip unexpected characters. In practise, we could use a lookup table to map:</p>
<ul>
<li>canonical bases <code>{A, C, G, T}</code> (and possibly <code>{a, c, g, t}</code>) to <code>{0, 1, 2, 3}</code>.</li>
<li>ambiguous bases <code>N</code> to <code>4</code>.</li>
<li>everything else to <code>5</code>.</li>
</ul>
<p>This, however, requires us to use an array of length <code>6</code>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="favor-compile-time"><a class="header" href="#favor-compile-time">Favor Compile Time</a></h1>
<p>A general rule I’ve found to work quite nicely is to favor compile time when possible. An excellent example of this is our lookup tables for nucleotide encoding and phred-score-to-error.</p>
<h2 id="lookup-tables"><a class="header" href="#lookup-tables">Lookup Tables</a></h2>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>As of recent Rust versions, many use cases for <code>lazy_static!</code> can be replaced with <code>std::sync::LazyLock</code> (stabilized in Rust 1.80). Consider this alternative for simpler, dependency-free compile-time initialization.</p>
</blockquote>
<p>We can use the <a href="https://docs.rs/lazy_static/latest/lazy_static/">lazy_static</a> crate to define static lookup tables. In the code example below, we define two lookup tables:</p>
<ul>
<li>One for converting ASCII characters to nucleotide encoding.</li>
<li>One for converting ASCII qualities to error probabilities.</li>
</ul>
<pre class="playground"><code class="language-rust edition2024"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use lazy_static::lazy_static;

const PHRED_OFFSET: usize = 33;
const MAX_PHRED_INDEX: usize = 93;

lazy_static! {
    pub static ref NT_LOOKUP: [u8; 256] = {
        let mut table = [4u8; 256];

        for i in 0u8..=255 {
            table[i as usize] = match i {
                b'A' | b'a' =&gt; 0,
                b'C' | b'c' =&gt; 1,
                b'G' | b'g' =&gt; 2,
                b'T' | b't' | b'U' | b'u' =&gt; 3,
                _ =&gt; 4,
            };
        }

        table
    };

    pub static ref PHRED_TO_ERROR: [f64; MAX_PHRED_INDEX + 1] = {
        let mut error_lookup = [1.0; MAX_PHRED_INDEX + 1];

        for (i, entry) in error_lookup.iter_mut().enumerate().skip(PHRED_OFFSET) {
            *entry = 10_f64.powf(-((i - PHRED_OFFSET) as f64) / 10.0);
        }

        error_lookup
    };
}
<span class="boring">}</span></code></pre>
<p>At least for <code>PHRED_TO_ERROR</code>, the advantage of using a static lookup table is obvious. We avoid repeated calculations of</p>
<p>\[ \text{error_probability} = 10^{-phred/10}\]</p>
<p>since the values are now <q>cached</q> in the lookup table. Note that in the code above, we also cap the ASCII value <code>93</code>, which corresponds to a phred score of <code>93 - 33 = 60</code> (an error probability of <code>10e-6</code>). This is optional, but avoids storing non-sensically low error probabilities that are very rarely encountered. The disadvantage of this approach is that when iterating over the ASCII qualities in a FASTQ record, we must make sure to cap the quality at <code>93</code> before indexing into the lookup table.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="multithreading"><a class="header" href="#multithreading">Multithreading</a></h1>
<p>We’ve discussed multithreading in an earlier <a href="#multi-threading">chapter</a>, but it is worth revisiting.</p>
<p>Multithreading enables us to literally run code in parallel, which is sometimes advantageous within bioinformatics. However, we should also be a bit careful about when multithreading helps and also when it hurts.</p>
<h2 id="ideal-use-cases"><a class="header" href="#ideal-use-cases">Ideal Use Cases</a></h2>
<p>Multithreading shines during CPU-heavy workloads when the outputs are independent of each other. A good example of this is calculating stats for multiple FASTQ files in parallel. Since the files (and their outputs) are completely independent, adding multithreading can be a huge win.</p>
<pre class="mermaid">graph TD
    S1["sample_1.fastq.gz"] --&gt;  E["process *n_thread* files in parallel"] 
    S["..."] --&gt; E
    SN["sample_N.fastq.gz"] --&gt; E
    
    E --&gt; O1["sample_1.json"]
    E --&gt; O["..."]
    E --&gt; ON["sample_N.json"]
    
    style E fill:#2a2,color:#fff

</pre>

<h2 id="conditional-benefits"><a class="header" href="#conditional-benefits">Conditional Benefits</a></h2>
<p>There are cases when multithreading might help, but the benefit depends on the specifics of the workload. Consider a single FASTA file, for which we’d like to process individual sequences in parallel. Maybe we’d like to calculate the <code>GC</code> content for each contig and collect the result in to a <code>Vec</code>. Here, we have a tradeoff between the time it takes to calculate the GC content for each contig vs the overhead of maintaining the logistics of a threadpool.</p>
<pre class="mermaid">graph TD
    S1["ATCG...AGA"] --&gt;  E["process *n_thread* contigs in parallel"] 
    S["..."] --&gt; E
    SN["CGAT...AGT"] --&gt; E
    
    E --&gt; F["::collect()"]
    F --&gt; O1["[0.52, ..., 0.49]"]
    
    style E fill:#f80,color:#fff

</pre>

<p>If the contigs are very short, the bottleneck probably isn’t calculating GC content but rather the overhead of distributing nucleotide sequences to each thread. We also need to wait for every calculation to finish before we can access the resulting <code>Vec</code>. In this case, multithreading adds more overhead than it saves.</p>
<p>If the contigs are very long, e.g., if the FASTA file contains multiple large single contig genomes, the bottleneck might actually be the GC calculation itself. In this case, multithreading can provide a meaningful speedup.</p>
<p>The takeaway is to consider the ratio of useful computation to coordination overhead. When the work per unit is small relative to the cost of dispatching it to a thread, you might not see a benefit.</p>
<h2 id="when-to-avoid-multithreading"><a class="header" href="#when-to-avoid-multithreading">When To Avoid Multithreading</a></h2>
<p>A rather questionable example of using multithreading would be trying to convert a FASTQ ASCII quality string to error probabilities. E.g., trying to map <code>b"????????"</code> to <code>[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]</code>. In theory, we could use <code>8</code> threads to attempt to do this in parallel. However, the arithmetic operation of converting <code>b'?'</code> to <code>0.001</code> is very fast and the bottleneck here is most likely maintaining the logistics around the threadpool we need to run this operation in parallel.</p>
<p>As a general rule, if the per-item computation takes less time than the overhead of scheduling work onto a thread, multithreading will make things slower, not faster. For cheap operations like arithmetic conversions or table lookups, a simple sequential loop will outperform a parallel one.</p>
<pre class="mermaid">graph TD
    S1["? ? ? ? ? ? ? ?"] --&gt;  Q1["?"]
    S1 --&gt; Q["..."]
    S1 --&gt; Q8["?"]
    
    Q1 --&gt; P1["process *n_thread* quality values in parallel"]
    Q --&gt; P1
    Q8 --&gt; P1
    
    P1 --&gt; R["[0.001, ..., 0.001]"]
    
    style P1 fill:#d44,color:#fff
</pre>

<div style="break-before: page; page-break-before: always;"></div>
<h1 id="aminoacids"><a class="header" href="#aminoacids">Aminoacids</a></h1>
<p>In the past chapters, we have gone through some fundamental ways to analyze and manipulate nucleotide sequences. Now, we’ll take a brief look at aminoacid sequences. Luckily, some of the concepts we have implemented for nucleotides also apply to aminoacids, with some minor tweaking of the code. Examples are:</p>
<ul>
<li>Counting aminoacids.</li>
<li>Identifying homopolymers.</li>
<li>Hamming distance.</li>
<li>Global and local aligner (with suitable substitution matrix).</li>
</ul>
<h2 id="codon-table"><a class="header" href="#codon-table">Codon Table</a></h2>
<p>For aminoacids, we have to think triplets of nucleotides because this is what encodes aminoacids. In Rust, we can use something like the <a href="https://docs.rs/bio-seq/latest/bio_seq/translation/index.html">bio_seq</a> crate. However, for fun we’ll create our own very basic <code>HashMap</code> using the <a href="https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi#SG1.">standard</a> NCBI codon table.</p>
<pre class="playground"><code class="language-rust edition2024">use std::collections::HashMap;

fn generate_codon_table&lt;'a&gt;() -&gt; HashMap&lt;[u8; 3], u8&gt; {
    let aa = b"FFLLSSSSYY**CC*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG";

    let base1 = b"TTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCAAAAAAAAAAAAAAAAGGGGGGGGGGGGGGGG";
    let base2 = b"TTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGG";
    let base3 = b"TCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAG";

    let map: HashMap&lt;[u8; 3], u8&gt; = (0..aa.len())
        .map(|i| {
            let value = aa[i];
            let key = [base1[i], base2[i], base3[i]];

            return (key, value);
        })
        .collect();

    return map;
}

fn main() {
    let codon_table = generate_codon_table();

    assert_eq!(codon_table.get(b"ATG"), Some(&amp;b'M'));
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="translation"><a class="header" href="#translation">Translation</a></h1>
<p>When it comes to translation, there is a couple of things we need to consider:</p>
<ul>
<li>
<p><code>sequence_length</code> - Is the length of our nucleotide string divisible by 3? If no, then we need to handle this. Otherwise, we might encounter a partial codon.</p>
<p>E.g., <code>ATGTTTTAG</code> -&gt; <code>ATG TTT TAG</code> is a well behaved nucleotide string.</p>
</li>
<li>
<p><code>frames</code> - The forward strand has three reading frames, so does the reverse strand. Ideally, we’d try translating all six frames.</p>
<p>E.g., <code>...ATGTTTTAG...</code> can be read in the forward direction as:<br>
<code>...ATG TTT TAG...</code> or<br>
<code>....TGT TTT AG...</code> or<br>
<code>.....GTT TTA G...</code><br><br>
where <code>...</code> is the remaining part of the string.</p>
</li>
<li>
<p><code>ambiguous nucleotides</code> - We need to decide how to handle ambiguous and softmasked nucleotides.</p>
</li>
</ul>
<p>For this first implementation, we’ll use the first frame of the forward strand and <code>panic!</code> if the length is not divisible by 3.</p>
<pre class="playground"><code class="language-rust edition2024"><span class="boring">use std::collections::HashMap;
</span><span class="boring">
</span><span class="boring">fn generate_codon_table() -&gt; HashMap&lt;[u8; 3], u8&gt; {
</span><span class="boring">    let aa = b"FFLLSSSSYY**CC*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG";
</span><span class="boring">
</span><span class="boring">    let base1 = b"TTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCAAAAAAAAAAAAAAAAGGGGGGGGGGGGGGGG";
</span><span class="boring">    let base2 = b"TTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGG";
</span><span class="boring">    let base3 = b"TCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAG";
</span><span class="boring">
</span><span class="boring">    let map: HashMap&lt;[u8; 3], u8&gt; = (0..aa.len())
</span><span class="boring">        .map(|i| {
</span><span class="boring">            let value = aa[i];
</span><span class="boring">            let key = [base1[i], base2[i], base3[i]];
</span><span class="boring">
</span><span class="boring">            return (key, value);
</span><span class="boring">        })
</span><span class="boring">        .collect();
</span><span class="boring">
</span><span class="boring">    return map;
</span><span class="boring">}
</span>// [...]

fn translate(seq: &amp;[u8], codon_table: &amp;HashMap&lt;[u8; 3], u8&gt;) -&gt; Vec&lt;u8&gt; {
    if seq.len() % 3 != 0 {
        panic!("Length of sequence must be divisible by three.");
    }

    let translation: Vec&lt;u8&gt; = seq
        .chunks(3)
        .filter_map(|codon| match codon_table.get(codon) {
            Some(aa) =&gt; Some(*aa),
            None =&gt; None,
        })
        .collect();

    return translation;
}

fn main() {
    let codon_table = generate_codon_table();

    assert_eq!(translate(b"ATGTAG", &amp;codon_table), b"M*");
    assert_eq!(translate(b"", &amp;codon_table), b"");
}</code></pre>
<p>There is lots of room for improvement here, such as accounting for frames and also ending the iteration when we encounter a stop codon.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="accounting-for-frames"><a class="header" href="#accounting-for-frames">Accounting For Frames</a></h1>
<p>We can refine our approach for translating a nucleotide sequence by considering the six frames (three in the forward direction and three in the reverse).</p>
<p>The Rust code becomes a bit complex, but basically we:</p>
<ol>
<li>Iterate over our three start positions at (zero-based) indices 0, 1 and 2.</li>
<li>From each start position, we chunk the sequence by length 3 to produce complete codons.</li>
<li>For each codon we translate to an aminoacid.</li>
<li>Finally, we extract the longest translated sequence from the three different frames.</li>
</ol>
<p>We use <code>chunk_exact</code> to skip the last chunks that are not of length 3. <code>map_while</code> makes sure we stop iterating when we reach a stop codon (or invalid codon, e.g., if we have ambiguous nucleotides).</p>
<p>The code below does not take the reverse complement into consideration (the reader is encouraged to implement this).</p>
<pre class="playground"><code class="language-rust edition2024">use std::collections::HashMap;

<span class="boring">fn generate_codon_table() -&gt; HashMap&lt;Vec&lt;u8&gt;, u8&gt; {
</span><span class="boring">   let aa = b"FFLLSSSSYY**CC*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG";
</span><span class="boring">
</span><span class="boring">   let base1 = b"TTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCAAAAAAAAAAAAAAAAGGGGGGGGGGGGGGGG";
</span><span class="boring">   let base2 = b"TTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGG";
</span><span class="boring">   let base3 = b"TCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAG";
</span><span class="boring">
</span><span class="boring">   let map: HashMap&lt;Vec&lt;u8&gt;, u8&gt; = (0..aa.len())
</span><span class="boring">       .map(|i| {
</span><span class="boring">           let value = aa[i];
</span><span class="boring">           let key = vec![base1[i], base2[i], base3[i]];
</span><span class="boring">
</span><span class="boring">           return (key, value);
</span><span class="boring">       })
</span><span class="boring">       .collect();
</span><span class="boring">
</span><span class="boring">   return map;
</span><span class="boring">}
</span>// [...]

fn get_longest_translation(codon_table: &amp;HashMap&lt;Vec&lt;u8&gt;, u8&gt;, seq: &amp;[u8]) -&gt; Vec&lt;u8&gt; {
    let frames: usize = 3;

    let longest_translations: Vec&lt;u8&gt; = (0..frames)
        .map(|start_pos| {
            // Process nt string in chunks of three and stop when we don't have enough nucleotides for a codon.
            let translated: Vec&lt;u8&gt; = seq[start_pos..]
                .chunks_exact(3)
                .map_while(|codon| {
                    let aa = match codon_table.get(codon) {
                        None | Some(b'*') =&gt; None,
                        Some(valid) =&gt; Some(*valid),
                    };

                    aa
                })
                .collect();

            translated
        })
        .max_by_key(|translation| translation.len())
        .expect("Failed to extract longest translated sequence");

    longest_translations
}

fn main() {
    let codon_table = generate_codon_table();

    // Single codon in first frame.
    assert_eq!(get_longest_translation(&amp;codon_table, b"ATG"), vec![b'M']);

    // Two valid codons in first frame.
    assert_eq!(
        get_longest_translation(&amp;codon_table, b"ATGGGG"),
        vec![b'M', b'G']
    );

    // In frame 1 -&gt; M*PP -&gt; M
    // In frame 2 -&gt; CNPP
    // In frame 3 -&gt; VTP
    assert_eq!(
        get_longest_translation(&amp;codon_table, b"ATGTAACCCCCCC"),
        vec![b'C', b'N', b'P', b'P']
    );
}</code></pre>
<p>There is still room for improvement. First, we end the iteration when we encounter a stop codon, but don’t actually include it in the return value. Second, using a <code>HashMap</code> is not ideal.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="improving-translation-algorithm"><a class="header" href="#improving-translation-algorithm">Improving Translation Algorithm</a></h1>
<p>The previous approach for mapping codons to amino acids works, but it is not the most efficient. Mainly because of the <code>HashMap</code>. There is a performance penalty involved in having to hash input keys and find them.</p>
<p>There is a more brilliant approach, which (you guessed it) involves bit shifts. Let’s look again at our codon table:</p>
<pre><code class="language-rust noplayground">    let aa = b"FFLLSSSSYY**CC*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG";

    let base1 = b"TTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCAAAAAAAAAAAAAAAAGGGGGGGGGGGGGGGG";
    let base2 = b"TTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGG";
    let base3 = b"TCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAG";</code></pre>
<p>The order is not random, but rather deliberate. The order of the codons is:</p>
<pre><code>TTT, TTC, TTA, TTG, ...,
CTT, CTC, CTA, CTG, ..., 
ATT, ATC, ATA, ATG, ...,
GTT, GTC, GTA, GTG, ...,
GGG 
</code></pre>
<p>From this, we can derive an order where <code>T &lt; C &lt; A &lt; G</code>. We have a total of 64 amino acids, so we need a way to map <code>TTT -&gt; index 0</code> and <code>GGG -&gt; index 63</code>. Recall that a codon is essentially a kmer of length 3, so we can take inspiration from the bit shift encoding we did in section 6.3. Here, however, we need to map nucleotides accordingly:</p>
<ul>
<li><code>T</code> =&gt; <code>0b00</code></li>
<li><code>C</code> =&gt; <code>0b01</code></li>
<li><code>A</code> =&gt; <code>0b10</code></li>
<li><code>G</code> =&gt; <code>0b11</code></li>
</ul>
<p>Each nucleotide occupies 2 bits and since we need three of them to form a codon, we need 6 bits in total (we’ll use <code>usize</code> for convenience though). We have a total of <code>4^3 = 64</code> combinations of triplets than can form codons. In addition, using a 6 bit encoding, we cover numbers up to <code>0b111111 = 2⁵ + 2⁴ ... + 2⁰ = 63</code>. The formula we’ll use to pack the nucleotides is <code>(base_1 &lt;&lt; 4) | (base_2 &lt;&lt; 2) | base_3</code>.</p>
<p>Consider the case of <code>b"GGG"</code>, which gives us <code>base_1 = b'G' =&gt; 0b11</code>, <code>base_2 = b'G' =&gt; 0b11</code> and <code>base_3 = b'G' =&gt; 0b11</code>. Doing the bit-shifts (without the ORs) gives:</p>
<pre><code>0b...000011 &lt;&lt; 4 = 0b...110000	# base_1
0b...000011 &lt;&lt; 2 = 0b...001100	# base_2
0b...000011 	 = 0b...000011	# base_3
</code></pre>
<p>Now, including the ORs, we get <code>0b...110000 | 0b...001100 | 0b...000011 = 0b...111111</code>, which is the number <code>63</code> in base 10. You can visually check that <code>b"GGG"</code> maps to the amino acid <code>G</code>. Similarly, using the 6 bit encoding for <code>b"TTT"</code> results in <code>0b...000000</code>, which is the number <code>0</code> in base 10. We can also visually check that <code>b"TTT"</code> corresponds to the first amino acid.</p>
<p>Putting all of this into code, it would look something like this</p>
<pre class="playground"><code class="language-rust edition2024">const CODON_STANDARD: &amp;[u8; 64] =
    b"FFLLSSSSYY**CC*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG";

const NT_CODON_MAP: [u8; 256] = {
    let mut map = [0u8; 256];
    map[b'T' as usize] = 0;
    map[b'C' as usize] = 1;
    map[b'A' as usize] = 2;
    map[b'G' as usize] = 3;
    // softmask
    map[b't' as usize] = 0;
    map[b'c' as usize] = 1;
    map[b'a' as usize] = 2;
    map[b'g' as usize] = 3;

    map[b'U' as usize] = 0;

    map
};

pub enum CodonTable {
    Standard,
}

impl CodonTable {
    pub fn table(&amp;self) -&gt; &amp;[u8; 64] {
        match self {
            CodonTable::Standard =&gt; CODON_STANDARD,
        }
    }
}

enum Frame {
    First,
    Second,
    Third,
}

impl Frame {
    pub fn start_pos(&amp;self) -&gt; usize {
        match self {
            Frame::First =&gt; 0,
            Frame::Second =&gt; 1,
            Frame::Third =&gt; 2,
        }
    }
}


fn translate(codon_table_type: CodonTable, frame: &amp;Frame, seq: &amp;[u8]) -&gt; Vec&lt;u8&gt; {
    let start_pos = frame.start_pos();

    if seq.len() &lt; 3 {
        return vec![];
    }

    let codon_table = codon_table_type.table();

    let mut translated: Vec&lt;u8&gt; = Vec::with_capacity(seq.len() / 3);

    for codon in seq[start_pos..].chunks_exact(3) {
        let b1 = NT_CODON_MAP[codon[0] as usize] as usize;
        let b2 = NT_CODON_MAP[codon[1] as usize] as usize;
        let b3 = NT_CODON_MAP[codon[2] as usize] as usize;

        let index = (b1 &lt;&lt; 4) | (b2 &lt;&lt; 2) | b3;

        let aa = codon_table[index];

        translated.push(aa);

        if aa == b'*' {
            break;
        }
    }

    translated
}

fn main(){
	let seq = b"ATG";
	let translated = translate(CodonTable::Standard, &amp;Frame::First, seq);
	assert_eq!(&amp;translated[..], b"M");	
	
	let seq = b"ATGTGA";
	let translated = translate(CodonTable::Standard, &amp;Frame::First, seq);
	assert_eq!(&amp;translated[..], b"M*");	
}</code></pre>
<p>A possible improvement here would be to handle ambiguous nucleotides and not just map them to <code>0</code> (which is done implicitly since we initialize <code>[0_u8; 256]</code> before overwriting with the nucleotide specific encodings).</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="amplicon"><a class="header" href="#amplicon">Amplicon</a></h1>
<p>As we all know, there are multiple different approaches to genome sequencing. I’ll list my interpretation of the different approaches below:</p>
<ul>
<li><code>WGS</code> - Is a rather broad term, but generally refers to single isolate sequencing. This could be for example sequencing the entire genome from a single bacterial colony.</li>
<li><code>Shotgun</code> - Generally refers to sequencing the entire genomes from multiple taxa (metagenomic sample). For example, sequencing a gut sample from a patient.</li>
<li><code>Amplicon</code> - Is a targeted approach, commonly used with PCR. The goal here is to sequence a part of the target genome. One example is amplicon sequencing of the 16S bacterial rRNA region.</li>
</ul>
<p>Amplicon sequencing has several advantages compared to other sequencing protocols:</p>
<ul>
<li>Reduced costs per sample due to sequencing less DNA for a shorter period of time.</li>
<li>Enables sequencing more samples in parallel due to smaller sample sizes.</li>
<li>The bioinformatic analysis is generally less computationally heavy.</li>
</ul>
<p>However, this does not come without disadvantages:</p>
<ul>
<li>PCR can introduce artifacts.</li>
<li>Off targets, depending on the primer design.</li>
<li>Reduced genomic resolution.</li>
</ul>
<p>In the following chapters, we’ll go through some very basic Rust implementations of common amplicon based analyses.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="in-silico-pcr"><a class="header" href="#in-silico-pcr">In Silico PCR</a></h1>
<p>The first amplicon based analysis we’ll cover is in silico PCR. The goal is to find certain genomic regions, not by searching for the sequences themselves, but rather through identifying flanking primer regions.</p>
<p>Consider a case where we are looking for a genomic region which can be quite diverse across taxa, but has very conserved flanking sites. This is the case for e.g., the 16S rRNA region in bacteria. Alignment approaches might not be suitable if we are unsure of, or expect a large diversity in the target region.</p>
<p>The following example tries to illustrate this, where the conserved flanking regions are <code>ATATAT</code> and <code>GTGTGT</code>.</p>
<pre><code>...ATATAT ACGTGACGTGACGGAGAT GTGTGT...  # taxa_1
...ATATAT ACCTAGCGTAGTCGAGTG GTGTGT...  # taxa_2
...ATATAT ACCTAGCGTACGAGTG GTGTGT...    # taxa_3
</code></pre>
<p>Instead of looking directly at the target region we can search for flanking sites, extract the target region and use some kind of length cutoff to prevent outliers. In the example above, using flanking sites <code>ATATAT</code> and <code>GTGTGT</code> with a length threshold of <code>&gt;= 15</code> and <code>&lt;= 20</code> would capture all three target regions with some margin.</p>
<pre class="playground"><code class="language-rust edition2024">fn primer_search(primer: &amp;[u8], seq: &amp;[u8]) -&gt; Option&lt;usize&gt; {
    for (i, window) in seq.windows(primer.len()).enumerate() {
        if window == primer {
            return Some(i);
        }
    }
    return None;
}

fn is_pcr&lt;'a&gt;(start: &amp;'a [u8], end: &amp;'a [u8], seq: &amp;'a [u8]) -&gt; Option&lt;&amp;'a [u8]&gt; {
    let start_index = primer_search(start, seq);

    let end_index = primer_search(end, seq);

    match (start_index, end_index) {
        (Some(s), Some(e)) =&gt; {
            let actual_start = s + start.len();

            if actual_start &lt; e {
                return Some(&amp;seq[actual_start..e]);
            }

            return None;
        }
        _ =&gt; return None,
    }
}

fn main() {
    assert_eq!(is_pcr(b"A", b"G", b""), None);
    assert_eq!(is_pcr(b"AT", b"CG", b"ATCG"), None);
    assert_eq!(is_pcr(b"AT", b"CG", b"ATTCG"), Some(&amp;b"T"[..]));
    assert_eq!(
        is_pcr(b"AAA", b"TTT", b"CGCGCGAAACCCCCCTTTCGCGCG"),
        Some(&amp;b"CCCCCC"[..])
    );
}</code></pre>
<p>In the code example above, our naive implementation just uses an exact string search for our flanking regions. We then check if the start primer is located prior to the end primer. If it is, we extract the interjacent sequence. Some good improvements to the code would be:</p>
<ul>
<li>Enable multiple matches to the start and end primer for finding multiple interjacent regions.</li>
<li>Add a <code>min_len</code> and <code>max_len</code> criteria to filter out potential outliers.</li>
<li>Check both forward and reverse complements.</li>
<li>Replace <code>.windows()</code> with something faster. For exact matches, <a href="https://docs.rs/memchr/latest/memchr/">memchr</a> is a good alternative.</li>
<li>Add fuzzy search to allow for a few mismatches between the primers and the sequence. A good alternative here is <a href="https://docs.rs/bio/latest/bio/pattern_matching/myers/index.html">myers</a> from the <a href="https://docs.rs/bio/latest/bio/">bio</a> crate since it supports ambiguous nucleotides.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="clustering"><a class="header" href="#clustering">Clustering</a></h1>
<p>Within amplicon analysis, read clustering is commonly applied as a type of dimensionality reduction. A typical example of this is prior to taxonomic classification. Usually, it is redundant and computationally expensive to classify every single read in a sample. Especially if multiple reads belong to the same taxa.</p>
<p>Consider a theoretical example with a known prior taxonomic distribution where we have 100,000 reads, half of which belong to <em>Escherichia coli</em> and the rest belong to <em>Staphylococcus aureus</em>. Instead of classifying all reads, we apply read clustering and get two distinct clusters, each containing 50,000 reads. From each cluster, we pick one representative sequence (E.g., the read with the highest quality) and classify only that one. Pretend that our two representatives (one for each cluster) classifies as <em>Escherichia coli</em> and <em>Staphylococcus aureus</em> respectively. We then extrapolate the classification for both clusters and say that 50,000 reads belong to <em>Escherichia coli</em> and 50,000 reads belong to <em>Staphylococcus aureus</em>, even though we only classified two sequences.</p>
<p>Obviously, we don’t always know the taxonomic distribution beforehand. Maybe if we use a mock sample, otherwise generally we don’t. There are also several questions that need to be addressed regarding our theoretical example:</p>
<ul>
<li>What algorithm should we use for read clustering?</li>
<li>What thresholds are suitable for considering a read part of a cluster?</li>
<li>How do we pick a suitable representative sequence from each cluster?</li>
</ul>
<h2 id="algorithms"><a class="header" href="#algorithms">Algorithms</a></h2>
<p>There are multiple different approaches we can use for read clustering, each with its pros and cons. Common methods include:</p>
<p><strong>Alignment based</strong> methods rely on some version of global, semi-global or local alignment. This approach is relatively slow but can be highly accurate.</p>
<p><strong>Kmer based</strong> methods rely on kmers for sequence similarity. This is an alignment free method that is fast but not always as sensitive as alignment based methods. In order to save even more space and time, we can use minimizers or syncmers.</p>
<p><strong>Cluster free</strong> methods do not really belong in this chapter, but we’ll briefly mention them anyways. These methods usually try to classify reads directly without an intermediary clustering step. One example is <a href="https://github.com/treangenlab/emu">EMU</a>, which leverages read error rates and an iterative maximum likelihood algorithm.</p>
<h2 id="thresholds"><a class="header" href="#thresholds">Thresholds</a></h2>
<p>We need some kind of metric to decide if a read belongs to an already existing cluster, or if it should initiate a new cluster. Obviously, this depends on if we use an alignment based method, or a kmer based method.</p>
<p>Historically, for alignment methods a threshold of 97% similarity has been used to classify two sequences as belonging to the same <a href="https://en.wikipedia.org/wiki/Operational_taxonomic_unit">Operational Taxonomic Unit</a> (OTU). The obvious downside to the OTU approach is that taxa with &gt;97% similarity are collapsed.</p>
<p>A more recent approach is to use <a href="https://doi.org/10.1038/ismej.2017.119">Amplicon Sequence Variants</a>, which is a more high resolution approach. With the improvements in NGS data quality, it is much easier to distinguish sequencing errors from true biological variation. This means we can relatively accurately identify the exact taxonomic variation in the sample and leverage that. The ASV approach is commonly used for Illumina data, but might be unsuitable for error prone Nanopore data.</p>
<p>For kmer approaches, we can use set theory to calculate how many, and the fraction of, shared kmers we have between the read and the cluster. The <a href="https://en.wikipedia.org/wiki/Jaccard_index">jaccard index</a> is a good example of this.</p>
<p>Read error rates are also something that must be considered. This is not generally a problem for Illumina data, but it can be for Nanopore. For example, if the average error rate in a sample is 3%, we need to take this into consideration when we choose a threshold. Error rates also become a problem during classification. If the average error rate is 3%, but the taxa we are trying to distinguish are &gt;97% similar, we might run into issues.</p>
<h2 id="representatives"><a class="header" href="#representatives">Representatives</a></h2>
<p>How to choose a representative sequence from a cluster varies across bioinformatic tools. A few common ways are:</p>
<ul>
<li>
<p><strong>First seen in cluster</strong>. The most straightforward way is to choose the read that initiated the cluster. However, since we don’t consider read length, error rate or anything else, this method might not be appropriate unless we have done any prior read sorting.</p>
</li>
<li>
<p><strong>Choosing the longest sequence</strong>. One could argue that the longer the representative, the longer alignment or the most kmers we can generate. However, we probably need to consider factors such as outliers and sequence errors as well.</p>
</li>
<li>
<p><strong>Choosing a random sequence</strong>. This approach introduces a bit of stochasticity unless we use a seed.</p>
</li>
<li>
<p><strong>Choosing the highest quality sequence</strong>. For Nanopore samples, this is a highly suitable approach because the sequence with the lowest error rate generally has the potential to generate the best classification.</p>
</li>
<li>
<p><strong>Least intercluster distance</strong>. For each cluster, we choose the sequence that has the least total distance to all other sequences in the cluster. This approach uses some kind of concept of a <q>mean</q> and is a bit more robust towards accidentally picking outliers, but might be a bit more computationally heavy.</p>
</li>
<li>
<p><strong>Generating a consensus sequence</strong>. If we expect the sequences in a cluster to be highly similar, we could generate a consensus sequence. This essentially means we generate a new sequence, based on some kind of multiple sequence alignment of all reads in the cluster, and take the majority vote in each position.</p>
</li>
</ul>
<h2 id="code-example"><a class="header" href="#code-example">Code example</a></h2>
<p>Clustering algorithms can be quite complex so we’ll create a <em>very</em> basic native Rust implementation here, which uses minimizers (using code from our sloppy, earlier implementation). We won’t bother with sorting sequences or choosing representatives but rather just keeping track of how many clusters we generate and their members.</p>
<p>Conceptually what we do is:</p>
<pre class="mermaid">graph TD
    A["Start with 0 clusters"] --&gt; B["For each sequence"]
    B --&gt; C["Extract minimizers"]
    C --&gt; D["For each existing cluster"]
    D --&gt; E["Calculate Jaccard index"]
    E --&gt; F{"Jaccard &gt;= threshold?"}
    F -- "Yes" --&gt; G["Assign to cluster"]
    F -- "No" --&gt; H{"More clusters?"}
    H -- "Yes" --&gt; D
    H -- "No" --&gt; I["Create new cluster"]
    G --&gt; B
    I --&gt; B
</pre>

<pre class="playground"><code class="language-rust edition2024"><span class="boring">use std::{cmp::min, collections::HashSet, vec};
</span><span class="boring">
</span><span class="boring">fn reverse(nt: &amp;u8) -&gt; u8 {
</span><span class="boring">    match nt {
</span><span class="boring">        b'A' =&gt; b'T',
</span><span class="boring">        b'C' =&gt; b'G',
</span><span class="boring">        b'G' =&gt; b'C',
</span><span class="boring">        b'T' =&gt; b'A',
</span><span class="boring">        _ =&gt; panic!("Invalid nt."),
</span><span class="boring">    }
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">fn minimizer_from_windows&lt;'a&gt;(
</span><span class="boring">    w_forward: &amp;'a [u8],
</span><span class="boring">    w_reverse: &amp;'a [u8],
</span><span class="boring">    kmer_size: usize,
</span><span class="boring">) -&gt; &amp;'a [u8] {
</span><span class="boring">    let min_fwd = w_forward.windows(kmer_size).min().unwrap();
</span><span class="boring">    let min_rev = w_reverse.windows(kmer_size).min().unwrap();
</span><span class="boring">
</span><span class="boring">    return min(min_fwd, min_rev);
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">fn get_minimizers(seq: &amp;[u8], window_size: usize, kmer_size: usize) -&gt; HashSet&lt;String&gt; {
</span><span class="boring">    let sliding_window_size = window_size + kmer_size - 1;
</span><span class="boring">    assert!(sliding_window_size &lt;= seq.len());
</span><span class="boring">
</span><span class="boring">    // We'll store the minimizers as strings for convenience.
</span><span class="boring">    let mut h: HashSet&lt;String&gt; = HashSet::new();
</span><span class="boring">
</span><span class="boring">    let rev_comp: Vec&lt;u8&gt; = seq.iter().rev().map(|nt| reverse(nt)).collect();
</span><span class="boring">
</span><span class="boring">    // Create windows for both forward and reverse sequences.
</span><span class="boring">    seq.windows(sliding_window_size)
</span><span class="boring">        .zip(rev_comp.as_slice().windows(sliding_window_size))
</span><span class="boring">        // Iterate over forward/reverse windows at the same time.
</span><span class="boring">        .for_each(|(w_forward, w_reverse)| {
</span><span class="boring">            let minimizer = minimizer_from_windows(w_forward, w_reverse, kmer_size);
</span><span class="boring">            h.insert(String::from_utf8(minimizer.to_vec()).unwrap());
</span><span class="boring">        });
</span><span class="boring">
</span><span class="boring">    return h;
</span><span class="boring">}
</span>// [...]

fn jaccard_index(h1: &amp;HashSet&lt;&amp;[u8]&gt;, h2: &amp;HashSet&lt;&amp;[u8]&gt;) -&gt; f64 {
    let num_common = h1.intersection(h2).count();
    let num_total = h1.union(h2).count();

    return num_common as f64 / num_total as f64;
}

fn cluster&lt;'a&gt;(
    seqs: &amp;[(&amp;'a str, &amp;[u8])],
    kmer_size: usize,
    window_size: usize,
    threshold: f64,
) -&gt; Vec&lt;(HashSet&lt;String&gt;, Vec&lt;&amp;'a str&gt;)&gt; {
    let mut clusters: Vec&lt;(HashSet&lt;String&gt;, Vec&lt;&amp;str&gt;)&gt; = Vec::new();

    for (seq_name, seq) in seqs {
        let minimizers = get_minimizers(seq, window_size, kmer_size);
        let minimizer_set: HashSet&lt;&amp;[u8]&gt; = minimizers.iter().map(|m| m.as_bytes()).collect();

        let mut assigned: bool = false;

        for (cluster_hashset, cluster_members) in &amp;mut clusters {
            let cluster_hashset: HashSet&lt;&amp;[u8]&gt; =
                cluster_hashset.iter().map(|h| h.as_bytes()).collect();

            let d = jaccard_index(&amp;minimizer_set, &amp;cluster_hashset);

            if d &gt;= threshold {
                assigned = true;
                cluster_members.push(seq_name);
                break;
            }
        }

        if !assigned {
            clusters.push((minimizers, vec![seq_name]));
        }
    }

    clusters
}

fn main() {
    let seqs: Vec&lt;(&amp;str, &amp;[u8])&gt; = vec![
        ("seq_1", b"AAACACCGTGTGGGGCTAGCTATTTCACATGTGTCATGCAT"),
        ("seq_2", b"AAACACCGTGTGGGGCTAGCTATTTCACATGTGTCATGCAT"),
        ("seq_3", b"TACGTACGTACGTACGTACGATCGATCGTACGATCGATCGT"),
        ("seq_4", b"TACGTACGTCCGTACGTACGATCGATCGTACGATCGTTCGT"),
    ];

    let window_size: usize = 3;
    let kmer_size: usize = 3;
    let threshold: f64 = 0.6;

    let clusters = cluster(&amp;seqs[..], kmer_size, window_size, threshold);

    println!("Num clusters: {}", clusters.len());

    for (_, members) in clusters {
        println!("{:?}", members)
    }
}</code></pre>
<p>In this example, we have plenty of room for improvement. Firstly, we’d probably want to filter out low quality sequences if we have access to phred scores. Second, we could sort by quality in descending order. This ensures that new clusters are initiated with the highest quality sequences. In addition, our current approach is greedy, meaning that a sequence is assigned to the first best cluster we find. We don’t know if there is a better matching cluster later in the iteration. Finally, we obviously want a more efficient approach for generating minimizers (such at <a href="https://docs.rs/minimizer-iter/latest/minimizer_iter/index.html">minimizer_iter</a> or maybe even our own bit-shift encoded implementation).</p>
<p>In summary, this example is crap when it comes to performance. It does, however, conceptually illustrate how clustering algorithms work. <a href="https://github.com/aljpetri/isONclust3">isONclust3</a> and <a href="https://github.com/rcedgar/usearch12">USEARCH</a> are great examples of fast and high performance implementations.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="classification"><a class="header" href="#classification">Classification</a></h1>
<p>The final part of the amplicon chapter is classification. In essence, classification means we have some kind of confidence that a sequence originates from a specific taxon</p>
<h2 id="alignment-based-methods"><a class="header" href="#alignment-based-methods">Alignment based methods</a></h2>
<p>Usually, we’d use a global, semi-global or local aligner. The advantage of alignment based methods is that we can easily extract alignment metrics, such as the number of mismatches and indels, as well as alignment length, percent identity and other metrics. This is relevant if we not only want to find the best database hit, but also know how and where this database hit differs from our sequence.</p>
<p>The downside to alignment based methods is that they are slow when the number of sequences and database entries grow. Another downside, not commonly talked about, is the fundamental issue with choosing only the best database hit. Pretend that our sequence matches to a particular database entry (taxa X) with 99.9% identity, but also matches to another database entry (taxa Y) with 99.85% identity. Can we really be sure that our sequence belongs to taxa X? The difference in identities between the hits could be as little as a single nucleotide. We better make sure our sequence does not contain any errors, since a single sequencing error theoretically could flip the classification from taxa Y to taxa X. If taxa X and taxa Y are different species from the same genus, maybe it makes sense to classify this sequence on genus level. This is especially true for Nanopore data, where sequencing errors can reach several percent.</p>
<p>One algorithm that is worth mentioning here is <a href="https://github.com/treangenlab/emu">EMU</a>, which uses minimap2 to align Nanopore reads to the entire database. Through an iterative maximum likelihood algorithm, based on alignment metrics, it can accurately estimate taxonomic abundances in the sample.</p>
<h2 id="alignment-free-methods"><a class="header" href="#alignment-free-methods">Alignment free methods</a></h2>
<p>These typically use kmers and are based on exact matches. There are numerous ways to use kmers for classification, but one algorithm in particular is worth mentioning. <a href="https://doi.org/10.1101/074161">SINTAX</a> from the <a href="https://github.com/rcedgar/usearch12">USEARCH</a> toolkit uses a rather interesting kmer based classification approach that relies on bootstrapped subsampling of kmers to generate a classification confidence score for each sequence.</p>
<p>In the code example below, we’ll implement our own working prototype of a kmer based classifier. To keep things simple, we’ll just compare and extract common kmers between our sequences and database entries. For each sequence, we keep the database hit that had the highest match to our sequence.</p>
<pre class="playground"><code class="language-rust edition2024">fn main() {
    println!("");

    // Define some mock sequences.

    // Define some mock database entries.

    // Extract kmers from both sequences and database entries.

    // For each sequence, return the database entry that had the most number of common kmers.
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="blueprints"><a class="header" href="#blueprints">Blueprints</a></h1>
<p>This section acts as a collection of templates that can be used to build bioinformatic applications in Rust. Each chapter contains a brief introduction, followed by non-runnable template code that can be used as inspiration for building your own application.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="argument-parsing"><a class="header" href="#argument-parsing">Argument Parsing</a></h1>
<p>There are multiple ways to handle argument parsing in Rust. One easy way is to use <a href="https://doc.rust-lang.org/book/ch12-01-accepting-command-line-arguments.html"><code>std::env</code></a>, but it quickly becomes rather complex when the number and types of arguments increase.</p>
<p>An alternative approach is to use <a href="https://docs.rs/clap/latest/clap/">clap</a>, which has worked really well for me personally. Defining arguments is as easy as defining a struct with a clap specific derive macro.</p>
<p>For reproducibility purposes, the code example uses the following Cargo.toml dependency:</p>
<pre><code class="language-toml">[dependencies]
clap = { version = "4.5.39", features = ["derive"] }
</code></pre>
<p>Pretend we are creating a CLI called <code>fasta_cli</code> for filtering and parsing a FASTA file. These might be some of the arguments we think are relevant.</p>
<pre><code class="language-rust noplayground">use clap::Parser;
use clap::value_parser;
use std::path::PathBuf;

#[derive(Parser, Debug)]
struct Args {
    #[arg(short, long, help = "Path to fasta file.")]
    fasta: PathBuf,

    #[arg(long, default_value_t = 100, help = "Min allowed read length.")]
    min_len: usize,

    #[arg(long, default_value_t = 1000, help = "Max allowed read length.")]
    max_len: usize,

    #[arg(long, default_value_t = 15, value_parser = value_parser!(u16).range(7..31))]
    kmer_size: u16,

    #[arg(short, long, default_value_t = 8)]
    threads: usize,
}

fn main() {
    let args = Args::parse();

    // Now, we can access the values as args.fasta, args.min_len, etc.
}</code></pre>
<p>Once compiled, we can run our binary as <code>fasta_cli --fasta &lt;file.fasta&gt; --min_len &lt;min_len&gt; --max_len &lt;max_len&gt; --kmer_size &lt;kmer_size&gt; --threads &lt;threads&gt;</code>.</p>
<p>Clap also supports more complex argument parsing, such as global flags, subcommands and enums. See e.g., <a href="https://github.com/OscarAspelin95/fastq_rs/blob/main/src/args.rs">fastq_rs</a> for examples of this.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="commands"><a class="header" href="#commands">Commands</a></h1>
<p>In Python, commands can easily be run with <code>subprocess</code> or through the very neat <a href="https://github.com/amoffat/sh"><code>sh</code></a> module.</p>
<p>In Rust, we can use <code>std::process::Command</code> to achieve something similar to <code>subprocess</code>. The example below shows how to call <code>minimap2</code> to align reads against a genome. We’ll use <code>thiserror</code> to create two custom errors, the last of which will capture stderr if the command exits with a non-zero exit code.</p>
<p>For reproducibility purposes, the code example uses the following Cargo.toml dependency:</p>
<pre><code class="language-toml">[dependencies]
thiserror = { version = "2.0.16" }
</code></pre>
<p>Note, we obviously need <code>minimap2</code> installed in order for this code to work properly.</p>
<pre><code class="language-rust noplayground">use std::{path::PathBuf, process::Command};
use thiserror::Error;

#[derive(Debug, Error)]
enum RunCommandError {
    #[error("Failed to initialize child process.")]
    CommandInitError,

    #[error("Command exited with non-zero exit code.")]
    NonZeroExitCodeError(String),
}

fn minimap2_align(fastq: PathBuf, fasta: PathBuf, outfile: PathBuf) -&gt; Result&lt;(), RunCommandError&gt; {
    let result = Command::new("minimap2")
        .arg(fasta)
        .arg(fastq)
        .arg("-o")
        .arg(outfile)
        .arg("-a")
        .output()
        .map_err(|_| RunCommandError::CommandInitError)?;

    match result.status.success() {
        true =&gt; Ok(()),
        false =&gt; Err(RunCommandError::NonZeroExitCodeError(
            String::from_utf8(result.stderr).unwrap(),
        )),
    }
}

fn main() {
    let fastq = PathBuf::from("reads.fastq.gz");
    let fasta = PathBuf::from("genome.fasta");
    let outfile = PathBuf::from("out.sam");

    minimap2_align(fastq, fasta, outfile).unwrap();
}</code></pre>
<p>Why would we want to call <code>minimap2</code> from Rust instead of e.g., Python or Bash? In many cases, we wouldn’t. If the goal is to simply align reads and parse the generated .sam file with SAMtools, then Python or Bash are probably better alternatives.</p>
<p>However, maybe our goal is to align reads and parse the .sam file with <a href="https://docs.rs/rust-htslib/latest/rust_htslib/">rust_htslib</a> to calculate some more advanced alignment statistics that require high performance. Maybe we also had a Rust preprocessing step for the fastq file prior to alignment. In those cases, it <em>could</em> be justified to also call <code>minimap2</code> from Rust to make the codebase more unified.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="dataframes"><a class="header" href="#dataframes">DataFrames</a></h1>
<p>Reading and manipulating dataframes in Rust is actually not that easy. <a href="https://docs.rs/polars/latest/polars/">Polars</a> is the crate to use for dataframes but honestly, the Rust API is not that good. In my opinion, it is much easier to either use the Python API, or simply use <a href="https://pandas.pydata.org/">pandas</a> and completely skip Rust.</p>
<p>With that said, here is a small example of reading a .tsv file in Rust, using polars.</p>
<p>For reproducibility purposes, the code example uses the following Cargo.toml dependency:</p>
<pre><code class="language-toml">[dependencies]
polars = { version = "0.50.0", features = ["lazy", "csv"]}
</code></pre>
<pre><code class="language-rust noplayground">use polars::prelude::*;

/// Assumes tab separated values and that the first line is the header.
fn tsv_to_df(tsv: &amp;PathBuf) -&gt; LazyFrame {
    let df = LazyCsvReader::new(PlPath::new(tsv.to_str().unwrap()))
        .with_separator(b'\t')
        .with_has_header(true)
        .with_truncate_ragged_lines(true)
        .finish()
        .expect("Failed to read tsv to DataFrame.");

    df
}

fn main() {
    let tsv: PathBuf = PathBuf::from("my_file.tsv");

    let df = tsv_to_df(&amp;tsv);

    // Do stuff with the dataframe...
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="needletail"><a class="header" href="#needletail">Needletail</a></h1>
<p>The <a href="https://docs.rs/needletail/0.6.3/needletail/">needletail</a> crate is perfectly suited for reading and parsing FASTA and FASTQ files. It is very fast and efficient but not easily parallelized. Here, we’ll outline a template for reading a fastq file and looping over each record.</p>
<p>For reproducibility purposes, the code example uses the following Cargo.toml dependency:</p>
<pre><code class="language-toml">[dependencies]
needletail = { version = "0.6.3" }
</code></pre>
<pre><code class="language-rust noplayground">use needletail::parse_fastx_file;
use std::path::PathBuf;

fn main() {
    let fastx_file = PathBuf::from("file.fastq.gz");

    let mut reader = parse_fastx_file(&amp;fastx_file).expect("Failed to initialize FastxReader.");

    while let Some(record) = reader.next() {
        let record = match record {
            Ok(record) =&gt; record,
            Err(_) =&gt; continue,
        };
    }

    // Do stuff with the record...
}</code></pre>
<p>The advantage of using <code>parse_fastx_file</code> is that we can read both .fasta and .fastq files in plain or gzip format, which is very convenient.</p>
<p>Note that in this example, we just skip invalid records. In practice, we probably want to log that as a warning or error.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="bio"><a class="header" href="#bio">Bio</a></h1>
<p>An alternative needletail is the <a href="https://docs.rs/bio/latest/bio/">bio</a> crate. This fastq reader is not as fast as needletail and does not natively handle both gzipped files. It is however easily parallelized with <a href="https://docs.rs/rayon/latest/rayon/">rayon</a> using <code>par_bridge()</code>. In the following example, we use <a href="https://docs.rs/flate2/latest/flate2/">flate2</a> together with rayon and <code>bio::io::fastq::Reader</code> to enable multi-thread support for gzipped fastq files. For a FASTA equivalent reader, check out <code>bio::io::fasta::Reader</code>.</p>
<p>For reproducibility purposes, the code example uses the following Cargo.toml dependencies:</p>
<pre><code class="language-toml">[dependencies]
bio = { version = "2.3.0" }
flate2 = { version = "1.1.2" }
rayon = { version = "1.10.0" }
</code></pre>
<pre><code class="language-rust noplayground">use bio::io::fastq::Reader;
use flate2::read::MultiGzDecoder;
use rayon::prelude::*;
use std::{fs::File, path::PathBuf};

fn main() {
    let fastq_file = PathBuf::from("file.fastq.gz");

    let f = File::open(fastq_file).expect("Failed to open provided file.");

    // Wrap in GzDecoder since file is in gzip format.
    let gzip_reader = Reader::new(MultiGzDecoder::new(f));

    gzip_reader.records().par_bridge().for_each(|record| {
        let record = match record {
            Ok(record) =&gt; record,
            Err(_) =&gt; return,
        };

        // Do stuff with the record...
    });
}</code></pre>
<p>Since <code>.records()</code> returns an iterator, we can apply loads of different iterator chaining steps here, such as <code>.map()</code> or <code>.filter_map()</code> followed by <code>.collect()</code>.</p>
<p><strong>A word of caution</strong> - multithreading is great in certain circumstances, but not all. If the processing time for each record is very short, for example if we only calculate the length of each record, multithreading probably does not help. It might actually be slower. In those cases, needletail is probably a better alternative.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="resources-1"><a class="header" href="#resources-1">Resources</a></h1>
<h2 id="reading-references"><a class="header" href="#reading-references">Reading References</a></h2>
<ul>
<li><a href="https://doc.rust-lang.org/book/">The Rust Programming Language</a> - Official Rust book.</li>
<li><a href="https://practice.course.rs/">Rust By Practice</a> - Practice Rust.</li>
<li><a href="https://doc.rust-lang.org/nomicon/intro.html">The Rustonomicon</a> - Even more Rust!</li>
<li><a href="https://nnethercote.github.io/perf-book/">The Rust Performance Book</a> - How to optimize Rust for performance.</li>
<li><a href="https://www.rustfinity.com/">Rustfinity</a> - Learn Rust through interactive problems.</li>
</ul>
<h2 id="viewing-references"><a class="header" href="#viewing-references">Viewing References</a></h2>
<ul>
<li><a href="https://www.youtube.com/@jonhoo">Jon Gjengset</a></li>
<li><a href="https://www.youtube.com/@letsgetrusty">Bogdan from Let’s Get Rusty</a></li>
<li><a href="https://www.youtube.com/@yousuckatprogramming">Dave from You Suck at Programming</a></li>
<li><a href="https://www.youtube.com/@maxtaylordev">Max Taylor</a></li>
<li><a href="https://www.youtube.com/@RustCurious">Rust Curious</a></li>
</ul>
<h2 id="listening-references"><a class="header" href="#listening-references">Listening References</a></h2>
<ul>
<li><a href="https://open.spotify.com/show/0Hf6gWrzpSzXp1X0cebbsT?si=db39249cb66b4d9b">Rust in Production</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="awesome-rust-crates"><a class="header" href="#awesome-rust-crates">Awesome Rust crates</a></h1>
<p>General purpose awesome Rust crates!
For a mega list of even more crates, see <a href="https://github.com/rust-unofficial/awesome-rust">Awesome Rust</a>.</p>
<ul>
<li><a href="https://docs.rs/clap/latest/clap/">Clap</a> - Command line argument parsing.</li>
<li><a href="https://docs.rs/rstest/latest/rstest/">Rstest</a> - Rust test fixtures.</li>
<li><a href="https://docs.rs/rayon/latest/rayon/">Rayon</a> - Multithreading library for iterators.</li>
<li><a href="https://github.com/xacrimon/dashmap">Dashmap</a> - Concurrent HashMaps.</li>
<li><a href="https://docs.rs/serde/latest/serde/">Serde</a> - Serialization/Deserialization.</li>
<li><a href="https://docs.rs/thiserror/latest/thiserror/">Thiserror</a> - Easily create custom error types.</li>
<li><a href="https://docs.rs/anyhow/latest/anyhow/">Anyhow</a> - Idiomatic error handling.</li>
<li><a href="https://docs.rs/log/latest/log/">Log</a> and <a href="https://docs.rs/simple_logger/latest/simple_logger/">SimpleLogger</a> - Switch those pesky println! macros for proper logging.</li>
<li><a href="https://docs.rs/flate2/latest/flate2/">Flate2</a> - Compression/Decompression library.</li>
<li><a href="https://docs.rs/bindgen/latest/bindgen/">Bindgen</a> - Rust bindings for C and C++.</li>
<li><a href="https://docs.rs/polars/latest/polars/">Polars</a> - Blazingly fast dataframes. <strong>NOTE</strong> - Using polars with native Rust can be a bit cumbersome. An alternative is to use the <a href="https://docs.pola.rs/api/Python/stable/reference/index.html">Python bindings</a>.</li>
<li><a href="https://docs.rs/pyo3/latest/pyo3/">Pyo3</a> - Generate Rust bindings to Python or vice versa.</li>
<li><a href="https://github.com/plotly/plotly.rs">Plotly-rs</a> - Rust bindings for the popular Plotly plotting library.</li>
<li><a href="https://docs.rs/linfa/latest/linfa/">Linfa</a> - Closely resembles Python’s scikit-learn for Machine Learning applications.</li>
<li><a href="https://github.com/statrs-dev/statrs">Statrs</a> - Statistical utilities such as distributions, etc.</li>
<li><a href="https://docs.rs/validator/latest/validator/">Validator</a> - Struct validation.</li>
<li><a href="https://github.com/DioxusLabs/dioxus">Dioxus</a> - Fullstack framework in Rust that resembles React. Build your own (bioinformatic) web or desktop applications!</li>
<li><a href="https://ratatui.rs/">Ratatui</a> - Build TUI applications in Rust.</li>
<li><a href="https://iced.rs/">Iced</a> - Build GUI applications in Rust.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="awesome-bioinformatic-tools"><a class="header" href="#awesome-bioinformatic-tools">Awesome bioinformatic tools</a></h1>
<p>Alignment related:</p>
<ul>
<li><a href="https://github.com/lh3/minimap2">Minimap2</a> [C] - Pairwise aligner. Written by the legendary <a href="https://github.com/lh3">Heng Li</a>. The go-to for Oxford Nanopore and PacBio data.</li>
<li><a href="https://github.com/lh3/bwa">BWA-MEM</a> [C] - Pairwise aligner suitable for Illumina data.</li>
<li><a href="https://github.com/jeffdaily/parasail">Parasail</a> [C] - General purpose pairwise aligner.</li>
<li><a href="https://docs.rs/parasail-rs/latest/parasail_rs/">Parasail-rs</a> [Rust] - Rust bindings for the parasail library.</li>
<li><a href="https://blast.ncbi.nlm.nih.gov/Blast.cgi">BLAST</a> [C++] - The usual go-to for local sequence alignment.</li>
<li><a href="https://mafft.cbrc.jp/alignment/server/index.html">MAFFT</a> - Multiple sequence aligner.</li>
<li><a href="https://www.ebi.ac.uk/jdispatcher/msa/clustalo">Clustal Omega</a> - Multiple sequence aligner.</li>
</ul>
<p>Assembly related:</p>
<ul>
<li><a href="https://github.com/mikolmogorov/Flye">Flye</a> [C/C++] - Genome assembler for Oxford Nanopore or PacBio data.</li>
<li><a href="https://github.com/loneknightpy/idba">IDBA</a> [C++] - Illumina specific genome assembler.</li>
<li><a href="https://github.com/ablab/spades">SPAdes</a> [C++] - Genome assembler suitable for Illumina or IonTorrent data.</li>
<li><a href="https://github.com/bluenote-1577/myloasm">Myloasm</a> [Rust] - Longread metagenome assembler.</li>
</ul>
<p>Variant calling related:</p>
<ul>
<li><a href="https://github.com/HKU-BAL/Clair3">Clair3</a> [Python] - Variant caller suitable for Illumina, Oxford Nanopore or PacBio data.</li>
<li><a href="https://github.com/nanoporetech/medaka">Medaka</a> [Python] - Variant caller and polishing tool specifically for Oxford Nanopore data.</li>
<li><a href="https://github.com/freebayes/freebayes">Freebayes</a> [C++] - Variant caller suitable for Illumina and IonTorrent data. Questionable use for Oxford Nanopore data.</li>
</ul>
<p>Misc:</p>
<ul>
<li><a href="https://github.com/samtools/samtools">SAMtools</a> [C] - SAM file manipulation.</li>
<li><a href="https://github.com/samtools/bcftools">BCFtools</a> [C] - VCF file manipulation.</li>
<li><a href="https://github.com/lh3/kmer-cnt">Kmer-cnt</a> [C] - Several kmer counting algorithms.</li>
<li><a href="https://github.com/shenwei356/seqkit">Seqkit</a> [Go] - Parsing and processing FASTA/Q files.</li>
<li><a href="https://ics.hutton.ac.uk/tablet/">Tablet</a> [Java] - Graphical alignment visualizer.</li>
<li><a href="https://github.com/rrwick/Bandage">Bandage</a> [C++] - Assembly graph visualizer.</li>
</ul>
<p>Tools written in Rust:</p>
<ul>
<li><a href="https://docs.rs/needletail/latest/needletail/">Needletail</a> [Rust] - Parsing and processing FASTA/Q files.</li>
<li><a href="http://docs.rs/bio/latest/bio/">Bio</a> [Rust] - General purpose bioinformatic tool for alignment, file processing and much more.</li>
<li><a href="https://docs.rs/bio-seq/latest/bio_seq/">Bio-seq</a> [Rust] - Toolbox for bit-packed biological sequences.</li>
<li><a href="https://github.com/bluenote-1577/sylph">Sylph</a> [Rust] - Metagenomic classification tool.</li>
<li><a href="https://docs.rs/rust-htslib/latest/rust_htslib/">Rust Htslib</a> [Rust] - Rust bindings for Htslib.</li>
<li><a href="https://github.com/nextstrain/nextclade">Nextclade</a> [Rust] - Virus specific tool for alignment, SNP calling, clade assignment and more.</li>
<li><a href="https://github.com/lbcb-sci/herro">Herro</a> [Rust] - Deep-learning based error correction tool for Oxford Nanopore data.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="thank-you"><a class="header" href="#thank-you">Thank You</a></h1>
<p>This was it. If you have made it to this point, I sincerely want to thank you for spending your time reading through this book.</p>
<p>Initially, this started off as a private project with the goal of learning more about the Rust programming language. Since my background is in biotech/bioinformatics, the combination Rust + bioinformatics felt very natural to me. Along the way, I realized that even though there are some bioinformatic tools written in Rust, there was no really good tutorial on just how well Rust integrates with the bioinformatic landscape.</p>
<p>I strongly opted out of vibe-coding this entire book. If I’d used ChatGPT and something like Claude, this project would probably have been done in a few days. Instead, I chose the difficult but proper way of reading a lot of resources and documentation. I did a lot of testing and failing until I reached something I thought was good enough. It is not perfect, nowhere close actually.</p>
<h2 id="contributions"><a class="header" href="#contributions">Contributions</a></h2>
<p>This project is far from done. It probably never will be. However, I stand by the concept of open-source and people working together to create software that is available for everyone. If you feel like you could contribute in any shape, way or form, then I’d be more than open to this.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>


        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace-2a3cd908.js"></script>
        <script src="mode-rust-2c9d5c9a.js"></script>
        <script src="editor-16ca416c.js"></script>
        <script src="theme-dawn-4493f9c8.js"></script>
        <script src="theme-tomorrow_night-9dbe62a9.js"></script>

        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid-eefea253.min.js"></script>
        <script src="mermaid-init-ccf746f1.js"></script>

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>


    </div>
    </body>
</html>
